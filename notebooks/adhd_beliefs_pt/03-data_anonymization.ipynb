{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from presidio_analyzer import AnalyzerEngine, EntityRecognizer, RecognizerResult\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
<<<<<<< Updated upstream
    "from transformers import pipeline"
=======
    "from huggingface_hub import snapshot_download\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/adhd-beliefs-pt/adhd-beliefs-pt-cleaned.pkl\"\n",
    "df = pd.read_pickle(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d13f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"special_interest\", \"diary_entry\", \"selfdefining_memory\", \"empty_sheet\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "faker = Faker(\"pt_PT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
=======
   "id": "570536d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-large-finetuned-conll03-english\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"FacebookAI/xlm-roberta-large-finetuned-conll03-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "33883b98",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "ner_pipeline = pipeline(\n",
    "    \"ner\", model=\"pucpr/roberta-ner-portuguese\", aggregation_strategy=\"simple\"\n",
=======
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c02105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model config\n",
    "model_config = [\n",
    "    {\"lang_code\": \"pt\",\n",
    "     \"model_name\": {\n",
    "         \"spacy\": \"pt_core_web_lg\", # for tokenization, lemmatization\n",
    "         \"transformers\": \"FacebookAI/xlm-roberta-large-finetuned-conll03-english\" # for NER\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a783cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(\n",
    "    PER=\"PERSON\",\n",
    "    LOC=\"LOCATION\",\n",
    "    ORG=\"ORGANIZATION\",\n",
    "    EMAIL=\"EMAIL\",\n",
    ")\n",
    "labels_to_ignore = [\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a28b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model_configuration = NerModelConfiguration(\n",
    "    model_to_presidio_entity_mapping=mapping,\n",
    "    alignment_mode=\"expand\", # \"strict\", \"contract\", \"expand\"\n",
    "    aggregation_strategy=\"max\", # \"simple\", \"first\", \"average\", \"max\"\n",
    "    labels_to_ignore = labels_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_nlp_engine = TransformersNlpEngine(\n",
    "    models=model_config,\n",
    "    ner_model_configuration=ner_model_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdde646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer-based analyzer\n",
    "analyzer = AnalyzerEngine(\n",
    "    nlp_engine=transformers_nlp_engine, \n",
    "    supported_languages=[\"pt\"]\n",
>>>>>>> Stashed changes
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
=======
   "id": "31f229f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline(\"Meu nome é Carla Souza e trabalho na Fiocruz. Moro em Fortaleza. Tenho 30 anos e gosto de viajar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "ebb35827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom recognizer using HuggingFace pipeline\n",
    "class HFPortugueseNERRecognizer(EntityRecognizer):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
<<<<<<< Updated upstream
    "            supported_entities=[\"PERSON\", \"ORG\", \"LOC\"],\n",
    "            name=\"HFPortugueseNERRecognizer\",\n",
    "        )\n",
=======
    "            supported_entities=[\"I-PER\", \"I-ORG\", \"I-LOC\"],\n",
    "            name=\"HFPortugueseNERRecognizer\",\n",
    "        )\n",
    "        self.supported_language = \"pt\"\n",
>>>>>>> Stashed changes
    "\n",
    "    def analyze(self, text, entities, nlp_artifacts=None):\n",
    "        results = []\n",
    "        ner_results = ner_pipeline(text)\n",
    "\n",
    "        for item in ner_results:\n",
<<<<<<< Updated upstream
    "            entity = item[\"entity_group\"]\n",
=======
    "            entity = item[\"entity\"]\n",
>>>>>>> Stashed changes
    "            if entity in entities:\n",
    "                results.append(\n",
    "                    RecognizerResult(\n",
    "                        entity_type=entity,\n",
    "                        start=item[\"start\"],\n",
    "                        end=item[\"end\"],\n",
    "                        score=item[\"score\"],\n",
    "                    )\n",
    "                )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cdeecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faker_replacement(entity_type):\n",
<<<<<<< Updated upstream
    "    if entity_type == \"PERSON\":\n",
    "        return faker.name()\n",
    "    elif entity_type == \"ORG\":\n",
    "        return faker.company()\n",
    "    elif entity_type == \"LOC\":\n",
=======
    "    if entity_type == \"I-PER\":\n",
    "        return faker.name()\n",
    "    elif entity_type == \"I-ORG\":\n",
    "        return faker.company()\n",
    "    elif entity_type == \"I-LOC\":\n",
>>>>>>> Stashed changes
    "        return faker.city()\n",
    "    elif entity_type == \"EMAIL_ADDRESS\":\n",
    "        return faker.email()\n",
    "    else:\n",
    "        return \"[REDACTED]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f86672",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Meu nome é Carla Souza e trabalho na Fiocruz. Moro em Fortaleza.\n",
    "Meu e-mail é carla.souza@exemplo.com.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Analyzer with custom NER\n",
    "analyzer = AnalyzerEngine()\n",
    "analyzer.registry.add_recognizer(HFPortugueseNERRecognizer())\n",
<<<<<<< Updated upstream
    "results = analyzer.analyze(text=text, language=\"pt\")"
=======
    "results = analyzer.analyze(text=text, language=\"pt\", nlp_artifacts={})"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb90098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build fake replacement instructions\n",
    "from presidio_anonymizer.entities import AnonymizerResult, OperatorConfig\n",
    "\n",
    "operators = {}\n",
    "for res in results:\n",
    "    fake_value = faker_replacement(res.entity_type)\n",
    "    operators[res.entity_type] = OperatorConfig(\"replace\", {\"new_value\": fake_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35956b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Anonymize\n",
    "anonymizer = AnonymizerEngine()\n",
    "anonymized = anonymizer.anonymize(\n",
    "    text=text, analyzer_results=results, operators=operators\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "print(\"Original:\\n\", text)\n",
    "print(\"\\nAnonymized:\\n\", anonymized.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
   "version": "3.10.12"
=======
   "version": "3.13.2"
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
