{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f601a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from pingouin import bayesfactor_ttest\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b173b38",
   "metadata": {},
   "source": [
    "## Women with ADHD vs. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa32460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/adhd-beliefs-pt/adhd-beliefs-pt-liwc-proportional.pkl\")\n",
    "mask_adhd = (df['sex']==\"Feminino\") & (df['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "mask_others = ~mask_adhd\n",
    "features = df.columns[-64:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea845ca",
   "metadata": {},
   "source": [
    "## Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b7f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_liwc(df, features, mask_g1, mask_g2, alpha=0.05):\n",
    "    \"\"\"\n",
    "    For each LIWC feature:\n",
    "      - Welch’s t-test\n",
    "      - JZS Bayes factor\n",
    "      - Cohen’s d\n",
    "    Returns a DataFrame with p-values, BF10, d, FDR‐corrected p’s, etc.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for feat in features:\n",
    "        g1 = df.loc[mask_g1, feat].dropna()\n",
    "        g2 = df.loc[mask_g2, feat].dropna()\n",
    "        t_stat, p_val = stats.ttest_ind(g1, g2, equal_var=False)\n",
    "        n1, n2 = len(g1), len(g2)\n",
    "        bf10 = bayesfactor_ttest(t_stat, n1, n2, paired=False)\n",
    "        s1, s2 = g1.std(ddof=1), g2.std(ddof=1)\n",
    "        s_pool = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2)/(n1+n2-2))\n",
    "        d = (g1.mean() - g2.mean())/s_pool\n",
    "        rows.append({\n",
    "            'feature': feat,\n",
    "            'mean_g1': g1.mean(),\n",
    "            'sd_g1': s1,\n",
    "            'mean_g2': g2.mean(),\n",
    "            'sd_g2': s2,\n",
    "            't_stat': t_stat,\n",
    "            'p_val': p_val,\n",
    "            'bf10': bf10,\n",
    "            'cohen_d': d\n",
    "        })\n",
    "    df_res = pd.DataFrame(rows)\n",
    "    _, p_corr, _, _ = multipletests(df_res['p_val'], method='fdr_bh')\n",
    "    df_res['p_fdr'] = p_corr\n",
    "    df_res['signif'] = df_res['p_fdr'] <= alpha\n",
    "    df_res['abs_cohen_d'] = df_res['cohen_d'].abs()\n",
    "    return df_res.sort_values('abs_cohen_d', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ece417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_group_diff(df, features, mask_g1, mask_g2, n_pc=5, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Standardize LIWC features, run PCA, perform Welch’s t-test on each PC\n",
    "    Returns a DataFrame of PC, explained_variance, t_stat, p_val, p_fdr.\n",
    "    \"\"\"\n",
    "    X = df[features].fillna(0).values\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=n_pc)\n",
    "    pcs = pca.fit_transform(Xs)\n",
    "    rows = []\n",
    "    for i in range(n_pc):\n",
    "        comp = pcs[:, i]\n",
    "        t, p = stats.ttest_ind(comp[mask_g1], comp[mask_g2], equal_var=False)\n",
    "        rows.append({\n",
    "            'PC': f'PC{i+1}',\n",
    "            'expl_var': pca.explained_variance_ratio_[i],\n",
    "            't_stat':   t,\n",
    "            'p_val':    p\n",
    "        })\n",
    "    df_pc = pd.DataFrame(rows)\n",
    "    _, p_corr, _, _ = multipletests(df_pc['p_val'], method='fdr_bh')\n",
    "    df_pc['p_fdr'] = p_corr\n",
    "    return df_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b234d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_pc1_loadings(df, features, n=10):\n",
    "    X = df[features].fillna(0).values\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(Xs)\n",
    "    load = pd.Series(pca.components_[0], index=features)\n",
    "    df_load = load.abs().sort_values(ascending=False).head(n).to_frame('abs_loading')\n",
    "    df_load['loading'] = load.loc[df_load.index]\n",
    "    return df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9899bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _adaptive_inner_cv(y, target_splits=5):\n",
    "    \"\"\"Use 5 folds if every class has >=5 samples; otherwise back off to 3.\"\"\"\n",
    "    min_class = np.min(np.bincount(y))\n",
    "    n_splits = target_splits if min_class >= target_splits else 3\n",
    "    return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5579e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logregcv_l1(inner_cv):\n",
    "    \"\"\"Configured L1-Logistic with explicit C grid and ROC-AUC tuning.\"\"\"\n",
    "    C_grid = np.logspace(-4, 4, 30)\n",
    "    return LogisticRegressionCV(\n",
    "        Cs=C_grid, cv=inner_cv, penalty=\"l1\", solver=\"saga\",\n",
    "        scoring=\"roc_auc\", class_weight=\"balanced\",\n",
    "        max_iter=5000, random_state=42, refit=True, n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "078cf710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stratified_bootstrap(X, y, rng):\n",
    "    \"\"\"Per-class resample with replacement; preserves class balance.\"\"\"\n",
    "    Xb_list, yb_list = [], []\n",
    "    for cls in np.unique(y):\n",
    "        idx = np.where(y == cls)[0]\n",
    "        samp = rng.choice(idx, size=len(idx), replace=True)\n",
    "        Xb_list.append(X[samp])\n",
    "        yb_list.append(y[samp])\n",
    "    Xb = np.vstack(Xb_list)\n",
    "    yb = np.concatenate(yb_list)\n",
    "    perm = rng.permutation(len(yb))\n",
    "    return Xb[perm], yb[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fd29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_logistic_top(df, features, mask_g1, n=10):\n",
    "    X = df[features].fillna(0).values\n",
    "    y = mask_g1.astype(int).values\n",
    "\n",
    "    inner_cv = _adaptive_inner_cv(y, target_splits=5)\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", _logregcv_l1(inner_cv))\n",
    "    ])\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    coef = pd.Series(pipe.named_steps[\"clf\"].coef_[0], index=features)\n",
    "    top = coef.abs().sort_values(ascending=False).head(n).index\n",
    "    return pd.DataFrame({\"coef\": coef.loc[top]}).sort_values(\"coef\", key=np.abs, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "999e7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_auc(df, features, mask_g1):\n",
    "    X = df[features].fillna(0).values\n",
    "    y = mask_g1.astype(int).values\n",
    "\n",
    "    inner_cv = _adaptive_inner_cv(y, target_splits=5)\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", _logregcv_l1(inner_cv))\n",
    "    ])\n",
    "\n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    auc_scores = cross_val_score(pipe, X, y, cv=outer_cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    return auc_scores.mean(), auc_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd76ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_stability(df, features, mask_g1, n_boot=100, tol=1e-6):\n",
    "    X = df[features].fillna(0).values\n",
    "    y = mask_g1.astype(int).values\n",
    "\n",
    "    inner_cv = _adaptive_inner_cv(y, target_splits=5)\n",
    "\n",
    "    sel_counts = pd.Series(0, index=features, dtype=float)\n",
    "    pos_counts = pd.Series(0, index=features, dtype=float)\n",
    "    coef_sum   = pd.Series(0.0, index=features)\n",
    "\n",
    "    rng = np.random.RandomState(1000)\n",
    "\n",
    "    for b in range(n_boot):\n",
    "        Xb, yb = _stratified_bootstrap(X, y, rng)\n",
    "        if len(np.unique(yb)) < 2:\n",
    "            continue  # extreme edge case, but safe-guard\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", _logregcv_l1(inner_cv))\n",
    "        ])\n",
    "        pipe.fit(Xb, yb)\n",
    "\n",
    "        coef = pd.Series(pipe.named_steps[\"clf\"].coef_[0], index=features)\n",
    "        selected = coef.abs() > tol\n",
    "\n",
    "        sel_counts[selected] += 1\n",
    "        pos_counts[selected & (coef > 0)] += 1\n",
    "        coef_sum += coef\n",
    "\n",
    "    stability = sel_counts / n_boot\n",
    "    sign_consistency = (pos_counts / sel_counts.replace(0, np.nan))\n",
    "    mean_coef = coef_sum / n_boot\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"sel_prop\": stability,\n",
    "        \"mean_coef\": mean_coef,\n",
    "        \"pos_sign_prop\": sign_consistency\n",
    "    }).sort_values([\"sel_prop\", \"mean_coef\"], ascending=False)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8414a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(x, y):\n",
    "    nx, ny = len(x), len(y)\n",
    "    sx, sy = np.std(x, ddof=1), np.std(y, ddof=1)\n",
    "    s_pooled = np.sqrt(((nx-1)*sx**2 + (ny-1)*sy**2) / (nx+ny-2))\n",
    "    return (np.mean(x) - np.mean(y)) / s_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c09f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_cohen_d(x, y):\n",
    "    return abs(cohen_d(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5cc0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(x, y, statfunc, n_boot=1000, ci=95):\n",
    "    boot_stats = []\n",
    "    for _ in range(n_boot):\n",
    "        bx = resample(x, replace=True)\n",
    "        by = resample(y, replace=True)\n",
    "        boot_stats.append(statfunc(bx, by))\n",
    "    lower = np.percentile(boot_stats, (100-ci)/2)\n",
    "    upper = np.percentile(boot_stats, 100-(100-ci)/2)\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "417875f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_priori_power(effect_size=0.6, alpha=0.05, power=0.8):\n",
    "    analysis = TTestIndPower()\n",
    "    return analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39da82a",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbdecb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LIWC dimensions |d| > 0.5:\n",
      "| feature   |   mean_g1 |   sd_g1 |   mean_g2 |   sd_g2 |   t_stat |   p_val |   bf10 |   cohen_d |   p_fdr | signif   |   abs_cohen_d |\n",
      "|:----------|----------:|--------:|----------:|--------:|---------:|--------:|-------:|----------:|--------:|:---------|--------------:|\n",
      "| cogmech   |     0.288 |   0.114 |     0.351 |   0.074 |   -2.541 |   0.018 |  3.792 |    -0.773 |   0.131 | False    |         0.773 |\n",
      "| excl      |     0.033 |   0.024 |     0.054 |   0.028 |   -3.692 |   0.001 | 80.826 |    -0.732 |   0.050 | False    |         0.732 |\n",
      "| funct     |     0.372 |   0.122 |     0.433 |   0.078 |   -2.331 |   0.028 |  2.439 |    -0.715 |   0.150 | False    |         0.715 |\n",
      "| ipron     |     0.088 |   0.046 |     0.115 |   0.042 |   -2.674 |   0.012 |  5.099 |    -0.639 |   0.131 | False    |         0.639 |\n",
      "| pronoun   |     0.135 |   0.063 |     0.170 |   0.053 |   -2.494 |   0.019 |  3.421 |    -0.639 |   0.131 | False    |         0.639 |\n",
      "| relativ   |     0.157 |   0.065 |     0.194 |   0.060 |   -2.598 |   0.015 |  4.296 |    -0.620 |   0.131 | False    |         0.620 |\n",
      "| tentat    |     0.059 |   0.046 |     0.084 |   0.039 |   -2.459 |   0.020 |  3.179 |    -0.620 |   0.131 | False    |         0.620 |\n",
      "| space     |     0.072 |   0.045 |     0.100 |   0.046 |   -2.695 |   0.011 |  5.354 |    -0.597 |   0.131 | False    |         0.597 |\n",
      "| past      |     0.024 |   0.021 |     0.039 |   0.028 |   -3.088 |   0.004 | 14.193 |    -0.575 |   0.124 | False    |         0.575 |\n",
      "| discrep   |     0.039 |   0.026 |     0.055 |   0.031 |   -2.697 |   0.011 |  5.388 |    -0.530 |   0.131 | False    |         0.530 |\n",
      "| preps     |     0.115 |   0.061 |     0.138 |   0.042 |   -1.788 |   0.086 |  0.930 |    -0.525 |   0.302 | False    |         0.525 |\n",
      "| negate    |     0.005 |   0.007 |     0.002 |   0.004 |    1.523 |   0.141 |  0.637 |     0.519 |   0.407 | False    |         0.519 |\n"
     ]
    }
   ],
   "source": [
    "# 1) Univariate LIWC\n",
    "uni = univariate_liwc(df, features, mask_adhd, mask_others)\n",
    "print(\"\\nLIWC dimensions |d| > 0.5:\")\n",
    "print(uni[uni['abs_cohen_d']>0.5].to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4149b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrap 95% CIs for Cohen's d (|d| > 0.5):\n",
      "| feature   |      d |   ci_lower |   ci_upper |\n",
      "|:----------|-------:|-----------:|-----------:|\n",
      "| cogmech   | -0.773 |     -1.390 |     -0.254 |\n",
      "| excl      | -0.732 |     -1.122 |     -0.373 |\n",
      "| funct     | -0.715 |     -1.301 |     -0.190 |\n",
      "| ipron     | -0.639 |     -1.134 |     -0.182 |\n",
      "| pronoun   | -0.639 |     -1.166 |     -0.188 |\n",
      "| relativ   | -0.620 |     -1.103 |     -0.162 |\n",
      "| tentat    | -0.620 |     -1.135 |     -0.110 |\n",
      "| space     | -0.597 |     -1.074 |     -0.213 |\n",
      "| past      | -0.575 |     -0.948 |     -0.239 |\n",
      "| discrep   | -0.530 |     -0.925 |     -0.157 |\n",
      "| preps     | -0.525 |     -1.119 |      0.019 |\n",
      "| negate    |  0.519 |     -0.087 |      1.124 |\n"
     ]
    }
   ],
   "source": [
    "# 2) Bootstrap CIs for features with |d| > 0.5\n",
    "top_feats = uni[uni['abs_cohen_d'] > 0.5]['feature']\n",
    "ci_list = []\n",
    "for feat in top_feats:\n",
    "    x = df.loc[mask_adhd, feat].dropna().values\n",
    "    y = df.loc[mask_others, feat].dropna().values\n",
    "    d_obs = cohen_d(x, y)\n",
    "    lo, hi = bootstrap_ci(x, y, cohen_d, n_boot=2000, ci=95)\n",
    "    ci_list.append({'feature': feat, 'd': d_obs, 'ci_lower': lo, 'ci_upper': hi})\n",
    "ci_df = pd.DataFrame(ci_list)\n",
    "print(\"\\nBootstrap 95% CIs for Cohen's d (|d| > 0.5):\")\n",
    "print(ci_df.to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2251f9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Required N per group for d=0.6, α=0.05, 80% power: 44.6\n"
     ]
    }
   ],
   "source": [
    "# 3) A priori power\n",
    "req_n = a_priori_power(effect_size=0.6)\n",
    "print(f\"\\nRequired N per group for d=0.6, α=0.05, 80% power: {req_n:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8470cce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LIWC dimensions |d| > 0.5:\n",
      "| feature   |   mean_g1 |   sd_g1 |   mean_g2 |   sd_g2 |   t_stat |   p_val |   bf10 |   cohen_d |   p_fdr | signif   |   abs_cohen_d |      N |\n",
      "|:----------|----------:|--------:|----------:|--------:|---------:|--------:|-------:|----------:|--------:|:---------|--------------:|-------:|\n",
      "| cogmech   |     0.288 |   0.114 |     0.351 |   0.074 |   -2.541 |   0.018 |  3.792 |    -0.773 |   0.131 | False    |         0.773 | 27.283 |\n",
      "| excl      |     0.033 |   0.024 |     0.054 |   0.028 |   -3.692 |   0.001 | 80.826 |    -0.732 |   0.050 | False    |         0.732 | 30.254 |\n",
      "| funct     |     0.372 |   0.122 |     0.433 |   0.078 |   -2.331 |   0.028 |  2.439 |    -0.715 |   0.150 | False    |         0.715 | 31.690 |\n",
      "| ipron     |     0.088 |   0.046 |     0.115 |   0.042 |   -2.674 |   0.012 |  5.099 |    -0.639 |   0.131 | False    |         0.639 | 39.384 |\n",
      "| pronoun   |     0.135 |   0.063 |     0.170 |   0.053 |   -2.494 |   0.019 |  3.421 |    -0.639 |   0.131 | False    |         0.639 | 39.441 |\n",
      "| relativ   |     0.157 |   0.065 |     0.194 |   0.060 |   -2.598 |   0.015 |  4.296 |    -0.620 |   0.131 | False    |         0.620 | 41.851 |\n",
      "| tentat    |     0.059 |   0.046 |     0.084 |   0.039 |   -2.459 |   0.020 |  3.179 |    -0.620 |   0.131 | False    |         0.620 | 41.863 |\n",
      "| space     |     0.072 |   0.045 |     0.100 |   0.046 |   -2.695 |   0.011 |  5.354 |    -0.597 |   0.131 | False    |         0.597 | 44.983 |\n",
      "| past      |     0.024 |   0.021 |     0.039 |   0.028 |   -3.088 |   0.004 | 14.193 |    -0.575 |   0.124 | False    |         0.575 | 48.541 |\n",
      "| discrep   |     0.039 |   0.026 |     0.055 |   0.031 |   -2.697 |   0.011 |  5.388 |    -0.530 |   0.131 | False    |         0.530 | 56.767 |\n",
      "| preps     |     0.115 |   0.061 |     0.138 |   0.042 |   -1.788 |   0.086 |  0.930 |    -0.525 |   0.302 | False    |         0.525 | 57.827 |\n",
      "| negate    |     0.005 |   0.007 |     0.002 |   0.004 |    1.523 |   0.141 |  0.637 |     0.519 |   0.407 | False    |         0.519 | 59.167 |\n",
      "\n",
      "Summary of required N per group:\n",
      "Highest N: 152015.6 (feature: quant)\n",
      "Lowest N: 27.3 (feature: cogmech)\n",
      "Mean N: 5064.9\n",
      "Median N: 259.9\n",
      "\n",
      "Summary of required N per group:\n",
      "Highest N: 59.2 (feature: negate)\n",
      "Mean N: 43.3\n",
      "Median N: 41.9\n"
     ]
    }
   ],
   "source": [
    "# 3.5) A priori power\n",
    "uni = univariate_liwc(df, features, mask_adhd, mask_others)\n",
    "\n",
    "# Compute required N for each effect size\n",
    "uni['N'] = uni['abs_cohen_d'].apply(lambda d: a_priori_power(effect_size=d) if d > 0 else np.nan)\n",
    "\n",
    "print(\"\\nLIWC dimensions |d| > 0.5:\")\n",
    "subset = uni[uni['abs_cohen_d']>0.5]\n",
    "print(subset.to_markdown(index=False, floatfmt=\".3f\"))\n",
    "\n",
    "# Summary statistics for N\n",
    "valid_n = uni['N'].dropna()\n",
    "print(f\"\\nSummary of required N per group:\")\n",
    "print(f\"Highest N: {valid_n.max():.1f} (feature: {uni.loc[uni['N'].idxmax(), 'feature']})\")\n",
    "print(f\"Lowest N: {valid_n.min():.1f} (feature: {uni.loc[uni['N'].idxmin(), 'feature']})\")\n",
    "print(f\"Mean N: {valid_n.mean():.1f}\")\n",
    "print(f\"Median N: {valid_n.median():.1f}\")\n",
    "\n",
    "# Summary statistics for N in d > 0.5\n",
    "valid_n = subset['N'].dropna()\n",
    "if len(valid_n) > 0:\n",
    "    print(f\"\\nSummary of required N per group:\")\n",
    "    print(f\"Highest N: {valid_n.max():.1f} (feature: {subset.loc[subset['N'].idxmax(), 'feature']})\")\n",
    "    print(f\"Mean N: {valid_n.mean():.1f}\")\n",
    "    print(f\"Median N: {valid_n.median():.1f}\")\n",
    "else:\n",
    "    print(\"\\nNo valid N values found for features with |d| > 0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "183582a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA group differences:\n",
      "| PC   |   expl_var |   t_stat |   p_val |   p_fdr |\n",
      "|:-----|-----------:|---------:|--------:|--------:|\n",
      "| PC1  |      0.149 |   -2.725 |   0.011 |   0.055 |\n",
      "| PC2  |      0.081 |    1.095 |   0.282 |   0.705 |\n",
      "| PC3  |      0.069 |   -0.237 |   0.815 |   0.815 |\n",
      "| PC4  |      0.062 |    0.264 |   0.794 |   0.815 |\n",
      "| PC5  |      0.053 |    0.448 |   0.658 |   0.815 |\n"
     ]
    }
   ],
   "source": [
    "# 4) PCA group differences\n",
    "pc_res = pca_group_diff(df, features, mask_adhd, mask_others)\n",
    "print(\"\\nPCA group differences:\")\n",
    "print(pc_res.to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c499f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top PC1 loadings:\n",
      "|         |   loading |\n",
      "|:--------|----------:|\n",
      "| ipron   |     0.275 |\n",
      "| funct   |     0.274 |\n",
      "| pronoun |     0.274 |\n",
      "| nonfl   |     0.241 |\n",
      "| shehe   |     0.238 |\n",
      "| article |     0.237 |\n",
      "| social  |     0.230 |\n",
      "| you     |     0.224 |\n",
      "| ppron   |     0.221 |\n",
      "| cogmech |     0.220 |\n"
     ]
    }
   ],
   "source": [
    "# 5) PCA group differences\n",
    "pc1_ld = top_pc1_loadings(df, features, n=10)\n",
    "print(\"\\nTop PC1 loadings:\")\n",
    "print(pc1_ld[['loading']].to_markdown(floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03a063bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 127)\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "df_sub = df[mask_adhd | mask_others]\n",
    "new_mask_adhd = (df_sub['sex']==\"Feminino\") & (df_sub['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "print(df_sub.shape)\n",
    "print(new_mask_adhd.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235f485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         |   coef |\n",
      "|:--------|-------:|\n",
      "| excl    | -0.268 |\n",
      "| negate  |  0.243 |\n",
      "| past    | -0.150 |\n",
      "| pronoun | -0.147 |\n",
      "| space   | -0.123 |\n",
      "| cogmech | -0.100 |\n",
      "| relativ | -0.099 |\n",
      "| achieve | -0.057 |\n",
      "| humans  |  0.029 |\n",
      "| anx     |  0.027 |\n"
     ]
    }
   ],
   "source": [
    "top_coef = l1_logistic_top(df_sub, features, new_mask_adhd, n=10)\n",
    "print(top_coef.to_markdown(floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa55a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV AUC: mean=0.590, SD=0.126\n"
     ]
    }
   ],
   "source": [
    "mean_auc, sd_auc = nested_auc(df_sub, features, new_mask_adhd)\n",
    "print(f\"Nested CV AUC: mean={mean_auc:.3f}, SD={sd_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28578086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         |   sel_prop |   mean_coef |   pos_sign_prop |\n",
      "|:--------|-----------:|------------:|----------------:|\n",
      "| excl    |      0.690 |      -0.537 |           0.174 |\n",
      "| negate  |      0.900 |       0.812 |           0.978 |\n",
      "| past    |      0.660 |      -0.272 |           0.227 |\n",
      "| pronoun |      0.740 |      -0.710 |           0.000 |\n",
      "| space   |      0.580 |      -0.295 |           0.172 |\n",
      "| cogmech |      0.840 |      -1.510 |           0.000 |\n",
      "| relativ |      0.770 |      -0.509 |           0.091 |\n",
      "| achieve |      0.840 |      -1.352 |           0.012 |\n",
      "| humans  |      0.730 |       0.828 |           0.918 |\n",
      "| anx     |      0.600 |      -0.044 |           0.483 |\n"
     ]
    }
   ],
   "source": [
    "stab = l1_stability(df_sub, features, new_mask_adhd, n_boot=100)\n",
    "print(stab.loc[top_coef.index].to_markdown(floatfmt=\".3f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adhd-linguistic-patterns-beliefs-portuguese-women",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
