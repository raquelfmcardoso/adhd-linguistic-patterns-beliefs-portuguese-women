{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f601a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from pingouin import bayesfactor_ttest\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b173b38",
   "metadata": {},
   "source": [
    "## Women with ADHD vs. Women without ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa32460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/adhd-beliefs-pt/adhd-beliefs-pt-liwc-proportional.pkl\")\n",
    "mask_women = (df['sex']==\"Feminino\") & (df['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "mask_others = (df['sex']==\"Feminino\") & (df['adhd_diagnosis']!=\"Sim, diagnosticado\")\n",
    "features = df.columns[-64:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea845ca",
   "metadata": {},
   "source": [
    "## Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b7f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_liwc(df, features, mask_g1, mask_g2, alpha=0.05):\n",
    "    \"\"\"\n",
    "    For each LIWC feature:\n",
    "      - Welch’s t-test\n",
    "      - JZS Bayes factor\n",
    "      - Cohen’s d\n",
    "    Returns a DataFrame with p-values, BF10, d, FDR‐corrected p’s, etc.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for feat in features:\n",
    "        g1 = df.loc[mask_g1, feat].dropna()\n",
    "        g2 = df.loc[mask_g2, feat].dropna()\n",
    "        t_stat, p_val = stats.ttest_ind(g1, g2, equal_var=False)\n",
    "        n1, n2 = len(g1), len(g2)\n",
    "        bf10 = bayesfactor_ttest(t_stat, n1, n2, paired=False)\n",
    "        s1, s2 = g1.std(ddof=1), g2.std(ddof=1)\n",
    "        s_pool = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2)/(n1+n2-2))\n",
    "        d = (g1.mean() - g2.mean())/s_pool\n",
    "        rows.append({\n",
    "            'feature': feat,\n",
    "            'mean_g1': g1.mean(),\n",
    "            'sd_g1': s1,\n",
    "            'mean_g2': g2.mean(),\n",
    "            'sd_g2': s2,\n",
    "            't_stat': t_stat,\n",
    "            'p_val': p_val,\n",
    "            'bf10': bf10,\n",
    "            'cohen_d': d\n",
    "        })\n",
    "    df_res = pd.DataFrame(rows)\n",
    "    _, p_corr, _, _ = multipletests(df_res['p_val'], method='fdr_bh')\n",
    "    df_res['p_fdr'] = p_corr\n",
    "    df_res['signif'] = df_res['p_fdr'] < alpha\n",
    "    df_res['abs_cohen_d'] = df_res['cohen_d'].abs()\n",
    "    return df_res.sort_values('abs_cohen_d', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ece417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_group_diff(df, features, mask_g1, mask_g2, n_pc=5, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Standardize LIWC features, run PCA, perform Welch’s t-test on each PC\n",
    "    Returns a DataFrame of PC, explained_variance, t_stat, p_val, p_fdr.\n",
    "    \"\"\"\n",
    "    X = df[features].fillna(0).values\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=n_pc)\n",
    "    pcs = pca.fit_transform(Xs)\n",
    "    rows = []\n",
    "    for i in range(n_pc):\n",
    "        comp = pcs[:, i]\n",
    "        t, p = stats.ttest_ind(comp[mask_g1], comp[mask_g2], equal_var=False)\n",
    "        rows.append({\n",
    "            'PC': f'PC{i+1}',\n",
    "            'expl_var': pca.explained_variance_ratio_[i],\n",
    "            't_stat':   t,\n",
    "            'p_val':    p\n",
    "        })\n",
    "    df_pc = pd.DataFrame(rows)\n",
    "    _, p_corr, _, _ = multipletests(df_pc['p_val'], method='fdr_bh')\n",
    "    df_pc['p_fdr'] = p_corr\n",
    "    return df_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b234d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_pc1_loadings(df, features, n=10):\n",
    "    X = df[features].fillna(0).values\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(Xs)\n",
    "    load = pd.Series(pca.components_[0], index=features)\n",
    "    df_load = load.abs().sort_values(ascending=False).head(n).to_frame('abs_loading')\n",
    "    df_load['loading'] = load.loc[df_load.index]\n",
    "    return df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d9b289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _adaptive_inner_cv(y, target_splits=5):\n",
    "    \"\"\"Use 5 folds if every class has >=5 samples; otherwise back off to 3.\"\"\"\n",
    "    min_class = np.min(np.bincount(y))\n",
    "    n_splits = target_splits if min_class >= target_splits else 3\n",
    "    return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f720f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logregcv_l1(inner_cv):\n",
    "    \"\"\"Configured L1-Logistic with explicit C grid and ROC-AUC tuning.\"\"\"\n",
    "    C_grid = np.logspace(-4, 4, 30)\n",
    "    return LogisticRegressionCV(\n",
    "        Cs=C_grid, cv=inner_cv, penalty=\"l1\", solver=\"saga\",\n",
    "        scoring=\"roc_auc\", class_weight=\"balanced\",\n",
    "        max_iter=7500, random_state=42, refit=True, n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b21c9062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stratified_bootstrap(X, y, rng):\n",
    "    \"\"\"Per-class resample with replacement; preserves class balance.\"\"\"\n",
    "    Xb_list, yb_list = [], []\n",
    "    for cls in np.unique(y):\n",
    "        idx = np.where(y == cls)[0]\n",
    "        samp = rng.choice(idx, size=len(idx), replace=True)\n",
    "        Xb_list.append(X[samp])\n",
    "        yb_list.append(y[samp])\n",
    "    Xb = np.vstack(Xb_list)\n",
    "    yb = np.concatenate(yb_list)\n",
    "    perm = rng.permutation(len(yb))\n",
    "    return Xb[perm], yb[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c6aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_logistic_top(df, features, mask_g1, n=10):\n",
    "    X = df[features].fillna(0).values\n",
    "    y = mask_g1.astype(int).values\n",
    "\n",
    "    inner_cv = _adaptive_inner_cv(y, target_splits=5)\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", _logregcv_l1(inner_cv))\n",
    "    ])\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    coef = pd.Series(pipe.named_steps[\"clf\"].coef_[0], index=features)\n",
    "    top = coef.abs().sort_values(ascending=False).head(n).index\n",
    "    return pd.DataFrame({\"coef\": coef.loc[top]}).sort_values(\"coef\", key=np.abs, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69d67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_auc(df, features, mask_g1):\n",
    "    X = df[features].fillna(0).values\n",
    "    y = mask_g1.astype(int).values\n",
    "\n",
    "    inner_cv = _adaptive_inner_cv(y, target_splits=5)\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", _logregcv_l1(inner_cv))\n",
    "    ])\n",
    "\n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    auc_scores = cross_val_score(pipe, X, y, cv=outer_cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    return auc_scores.mean(), auc_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9941ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_stability(df, features, mask_g1, n_boot=100, tol=1e-6):\n",
    "    X = df[features].fillna(0).values\n",
    "    y = mask_g1.astype(int).values\n",
    "\n",
    "    inner_cv = _adaptive_inner_cv(y, target_splits=5)\n",
    "\n",
    "    sel_counts = pd.Series(0, index=features, dtype=float)\n",
    "    pos_counts = pd.Series(0, index=features, dtype=float)\n",
    "    coef_sum   = pd.Series(0.0, index=features)\n",
    "\n",
    "    rng = np.random.RandomState(1000)\n",
    "\n",
    "    for b in range(n_boot):\n",
    "        Xb, yb = _stratified_bootstrap(X, y, rng)\n",
    "        if len(np.unique(yb)) < 2:\n",
    "            continue  # extreme edge case, but safe-guard\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", _logregcv_l1(inner_cv))\n",
    "        ])\n",
    "        pipe.fit(Xb, yb)\n",
    "\n",
    "        coef = pd.Series(pipe.named_steps[\"clf\"].coef_[0], index=features)\n",
    "        selected = coef.abs() > tol\n",
    "\n",
    "        sel_counts[selected] += 1\n",
    "        pos_counts[selected & (coef > 0)] += 1\n",
    "        coef_sum += coef\n",
    "\n",
    "    stability = sel_counts / n_boot\n",
    "    sign_consistency = (pos_counts / sel_counts.replace(0, np.nan))\n",
    "    mean_coef = coef_sum / n_boot\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"sel_prop\": stability,\n",
    "        \"mean_coef\": mean_coef,\n",
    "        \"pos_sign_prop\": sign_consistency\n",
    "    }).sort_values([\"sel_prop\", \"mean_coef\"], ascending=False)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8414a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(x, y):\n",
    "    nx, ny = len(x), len(y)\n",
    "    sx, sy = np.std(x, ddof=1), np.std(y, ddof=1)\n",
    "    s_pooled = np.sqrt(((nx-1)*sx**2 + (ny-1)*sy**2) / (nx+ny-2))\n",
    "    return (np.mean(x) - np.mean(y)) / s_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c09f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_cohen_d(x, y):\n",
    "    return abs(cohen_d(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5cc0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(x, y, statfunc, n_boot=1000, ci=95):\n",
    "    boot_stats = []\n",
    "    for _ in range(n_boot):\n",
    "        bx = resample(x, replace=True)\n",
    "        by = resample(y, replace=True)\n",
    "        boot_stats.append(statfunc(bx, by))\n",
    "    lower = np.percentile(boot_stats, (100-ci)/2)\n",
    "    upper = np.percentile(boot_stats, 100-(100-ci)/2)\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "417875f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_priori_power(effect_size=0.6, alpha=0.05, power=0.8):\n",
    "    analysis = TTestIndPower()\n",
    "    return analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39da82a",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbdecb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LIWC dimensions |d| > 0.5:\n",
      "| feature   |   mean_g1 |   sd_g1 |   mean_g2 |   sd_g2 |   t_stat |   p_val |   bf10 |   cohen_d |   p_fdr | signif   |   abs_cohen_d |\n",
      "|:----------|----------:|--------:|----------:|--------:|---------:|--------:|-------:|----------:|--------:|:---------|--------------:|\n",
      "| funct     |     0.372 |   0.122 |     0.447 |   0.062 |   -2.842 |   0.009 |  7.342 |    -0.945 |   0.067 | False    |         0.945 |\n",
      "| cogmech   |     0.288 |   0.114 |     0.359 |   0.060 |   -2.849 |   0.009 |  7.461 |    -0.930 |   0.067 | False    |         0.930 |\n",
      "| pronoun   |     0.135 |   0.063 |     0.182 |   0.049 |   -3.277 |   0.003 | 21.884 |    -0.890 |   0.052 | False    |         0.890 |\n",
      "| ipron     |     0.088 |   0.046 |     0.121 |   0.038 |   -3.181 |   0.003 | 16.997 |    -0.834 |   0.052 | False    |         0.834 |\n",
      "| excl      |     0.033 |   0.024 |     0.053 |   0.025 |   -3.390 |   0.002 | 29.682 |    -0.782 |   0.052 | False    |         0.782 |\n",
      "| relativ   |     0.157 |   0.065 |     0.195 |   0.046 |   -2.607 |   0.014 |  4.318 |    -0.739 |   0.091 | False    |         0.739 |\n",
      "| space     |     0.072 |   0.045 |     0.105 |   0.045 |   -3.024 |   0.005 | 11.403 |    -0.723 |   0.059 | False    |         0.723 |\n",
      "| past      |     0.024 |   0.021 |     0.042 |   0.027 |   -3.348 |   0.002 | 26.494 |    -0.697 |   0.052 | False    |         0.697 |\n",
      "| ppron     |     0.094 |   0.049 |     0.125 |   0.045 |   -2.754 |   0.009 |  5.992 |    -0.686 |   0.067 | False    |         0.686 |\n",
      "| discrep   |     0.039 |   0.026 |     0.057 |   0.029 |   -2.902 |   0.006 |  8.465 |    -0.647 |   0.064 | False    |         0.647 |\n",
      "| tentat    |     0.059 |   0.046 |     0.081 |   0.034 |   -2.165 |   0.039 |  1.790 |    -0.602 |   0.137 | False    |         0.602 |\n",
      "| shehe     |     0.048 |   0.035 |     0.067 |   0.031 |   -2.310 |   0.027 |  2.349 |    -0.587 |   0.123 | False    |         0.587 |\n",
      "| you       |     0.052 |   0.036 |     0.073 |   0.038 |   -2.432 |   0.020 |  2.990 |    -0.564 |   0.098 | False    |         0.564 |\n",
      "| article   |     0.067 |   0.037 |     0.086 |   0.037 |   -2.213 |   0.033 |  1.956 |    -0.529 |   0.125 | False    |         0.529 |\n",
      "| nonfl     |     0.022 |   0.020 |     0.035 |   0.026 |   -2.507 |   0.016 |  3.492 |    -0.521 |   0.092 | False    |         0.521 |\n",
      "| preps     |     0.115 |   0.061 |     0.138 |   0.039 |   -1.717 |   0.097 |  0.860 |    -0.514 |   0.296 | False    |         0.514 |\n"
     ]
    }
   ],
   "source": [
    "# 1) Univariate LIWC\n",
    "uni = univariate_liwc(df, features, mask_women, mask_others)\n",
    "print(\"\\nLIWC dimensions |d| > 0.5:\")\n",
    "print(uni[uni['abs_cohen_d']>0.5].to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4149b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrap 95% CIs for Cohen's d (|d| > 0.5):\n",
      "| feature   |      d |   ci_lower |   ci_upper |\n",
      "|:----------|-------:|-----------:|-----------:|\n",
      "| funct     | -0.945 |     -1.493 |     -0.401 |\n",
      "| cogmech   | -0.930 |     -1.444 |     -0.442 |\n",
      "| pronoun   | -0.890 |     -1.425 |     -0.427 |\n",
      "| ipron     | -0.834 |     -1.385 |     -0.366 |\n",
      "| excl      | -0.782 |     -1.259 |     -0.356 |\n",
      "| relativ   | -0.739 |     -1.345 |     -0.209 |\n",
      "| space     | -0.723 |     -1.277 |     -0.308 |\n",
      "| past      | -0.697 |     -1.098 |     -0.319 |\n",
      "| ppron     | -0.686 |     -1.130 |     -0.249 |\n",
      "| discrep   | -0.647 |     -1.119 |     -0.243 |\n",
      "| tentat    | -0.602 |     -1.238 |     -0.046 |\n",
      "| shehe     | -0.587 |     -1.115 |     -0.103 |\n",
      "| you       | -0.564 |     -1.023 |     -0.120 |\n",
      "| article   | -0.529 |     -0.987 |     -0.109 |\n",
      "| nonfl     | -0.521 |     -0.996 |     -0.152 |\n",
      "| preps     | -0.514 |     -1.115 |      0.036 |\n"
     ]
    }
   ],
   "source": [
    "# 2) Bootstrap CIs for features with |d| > 0.5\n",
    "top_feats = uni[uni['abs_cohen_d'] > 0.5]['feature']\n",
    "ci_list = []\n",
    "for feat in top_feats:\n",
    "    x = df.loc[mask_women, feat].dropna().values\n",
    "    y = df.loc[mask_others, feat].dropna().values\n",
    "    d_obs = cohen_d(x, y)\n",
    "    lo, hi = bootstrap_ci(x, y, cohen_d, n_boot=2000, ci=95)\n",
    "    ci_list.append({'feature': feat, 'd': d_obs, 'ci_lower': lo, 'ci_upper': hi})\n",
    "ci_df = pd.DataFrame(ci_list)\n",
    "print(\"\\nBootstrap 95% CIs for Cohen's d (|d| > 0.5):\")\n",
    "print(ci_df.to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2251f9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Required N per group for d=0.6, α=0.05, 80% power: 44.6\n"
     ]
    }
   ],
   "source": [
    "# 3) A priori power\n",
    "req_n = a_priori_power(effect_size=0.6)\n",
    "print(f\"\\nRequired N per group for d=0.6, α=0.05, 80% power: {req_n:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1985951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LIWC dimensions |d| > 0.5:\n",
      "| feature   |   mean_g1 |   sd_g1 |   mean_g2 |   sd_g2 |   t_stat |   p_val |   bf10 |   cohen_d |   p_fdr | signif   |   abs_cohen_d |      N |\n",
      "|:----------|----------:|--------:|----------:|--------:|---------:|--------:|-------:|----------:|--------:|:---------|--------------:|-------:|\n",
      "| funct     |     0.372 |   0.122 |     0.447 |   0.062 |   -2.842 |   0.009 |  7.342 |    -0.945 |   0.067 | False    |         0.945 | 18.577 |\n",
      "| cogmech   |     0.288 |   0.114 |     0.359 |   0.060 |   -2.849 |   0.009 |  7.461 |    -0.930 |   0.067 | False    |         0.930 | 19.142 |\n",
      "| pronoun   |     0.135 |   0.063 |     0.182 |   0.049 |   -3.277 |   0.003 | 21.884 |    -0.890 |   0.052 | False    |         0.890 | 20.824 |\n",
      "| ipron     |     0.088 |   0.046 |     0.121 |   0.038 |   -3.181 |   0.003 | 16.997 |    -0.834 |   0.052 | False    |         0.834 | 23.561 |\n",
      "| excl      |     0.033 |   0.024 |     0.053 |   0.025 |   -3.390 |   0.002 | 29.682 |    -0.782 |   0.052 | False    |         0.782 | 26.682 |\n",
      "| relativ   |     0.157 |   0.065 |     0.195 |   0.046 |   -2.607 |   0.014 |  4.318 |    -0.739 |   0.091 | False    |         0.739 | 29.713 |\n",
      "| space     |     0.072 |   0.045 |     0.105 |   0.045 |   -3.024 |   0.005 | 11.403 |    -0.723 |   0.059 | False    |         0.723 | 31.006 |\n",
      "| past      |     0.024 |   0.021 |     0.042 |   0.027 |   -3.348 |   0.002 | 26.494 |    -0.697 |   0.052 | False    |         0.697 | 33.295 |\n",
      "| ppron     |     0.094 |   0.049 |     0.125 |   0.045 |   -2.754 |   0.009 |  5.992 |    -0.686 |   0.067 | False    |         0.686 | 34.333 |\n",
      "| discrep   |     0.039 |   0.026 |     0.057 |   0.029 |   -2.902 |   0.006 |  8.465 |    -0.647 |   0.064 | False    |         0.647 | 38.482 |\n",
      "| tentat    |     0.059 |   0.046 |     0.081 |   0.034 |   -2.165 |   0.039 |  1.790 |    -0.602 |   0.137 | False    |         0.602 | 44.304 |\n",
      "| shehe     |     0.048 |   0.035 |     0.067 |   0.031 |   -2.310 |   0.027 |  2.349 |    -0.587 |   0.123 | False    |         0.587 | 46.478 |\n",
      "| you       |     0.052 |   0.036 |     0.073 |   0.038 |   -2.432 |   0.020 |  2.990 |    -0.564 |   0.098 | False    |         0.564 | 50.286 |\n",
      "| article   |     0.067 |   0.037 |     0.086 |   0.037 |   -2.213 |   0.033 |  1.956 |    -0.529 |   0.125 | False    |         0.529 | 57.123 |\n",
      "| nonfl     |     0.022 |   0.020 |     0.035 |   0.026 |   -2.507 |   0.016 |  3.492 |    -0.521 |   0.092 | False    |         0.521 | 58.705 |\n",
      "| preps     |     0.115 |   0.061 |     0.138 |   0.039 |   -1.717 |   0.097 |  0.860 |    -0.514 |   0.296 | False    |         0.514 | 60.381 |\n",
      "\n",
      "Summary of required N per group:\n",
      "Highest N: 121005.1 (feature: sad)\n",
      "Lowest N: 18.6 (feature: funct)\n",
      "Mean N: 2866.7\n",
      "Median N: 219.0\n",
      "\n",
      "Summary of required N per group:\n",
      "Highest N: 60.4 (feature: preps)\n",
      "Mean N: 37.1\n",
      "Median N: 33.8\n"
     ]
    }
   ],
   "source": [
    "# 3.5) A priori power\n",
    "uni = univariate_liwc(df, features, mask_women, mask_others)\n",
    "\n",
    "# Compute required N for each effect size\n",
    "uni['N'] = uni['abs_cohen_d'].apply(lambda d: a_priori_power(effect_size=d) if d > 0 else np.nan)\n",
    "\n",
    "print(\"\\nLIWC dimensions |d| > 0.5:\")\n",
    "subset = uni[uni['abs_cohen_d']>0.5]\n",
    "print(subset.to_markdown(index=False, floatfmt=\".3f\"))\n",
    "\n",
    "# Summary statistics for N\n",
    "valid_n = uni['N'].dropna()\n",
    "print(f\"\\nSummary of required N per group:\")\n",
    "print(f\"Highest N: {valid_n.max():.1f} (feature: {uni.loc[uni['N'].idxmax(), 'feature']})\")\n",
    "print(f\"Lowest N: {valid_n.min():.1f} (feature: {uni.loc[uni['N'].idxmin(), 'feature']})\")\n",
    "print(f\"Mean N: {valid_n.mean():.1f}\")\n",
    "print(f\"Median N: {valid_n.median():.1f}\")\n",
    "\n",
    "# Summary statistics for N in d > 0.5\n",
    "valid_n = subset['N'].dropna()\n",
    "if len(valid_n) > 0:\n",
    "    print(f\"\\nSummary of required N per group:\")\n",
    "    print(f\"Highest N: {valid_n.max():.1f} (feature: {subset.loc[subset['N'].idxmax(), 'feature']})\")\n",
    "    print(f\"Mean N: {valid_n.mean():.1f}\")\n",
    "    print(f\"Median N: {valid_n.median():.1f}\")\n",
    "else:\n",
    "    print(\"\\nNo valid N values found for features with |d| > 0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "183582a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA group differences:\n",
      "| PC   |   expl_var |   t_stat |   p_val |   p_fdr |\n",
      "|:-----|-----------:|---------:|--------:|--------:|\n",
      "| PC1  |      0.149 |   -3.431 |   0.002 |   0.009 |\n",
      "| PC2  |      0.081 |    0.814 |   0.421 |   0.924 |\n",
      "| PC3  |      0.069 |   -0.242 |   0.811 |   0.924 |\n",
      "| PC4  |      0.062 |   -0.096 |   0.924 |   0.924 |\n",
      "| PC5  |      0.053 |    0.231 |   0.820 |   0.924 |\n"
     ]
    }
   ],
   "source": [
    "# 4) PCA group differences\n",
    "pc_res = pca_group_diff(df, features, mask_women, mask_others)\n",
    "print(\"\\nPCA group differences:\")\n",
    "print(pc_res.to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c499f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top PC1 loadings:\n",
      "|         |   loading |\n",
      "|:--------|----------:|\n",
      "| ipron   |     0.275 |\n",
      "| funct   |     0.274 |\n",
      "| pronoun |     0.274 |\n",
      "| nonfl   |     0.241 |\n",
      "| shehe   |     0.238 |\n",
      "| article |     0.237 |\n",
      "| social  |     0.230 |\n",
      "| you     |     0.224 |\n",
      "| ppron   |     0.221 |\n",
      "| cogmech |     0.220 |\n"
     ]
    }
   ],
   "source": [
    "# 5) PCA group differences\n",
    "pc1_ld = top_pc1_loadings(df, features, n=10)\n",
    "print(\"\\nTop PC1 loadings:\")\n",
    "print(pc1_ld[['loading']].to_markdown(floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47eb8fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 127)\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "df_sub = df[mask_women | mask_others]\n",
    "new_mask_women = (df_sub['sex']==\"Feminino\") & (df_sub['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "print(df_sub.shape)\n",
    "print(new_mask_women.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a101957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         |   coef |\n",
      "|:--------|-------:|\n",
      "| cogmech | -3.369 |\n",
      "| conj    |  2.188 |\n",
      "| certain |  1.839 |\n",
      "| pronoun | -1.531 |\n",
      "| auxverb |  1.448 |\n",
      "| assent  | -1.411 |\n",
      "| money   | -1.407 |\n",
      "| achieve | -1.303 |\n",
      "| filler  |  1.277 |\n",
      "| feel    |  1.255 |\n"
     ]
    }
   ],
   "source": [
    "top_coef = l1_logistic_top(df_sub, features, new_mask_women, n=10)\n",
    "print(top_coef.to_markdown(floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7482c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV AUC: mean=0.697, SD=0.160\n"
     ]
    }
   ],
   "source": [
    "mean_auc, sd_auc = nested_auc(df_sub, features, new_mask_women)\n",
    "print(f\"Nested CV AUC: mean={mean_auc:.3f}, SD={sd_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34726433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         |   sel_prop |   mean_coef |   pos_sign_prop |\n",
      "|:--------|-----------:|------------:|----------------:|\n",
      "| cogmech |      0.950 |      -1.766 |           0.000 |\n",
      "| conj    |      0.840 |       1.572 |           1.000 |\n",
      "| certain |      0.870 |       1.300 |           1.000 |\n",
      "| pronoun |      0.820 |      -0.954 |           0.000 |\n",
      "| auxverb |      0.660 |       1.025 |           1.000 |\n",
      "| assent  |      0.760 |      -0.751 |           0.013 |\n",
      "| money   |      0.650 |      -0.966 |           0.000 |\n",
      "| achieve |      0.820 |      -0.794 |           0.024 |\n",
      "| filler  |      0.720 |       0.775 |           0.944 |\n",
      "| feel    |      0.760 |       0.774 |           0.974 |\n"
     ]
    }
   ],
   "source": [
    "stab = l1_stability(df_sub, features, new_mask_women, n_boot=100)\n",
    "print(stab.loc[top_coef.index].to_markdown(floatfmt=\".3f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adhd-linguistic-patterns-beliefs-portuguese-women",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
