{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f601a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from pingouin import bayesfactor_ttest\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b173b38",
   "metadata": {},
   "source": [
    "## Women with ADHD vs. Men with ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa32460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/adhd-beliefs-pt/adhd-beliefs-pt-liwc-proportional.pkl\")\n",
    "mask_women = (df['sex']==\"Feminino\") & (df['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "mask_others = (df['sex']==\"Masculino\") & (df['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "features = df.columns[-64:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfd60a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women with ADHD: 23\n",
      "Men with ADHD: 10\n",
      "\n",
      "funct:\n",
      "  Women - min: 0.0000, max: 0.5029, std: 0.1222\n",
      "  Men - min: 0.3279, max: 0.5017, std: 0.0498\n",
      "\n",
      "pronoun:\n",
      "  Women - min: 0.0000, max: 0.2356, std: 0.0632\n",
      "  Men - min: 0.0984, max: 0.3125, std: 0.0587\n",
      "\n",
      "ppron:\n",
      "  Women - min: 0.0000, max: 0.1538, std: 0.0489\n",
      "  Men - min: 0.0656, max: 0.2500, std: 0.0540\n",
      "\n",
      "i:\n",
      "  Women - min: 0.0000, max: 0.1250, std: 0.0323\n",
      "  Men - min: 0.0000, max: 0.1250, std: 0.0345\n",
      "\n",
      "we:\n",
      "  Women - min: 0.0000, max: 0.0000, std: 0.0000\n",
      "  Men - min: 0.0000, max: 0.0000, std: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Check the size of women with ADHD group\n",
    "mask_women_len = mask_women.sum()\n",
    "print(f\"Women with ADHD: {mask_women_len}\")\n",
    "print(f\"Men with ADHD: {mask_others.sum()}\")\n",
    "\n",
    "# Check if any LIWC features have constant values (zero variance)\n",
    "for feat in features[:5]:  # Check first 5 features as example\n",
    "    g1 = df.loc[mask_women, feat].dropna()\n",
    "    g2 = df.loc[mask_others, feat].dropna()\n",
    "    print(f\"\\n{feat}:\")\n",
    "    print(f\"  Women - min: {g1.min():.4f}, max: {g1.max():.4f}, std: {g1.std():.4f}\")\n",
    "    print(f\"  Men - min: {g2.min():.4f}, max: {g2.max():.4f}, std: {g2.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9827e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['we'], errors='ignore')\n",
    "features.remove('we')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea845ca",
   "metadata": {},
   "source": [
    "## Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b7f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_liwc(df, features, mask_g1, mask_g2, alpha=0.05):\n",
    "    \"\"\"\n",
    "    For each LIWC feature:\n",
    "      - Welch’s t-test\n",
    "      - JZS Bayes factor\n",
    "      - Cohen’s d\n",
    "    Returns a DataFrame with p-values, BF10, d, FDR‐corrected p’s, etc.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for feat in features:\n",
    "        g1 = df.loc[mask_g1, feat].dropna()\n",
    "        g2 = df.loc[mask_g2, feat].dropna()\n",
    "        t_stat, p_val = stats.ttest_ind(g1, g2, equal_var=False)\n",
    "        n1, n2 = len(g1), len(g2)\n",
    "        bf10 = bayesfactor_ttest(t_stat, n1, n2, paired=False)\n",
    "        s1, s2 = g1.std(ddof=1), g2.std(ddof=1)\n",
    "        s_pool = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2)/(n1+n2-2))\n",
    "        d = (g1.mean() - g2.mean())/s_pool\n",
    "        rows.append({\n",
    "            'feature': feat,\n",
    "            'mean_g1': g1.mean(),\n",
    "            'sd_g1': s1,\n",
    "            'mean_g2': g2.mean(),\n",
    "            'sd_g2': s2,\n",
    "            't_stat': t_stat,\n",
    "            'p_val': p_val,\n",
    "            'bf10': bf10,\n",
    "            'cohen_d': d\n",
    "        })\n",
    "    df_res = pd.DataFrame(rows)\n",
    "    _, p_corr, _, _ = multipletests(df_res['p_val'], method='fdr_bh')\n",
    "    df_res['p_fdr'] = p_corr\n",
    "    df_res['signif'] = df_res['p_fdr'] <= alpha\n",
    "    df_res['abs_cohen_d'] = df_res['cohen_d'].abs()\n",
    "    return df_res.sort_values('abs_cohen_d', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ece417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_group_diff(df, features, mask_g1, mask_g2, n_pc=5, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Standardize LIWC features, run PCA, perform Welch’s t-test on each PC\n",
    "    Returns a DataFrame of PC, explained_variance, t_stat, p_val, p_fdr.\n",
    "    \"\"\"\n",
    "    X = df[features].fillna(0).values\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=n_pc)\n",
    "    pcs = pca.fit_transform(Xs)\n",
    "    rows = []\n",
    "    for i in range(n_pc):\n",
    "        comp = pcs[:, i]\n",
    "        t, p = stats.ttest_ind(comp[mask_g1], comp[mask_g2], equal_var=False)\n",
    "        rows.append({\n",
    "            'PC': f'PC{i+1}',\n",
    "            'expl_var': pca.explained_variance_ratio_[i],\n",
    "            't_stat':   t,\n",
    "            'p_val':    p\n",
    "        })\n",
    "    df_pc = pd.DataFrame(rows)\n",
    "    _, p_corr, _, _ = multipletests(df_pc['p_val'], method='fdr_bh')\n",
    "    df_pc['p_fdr'] = p_corr\n",
    "    return df_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b234d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_pc1_loadings(df, features, n=10):\n",
    "    X = df[features].fillna(0).values\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(Xs)\n",
    "    load = pd.Series(pca.components_[0], index=features)\n",
    "    df_load = load.abs().sort_values(ascending=False).head(n).to_frame('abs_loading')\n",
    "    df_load['loading'] = load.loc[df_load.index]\n",
    "    return df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f748e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _adaptive_inner_cv(y, target_splits=5):\n",
    "    \"\"\"Use 5 folds if every class has >=5 samples; otherwise back off to 3.\"\"\"\n",
    "    min_class = np.min(np.bincount(y))\n",
    "    n_splits = target_splits if min_class >= target_splits else 3\n",
    "    return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9264782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logregcv_l1(inner_cv):\n",
    "    \"\"\"Configured L1-Logistic with explicit C grid and ROC-AUC tuning.\"\"\"\n",
    "    C_grid = np.logspace(-4, 4, 30)\n",
    "    return LogisticRegressionCV(\n",
    "        Cs=C_grid, cv=inner_cv, penalty=\"l1\", solver=\"saga\",\n",
    "        scoring=\"roc_auc\", class_weight=\"balanced\",\n",
    "        max_iter=5000, random_state=42, refit=True, n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8257fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stratified_bootstrap(X, y, rng):\n",
    "    \"\"\"Per-class resample with replacement; preserves class balance.\"\"\"\n",
    "    Xb_list, yb_list = [], []\n",
    "    for cls in np.unique(y):\n",
    "        idx = np.where(y == cls)[0]\n",
    "        samp = rng.choice(idx, size=len(idx), replace=True)\n",
    "        Xb_list.append(X[samp])\n",
    "        yb_list.append(y[samp])\n",
    "    Xb = np.vstack(Xb_list)\n",
    "    yb = np.concatenate(yb_list)\n",
    "    perm = rng.permutation(len(yb))\n",
    "    return Xb[perm], yb[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc248db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_logistic_top(df, features, mask_g1, n=10):\n",
    "    X = df[features].fillna(0).values\n",
    "    y = mask_g1.astype(int).values\n",
    "\n",
    "    inner_cv = _adaptive_inner_cv(y, target_splits=5)\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", _logregcv_l1(inner_cv))\n",
    "    ])\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    coef = pd.Series(pipe.named_steps[\"clf\"].coef_[0], index=features)\n",
    "    top = coef.abs().sort_values(ascending=False).head(n).index\n",
    "    return pd.DataFrame({\"coef\": coef.loc[top]}).sort_values(\"coef\", key=np.abs, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "529f5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_auc(df, features, mask_g1):\n",
    "    X = df[features].fillna(0).values\n",
    "    y = mask_g1.astype(int).values\n",
    "\n",
    "    inner_cv = _adaptive_inner_cv(y, target_splits=5)\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", _logregcv_l1(inner_cv))\n",
    "    ])\n",
    "\n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    auc_scores = cross_val_score(pipe, X, y, cv=outer_cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    return auc_scores.mean(), auc_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe811f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_stability(df, features, mask_g1, n_boot=100, tol=1e-6):\n",
    "    X = df[features].fillna(0).values\n",
    "    y = mask_g1.astype(int).values\n",
    "\n",
    "    inner_cv = _adaptive_inner_cv(y, target_splits=5)\n",
    "\n",
    "    sel_counts = pd.Series(0, index=features, dtype=float)\n",
    "    pos_counts = pd.Series(0, index=features, dtype=float)\n",
    "    coef_sum   = pd.Series(0.0, index=features)\n",
    "\n",
    "    rng = np.random.RandomState(1000)\n",
    "\n",
    "    for b in range(n_boot):\n",
    "        Xb, yb = _stratified_bootstrap(X, y, rng)\n",
    "        if len(np.unique(yb)) < 2:\n",
    "            continue  # extreme edge case, but safe-guard\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", _logregcv_l1(inner_cv))\n",
    "        ])\n",
    "        pipe.fit(Xb, yb)\n",
    "\n",
    "        coef = pd.Series(pipe.named_steps[\"clf\"].coef_[0], index=features)\n",
    "        selected = coef.abs() > tol\n",
    "\n",
    "        sel_counts[selected] += 1\n",
    "        pos_counts[selected & (coef > 0)] += 1\n",
    "        coef_sum += coef\n",
    "\n",
    "    stability = sel_counts / n_boot\n",
    "    sign_consistency = (pos_counts / sel_counts.replace(0, np.nan))\n",
    "    mean_coef = coef_sum / n_boot\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"sel_prop\": stability,\n",
    "        \"mean_coef\": mean_coef,\n",
    "        \"pos_sign_prop\": sign_consistency\n",
    "    }).sort_values([\"sel_prop\", \"mean_coef\"], ascending=False)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8414a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(x, y):\n",
    "    nx, ny = len(x), len(y)\n",
    "    sx, sy = np.std(x, ddof=1), np.std(y, ddof=1)\n",
    "    s_pooled = np.sqrt(((nx-1)*sx**2 + (ny-1)*sy**2) / (nx+ny-2))\n",
    "    return (np.mean(x) - np.mean(y)) / s_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c09f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_cohen_d(x, y):\n",
    "    return abs(cohen_d(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5cc0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(x, y, statfunc, n_boot=1000, ci=95):\n",
    "    boot_stats = []\n",
    "    for _ in range(n_boot):\n",
    "        bx = resample(x, replace=True)\n",
    "        by = resample(y, replace=True)\n",
    "        boot_stats.append(statfunc(bx, by))\n",
    "    lower = np.percentile(boot_stats, (100-ci)/2)\n",
    "    upper = np.percentile(boot_stats, 100-(100-ci)/2)\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "417875f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_priori_power(effect_size=0.6, alpha=0.05, power=0.8):\n",
    "    analysis = TTestIndPower()\n",
    "    return analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39da82a",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbdecb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LIWC dimensions |d| > 0.5:\n",
      "| feature   |   mean_g1 |   sd_g1 |   mean_g2 |   sd_g2 |   t_stat |   p_val |   bf10 |   cohen_d |   p_fdr | signif   |   abs_cohen_d |\n",
      "|:----------|----------:|--------:|----------:|--------:|---------:|--------:|-------:|----------:|--------:|:---------|--------------:|\n",
      "| money     |     0.018 |   0.013 |     0.033 |   0.015 |   -2.660 |   0.017 |  4.328 |    -1.045 |   0.811 | False    |         1.045 |\n",
      "| assent    |     0.001 |   0.002 |     0.006 |   0.011 |   -1.335 |   0.213 |  0.683 |    -0.753 |   0.811 | False    |         0.753 |\n",
      "| ipron     |     0.088 |   0.046 |     0.119 |   0.036 |   -2.078 |   0.050 |  1.687 |    -0.717 |   0.811 | False    |         0.717 |\n",
      "| excl      |     0.033 |   0.024 |     0.046 |   0.014 |   -1.930 |   0.064 |  1.371 |    -0.604 |   0.811 | False    |         0.604 |\n",
      "| pronoun   |     0.135 |   0.063 |     0.171 |   0.059 |   -1.581 |   0.131 |  0.886 |    -0.582 |   0.811 | False    |         0.582 |\n",
      "| adverb    |     0.019 |   0.015 |     0.029 |   0.024 |   -1.187 |   0.258 |  0.596 |    -0.538 |   0.811 | False    |         0.538 |\n",
      "| space     |     0.072 |   0.045 |     0.093 |   0.018 |   -1.907 |   0.066 |  1.328 |    -0.533 |   0.811 | False    |         0.533 |\n",
      "| shehe     |     0.048 |   0.035 |     0.065 |   0.027 |   -1.540 |   0.138 |  0.846 |    -0.528 |   0.811 | False    |         0.528 |\n",
      "| you       |     0.052 |   0.036 |     0.071 |   0.037 |   -1.368 |   0.190 |  0.706 |    -0.526 |   0.811 | False    |         0.526 |\n"
     ]
    }
   ],
   "source": [
    "# 1) Univariate LIWC\n",
    "uni = univariate_liwc(df, features, mask_women, mask_others)\n",
    "print(\"\\nLIWC dimensions |d| > 0.5:\")\n",
    "print(uni[uni['abs_cohen_d']>0.5].to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "954bafdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrap 95% CIs for Cohen's d (|d| > 0.5):\n",
      "| feature   |      d |   ci_lower |   ci_upper |\n",
      "|:----------|-------:|-----------:|-----------:|\n",
      "| money     | -1.045 |     -1.852 |     -0.416 |\n",
      "| assent    | -0.753 |     -1.525 |      0.328 |\n",
      "| ipron     | -0.717 |     -1.313 |     -0.100 |\n",
      "| excl      | -0.604 |     -1.249 |      0.016 |\n",
      "| pronoun   | -0.582 |     -1.228 |      0.056 |\n",
      "| adverb    | -0.538 |     -1.306 |      0.304 |\n",
      "| space     | -0.533 |     -1.060 |     -0.034 |\n",
      "| shehe     | -0.528 |     -1.302 |      0.113 |\n",
      "| you       | -0.526 |     -1.338 |      0.219 |\n"
     ]
    }
   ],
   "source": [
    "# 2) Bootstrap CIs for features with |d| > 0.5\n",
    "top_feats = uni[uni['abs_cohen_d'] > 0.5]['feature']\n",
    "ci_list = []\n",
    "for feat in top_feats:\n",
    "    x = df.loc[mask_women, feat].dropna().values\n",
    "    y = df.loc[mask_others, feat].dropna().values\n",
    "    d_obs = cohen_d(x, y)\n",
    "    lo, hi = bootstrap_ci(x, y, cohen_d, n_boot=2000, ci=95)\n",
    "    ci_list.append({'feature': feat, 'd': d_obs, 'ci_lower': lo, 'ci_upper': hi})\n",
    "ci_df = pd.DataFrame(ci_list)\n",
    "print(\"\\nBootstrap 95% CIs for Cohen's d (|d| > 0.5):\")\n",
    "print(ci_df.to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2251f9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Required N per group for d=0.6, α=0.05, 80% power: 44.6\n"
     ]
    }
   ],
   "source": [
    "# 3) A priori power\n",
    "req_n = a_priori_power(effect_size=0.6)\n",
    "print(f\"\\nRequired N per group for d=0.6, α=0.05, 80% power: {req_n:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "183582a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA group differences:\n",
      "| PC   |   expl_var |   t_stat |   p_val |   p_fdr |\n",
      "|:-----|-----------:|---------:|--------:|--------:|\n",
      "| PC1  |      0.151 |   -1.944 |   0.061 |   0.306 |\n",
      "| PC2  |      0.082 |   -0.103 |   0.919 |   0.919 |\n",
      "| PC3  |      0.070 |   -0.149 |   0.883 |   0.919 |\n",
      "| PC4  |      0.063 |    0.168 |   0.867 |   0.919 |\n",
      "| PC5  |      0.054 |    0.206 |   0.838 |   0.919 |\n"
     ]
    }
   ],
   "source": [
    "# 4) PCA group differences\n",
    "pc_res = pca_group_diff(df, features, mask_women, mask_others)\n",
    "print(\"\\nPCA group differences:\")\n",
    "print(pc_res.to_markdown(index=False, floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c499f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top PC1 loadings:\n",
      "|         |   loading |\n",
      "|:--------|----------:|\n",
      "| ipron   |     0.275 |\n",
      "| funct   |     0.274 |\n",
      "| pronoun |     0.274 |\n",
      "| nonfl   |     0.241 |\n",
      "| shehe   |     0.238 |\n",
      "| article |     0.237 |\n",
      "| social  |     0.230 |\n",
      "| you     |     0.224 |\n",
      "| ppron   |     0.220 |\n",
      "| cogmech |     0.220 |\n"
     ]
    }
   ],
   "source": [
    "# 5) PCA group differences\n",
    "pc1_ld = top_pc1_loadings(df, features, n=10)\n",
    "print(\"\\nTop PC1 loadings:\")\n",
    "print(pc1_ld[['loading']].to_markdown(floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c1e52b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 126)\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "df_sub = df[mask_women | mask_others]\n",
    "new_mask_women = (df_sub['sex']==\"Feminino\") & (df_sub['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "print(df_sub.shape)\n",
    "print(new_mask_women.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa7ead45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         |   coef |\n",
      "|:--------|-------:|\n",
      "| money   | -0.361 |\n",
      "| assent  | -0.013 |\n",
      "| adverb  | -0.004 |\n",
      "| i       |  0.000 |\n",
      "| you     |  0.000 |\n",
      "| pronoun |  0.000 |\n",
      "| funct   |  0.000 |\n",
      "| they    |  0.000 |\n",
      "| ipron   |  0.000 |\n",
      "| verb    |  0.000 |\n"
     ]
    }
   ],
   "source": [
    "top_coef = l1_logistic_top(df_sub, features, new_mask_women, n=10)\n",
    "print(top_coef.to_markdown(floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b0efd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested CV AUC: mean=0.500, SD=0.215\n"
     ]
    }
   ],
   "source": [
    "mean_auc, sd_auc = nested_auc(df_sub, features, new_mask_women)\n",
    "print(f\"Nested CV AUC: mean={mean_auc:.3f}, SD={sd_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c560de8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         |   sel_prop |   mean_coef |   pos_sign_prop |\n",
      "|:--------|-----------:|------------:|----------------:|\n",
      "| money   |      0.770 |      -0.838 |           0.000 |\n",
      "| assent  |      0.620 |      -0.170 |           0.081 |\n",
      "| adverb  |      0.470 |      -0.317 |           0.000 |\n",
      "| i       |      0.130 |       0.016 |           0.769 |\n",
      "| you     |      0.310 |      -0.227 |           0.032 |\n",
      "| pronoun |      0.150 |      -0.107 |           0.133 |\n",
      "| funct   |      0.070 |      -0.001 |           0.429 |\n",
      "| they    |      0.250 |       0.163 |           0.680 |\n",
      "| ipron   |      0.380 |      -0.269 |           0.026 |\n",
      "| verb    |      0.090 |      -0.002 |           0.444 |\n"
     ]
    }
   ],
   "source": [
    "stab = l1_stability(df_sub, features, new_mask_women, n_boot=100)\n",
    "print(stab.loc[top_coef.index].to_markdown(floatfmt=\".3f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adhd-linguistic-patterns-beliefs-portuguese-women",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
