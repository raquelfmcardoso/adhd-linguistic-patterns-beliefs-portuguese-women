{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import pingouin as pg\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.utils import resample\n",
    "import scikit_posthocs as sp\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb627164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/adhd-beliefs-pt/adhd-beliefs-pt-liwc-proportional.pkl\")\n",
    "features = df.columns[-64:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22888022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data & groups\n",
    "df['group'] = (\n",
    "    df['sex'].map({'Feminino':'Female','Masculino':'Male'}).astype(str) + '_' +\n",
    "    np.where(df['adhd_diagnosis']==\"Sim, diagnosticado\", 'ADHD',\n",
    "        np.where(df['adhd_diagnosis'].isin([\"Suspeito que tenho\", \"Estou em processo de diagnóstico\"]), 'SuspectADHD', 'noADHD')\n",
    "    )\n",
    ")\n",
    "groups = df['group'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of participants in each group\n",
    "group_counts = df['group'].value_counts()\n",
    "print(\"Group counts:\")\n",
    "print(group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Welch ANOVA\n",
    "def perm_anova_F(feat, group_col='group', n_perm=5000):\n",
    "    obs = pg.welch_anova(dv=feat, between=group_col, data=df)\n",
    "    f_obs = obs.at[0, 'F']\n",
    "    perm_F = []\n",
    "    for _ in range(n_perm):\n",
    "        shuffled = np.random.permutation(df[group_col].values)\n",
    "        perm_df = df.assign(__grp=shuffled)\n",
    "        res = pg.welch_anova(dv=feat, between='__grp', data=perm_df)\n",
    "        perm_F.append(res.at[0, 'F'])\n",
    "    p_perm = (np.sum(np.array(perm_F) >= f_obs) + 1) / (n_perm + 1)\n",
    "    return f_obs, p_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4656cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omnibus tests per feature\n",
    "omni_rows = []\n",
    "for feat in features:\n",
    "    # a) Covariate‐adjusted ANOVA\n",
    "    null = smf.ols(f\"{feat} ~ age + C(education) + word_count\", data=df).fit()\n",
    "    full = smf.ols(f\"{feat} ~ C(group) + age + C(education) + word_count\", data=df).fit()\n",
    "    an3 = anova_lm(full, typ=3)\n",
    "    F_adj = an3.loc['C(group)', 'F']\n",
    "    p_raw = an3.loc['C(group)', 'PR(>F)']\n",
    "    # b) Permutation\n",
    "    _, p_perm = perm_anova_F(feat)\n",
    "    # c) Kruskal–Wallis\n",
    "    samples = [g[feat].dropna() for _, g in df.groupby('group')]\n",
    "    H, p_kw = stats.kruskal(*samples)\n",
    "    # d) Bayes factor via BIC\n",
    "    bf10 = np.exp((null.bic - full.bic) / 2)\n",
    "    omni_rows.append({\n",
    "        'feature': feat, 'F_adj': F_adj, 'p_adj_raw': p_raw,\n",
    "        'p_perm': p_perm, 'H': H, 'p_kw': p_kw, 'BF10': bf10\n",
    "    })\n",
    "omni_df = pd.DataFrame(omni_rows)\n",
    "omni_df['p_adj_fdr'] = multipletests(omni_df['p_adj_raw'], method='fdr_bh')[1]\n",
    "omni_df['p_kw_fdr']  = multipletests(omni_df['p_kw'],      method='fdr_bh')[1]\n",
    "omni_df = omni_df.sort_values('p_adj_raw')\n",
    "# Keep top 5 for post‐hoc\n",
    "top5 = omni_df.head(5)['feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omnibus summary (top 5 features)\n",
    "print(\"=== Omnibus ANOVA (top 5) ===\")\n",
    "print(omni_df[['feature','F_adj','p_adj_raw','p_adj_fdr','p_perm','BF10']].head(5).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residualize features\n",
    "resid_df = df.copy()\n",
    "for feat in features:\n",
    "    m = smf.ols(f\"{feat} ~ age + C(education) + word_count\", data=df).fit()\n",
    "    resid_df[feat] = m.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e44a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Games–Howell contrasts & effect sizes for top features\n",
    "def hedges_g(x, y):\n",
    "    nx, ny = len(x), len(y)\n",
    "    sx, sy = x.std(ddof=1), y.std(ddof=1)\n",
    "    s_p = np.sqrt(((nx-1)*sx**2 + (ny-1)*sy**2)/(nx+ny-2))\n",
    "    g = (x.mean() - y.mean())/s_p\n",
    "    return g*(1 - 3/(4*(nx+ny)-9))\n",
    "\n",
    "def bootstrap_ci(x, y, statfunc, n_boot=2000, ci=95):\n",
    "    vals = []\n",
    "    # precompute arrays\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    nx, ny = len(x), len(y)\n",
    "    for _ in range(n_boot):\n",
    "        idx_x = np.random.randint(0, nx, size=nx)    # bootstrap indices for x\n",
    "        idx_y = np.random.randint(0, ny, size=ny)    # bootstrap indices for y\n",
    "        bx = x[idx_x]\n",
    "        by = y[idx_y]\n",
    "        vals.append(statfunc(bx, by))\n",
    "    lower = np.percentile(vals, (100-ci)/2)\n",
    "    upper = np.percentile(vals, 100-(100-ci)/2)\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c40ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(combinations(groups, 2))\n",
    "posthoc = {}\n",
    "for feat in top5:\n",
    "    gh = pg.pairwise_gameshowell(dv=feat, between='group', data=resid_df)\n",
    "    gh['p_fdr'] = multipletests(gh['pval'], method='fdr_bh')[1]\n",
    "    es = []\n",
    "    for A, B in pairs:\n",
    "        x = resid_df.loc[resid_df.group == A, feat].dropna().values\n",
    "        y = resid_df.loc[resid_df.group == B, feat].dropna().values\n",
    "        g = hedges_g(x, y)\n",
    "        lo, hi = bootstrap_ci(x, y, hedges_g)\n",
    "        es.append({'A': A, 'B': B, 'g': g, 'ci_lower': lo, 'ci_upper': hi})\n",
    "    posthoc[feat] = {'games_howell': gh, 'effect_sizes': pd.DataFrame(es)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a23a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc Games-Howell and effect sizes\n",
    "for feat in top5:\n",
    "    print(f\"=== Post-hoc for {feat} ===\")\n",
    "    print(\"Games-Howell:\")\n",
    "    print(posthoc[feat]['games_howell'][['A','B','T','pval','p_fdr']].round(3).to_markdown(index=False))\n",
    "    print(\"Effect sizes (Hedges' g + 95% CI):\")\n",
    "    print(posthoc[feat]['effect_sizes'].round(3).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85781e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dunn’s test on residuals\n",
    "dunn_tests = {}\n",
    "for feat in top5:\n",
    "    dunn = sp.posthoc_dunn(resid_df, val_col=feat, group_col='group', p_adjust='fdr_bh')\n",
    "    dunn_tests[feat] = dunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d644e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dunn's tests\n",
    "print(\"=== Dunn's tests ===\")\n",
    "for feat in top5:\n",
    "    print(f\"Dunn's for {feat}:\")\n",
    "    print(dunn_tests[feat].round(3).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption checks\n",
    "def assumption_checks(feature):\n",
    "    samples = [df[df.group == g][feature].dropna() for g in groups]\n",
    "    levene_p = stats.levene(*samples, center='median').pvalue\n",
    "    model = smf.ols(f\"{feature} ~ C(group) + age + C(education) + word_count\", data=df).fit()\n",
    "    shapiro_p = stats.shapiro(model.resid)[1]\n",
    "    infl = OLSInfluence(model)\n",
    "    cooks = infl.cooks_distance[0]\n",
    "    n_high = np.sum(cooks > 4/len(df))\n",
    "    return {'levene_p': levene_p, 'shapiro_p': shapiro_p, 'n_high_cook': n_high}\n",
    "assump = {feat: assumption_checks(feat) for feat in top5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e0596",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Assumption Checks (top features) ===\")\n",
    "for feat, res in assump.items():\n",
    "    print(f\"{feat}: Levene p={res['levene_p']:.3f}, Shapiro p={res['shapiro_p']:.3f}, High Cook's={res['n_high_cook']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANOVA\n",
    "# Use formula interface to treat 'group' as categorical automatically\n",
    "formula = ' + '.join(features) + ' ~ group'\n",
    "# statsmodels MANOVA supports from_formula\n",
    "man = MANOVA.from_formula(formula, data=df)\n",
    "manova_res = man.mv_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32076856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANOVA result summary\n",
    "print(\"=== MANOVA ===\")\n",
    "print(manova_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canonical variates & discriminant analysis\n",
    "# Prepare data for LDA: drop missing and covariates\n",
    "X = df[features].dropna()\n",
    "y = df.loc[X.index, 'group']\n",
    "\n",
    "# Fit LDA with up to min(n_classes-1, n_features) components\n",
    "lda = LDA(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# Append to DataFrame for plotting\n",
    "df_lda = pd.DataFrame(X_lda, columns=['LD1','LD2'], index=X.index)\n",
    "df_lda['group'] = y\n",
    "\n",
    "# Scatter plot of first two canonical axes\n",
    "plt.figure(figsize=(8,6))\n",
    "for grp in df_lda['group'].unique():\n",
    "    subset = df_lda[df_lda['group']==grp]\n",
    "    plt.scatter(subset['LD1'], subset['LD2'], label=grp, alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('LDA: First two linear discriminants')\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature loadings on discriminants\n",
    "# sklearn LDA uses `scalings_` for linear discriminants (n_features x n_components)\n",
    "scalings = pd.DataFrame(lda.scalings_[:, :2], index=features, columns=['LD1','LD2'])\n",
    "# Sort to find top contributors by absolute weight\n",
    "top_ld1 = scalings['LD1'].abs().sort_values(ascending=False).head(10)\n",
    "top_ld2 = scalings['LD2'].abs().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53262316",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Feature scalings on discriminants ===\")\n",
    "print('Top 10 features loading on LD1:')\n",
    "print(scalings.loc[top_ld1.index, 'LD1'])\n",
    "print('Top 10 features loading on LD2:')\n",
    "print(scalings.loc[top_ld2.index, 'LD2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained = lda.explained_variance_ratio_\n",
    "print(f\"Explained variance by LD1: {explained[0]:.2%}\")\n",
    "print(f\"Explained variance by LD2: {explained[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=5)\n",
    "df_pca = df.dropna(subset=features)\n",
    "pcs = pca.fit_transform(df_pca[features])\n",
    "for i in range(5): df_pca[f'PC{i+1}'] = pcs[:, i]\n",
    "pc_anovas = {f'PC{i+1}': pg.welch_anova(dv=f'PC{i+1}', between='group', data=df_pca) for i in range(5)}\n",
    "pc1_anova = pc_anovas['PC1']\n",
    "pc2_anova = pc_anovas['PC2']\n",
    "pc3_anova = pc_anovas['PC3']\n",
    "pc4_anova = pc_anovas['PC4']\n",
    "pc5_anova = pc_anovas['PC5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25134838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA -> PC1 ANOVA\n",
    "print(\"=== PCA PC1 ANOVA ===\")\n",
    "print(pc1_anova)\n",
    "print(\"=== PCA PC2 ANOVA ===\")\n",
    "print(pc2_anova)\n",
    "print(\"=== PCA PC3 ANOVA ===\")\n",
    "print(pc3_anova)\n",
    "print(\"=== PCA PC4 ANOVA ===\")\n",
    "print(pc4_anova)\n",
    "print(\"=== PCA PC5 ANOVA ===\")\n",
    "print(pc5_anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef92c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained = pca.explained_variance_ratio_\n",
    "for i, var in enumerate(explained, 1):\n",
    "    print(f\"PC{i}: {var:.2%} of total variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.DataFrame(pca.components_.T, index=features,\n",
    "                        columns=[f\"PC{i}\" for i in range(1,6)])\n",
    "for i in range(1, 6):\n",
    "    print(f\"Top contributors to PC{i}:\")\n",
    "    print(loadings[f'PC{i}'].abs().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='group', y='PC1', data=df_pca)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"PC1 scores by group\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bdfdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df_pca.join(df_lda[['LD1']])\n",
    "r, p = pearsonr(merged['PC1'], merged['LD1'])\n",
    "print(f\"PC1 vs. LD1: r={r:.2f}, p={p:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.copy()\n",
    "print(df_numeric['education'].unique())\n",
    "edu_map = {'Ensino secundário': 1, 'Licenciatura': 2, 'Pós-Graduação': 3, 'Mestrado': 4, 'Doutoramento': 5}\n",
    "df_numeric['education'] = df_numeric['education'].map(edu_map).astype(int)\n",
    "print(df_numeric['education'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ff890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank ANCOVA\n",
    "df_rank = df_numeric.copy()\n",
    "rank_ancova = {}\n",
    "for feat in features:\n",
    "    # rank-transform feature\n",
    "    df_rank[f'{feat}_rank'] = df_rank[feat].rank()\n",
    "    res = pg.ancova(data=df_rank, dv=f'{feat}_rank', covar=['age','education','word_count'], between='group')\n",
    "    rank_ancova[feat] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f818639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank-ANCOVA on top features\n",
    "print(\"=== Rank-based ANCOVA (top features) ===\")\n",
    "for feat in top5:\n",
    "    print(f\"{feat}:\")\n",
    "    print(rank_ancova[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444aca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals Visualizations\n",
    "def plot_residuals(feat):\n",
    "    mdl = smf.ols(f\"{feat} ~ age + C(education) + word_count\", data=df).fit()\n",
    "    resid = mdl.resid\n",
    "    plt.figure()\n",
    "    sns.violinplot(x=df['group'], y=resid, inner='quartile')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for feat in top5[:3]:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    mdl = smf.ols(f\"{feat} ~ age + C(education) + word_count\", data=df).fit()\n",
    "    resid = mdl.resid\n",
    "    sns.violinplot(x=df['group'], y=resid, inner='quartile', hue=df['group'], palette='Set2', legend=False)\n",
    "    sns.stripplot(x=df['group'], y=resid, color='k', alpha=0.3, jitter=0.2, size=2)\n",
    "    plt.title(f\"Residuals of {feat} by group\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(f\"{feat} (residual)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap ANCOVA F CI\n",
    "def bootstrap_ancova(feat, n_boot=1000):\n",
    "    Fs = []\n",
    "    df_bsa = df_numeric.copy()\n",
    "    for _ in range(n_boot):\n",
    "        samp = df_bsa.sample(frac=1, replace=True)\n",
    "        mod = smf.ols(f\"{feat} ~ C(group) + age + education + word_count\", data=samp).fit()\n",
    "        Fs.append(anova_lm(mod, typ=3).loc['C(group)', 'F'])\n",
    "    return np.percentile(Fs, [2.5, 97.5])\n",
    "ci_boot = {feat: bootstrap_ancova(feat) for feat in top5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Bootstrap ANCOVA F 95% CI ===\")\n",
    "for feat, ci in ci_boot.items():\n",
    "    print(f\"{feat}: {ci[0]:.2f} to {ci[1]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adhd-linguistic-patterns-beliefs-portuguese-women",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
