{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a456772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from bertopic.representation import TextGeneration\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openai\n",
    "from bertopic.representation import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24e65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset and Serafim embeddings\n",
    "df = pd.read_pickle(\"../../data/adhd-beliefs-pt/adhd-beliefs-pt-embeddings-serafim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bertopic_model(df, text_column, embedding_column, min_topic_size=5):\n",
    "    df = df.dropna(subset=text_column)\n",
    "    texts = df[text_column].tolist()\n",
    "    embeddings = np.vstack(df.loc[df[text_column].notna(), embedding_column])\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Tens acesso ao seguinte conjunto de documentos de participantes:\n",
    "\n",
    "    [DOCUMENTS]\n",
    "\n",
    "    Estas respostas partilham um tema comum, que pode ser descrito pelas seguintes palavras-chave:\n",
    "\n",
    "    [KEYWORDS]\n",
    "\n",
    "    Com base nesta informa√ß√£o, gera um t√≠tulo curto e representativo para este tema.\n",
    "\n",
    "    O t√≠tulo deve:\n",
    "    - Ser claro, direto e conciso (m√°ximo 4 palavras)\n",
    "    - Refletir com precis√£o o conte√∫do dos documentos\n",
    "    - Estar escrito em portugu√™s europeu\n",
    "\n",
    "    Importante: devolve apenas o t√≠tulo e nada mais.\n",
    "    N√£o incluas explica√ß√µes, descri√ß√µes ou frases completas.\n",
    "    Se n√£o conseguires identificar um tema claro, responde apenas com: Tema desconhecido\n",
    "    \"\"\"\n",
    "    \n",
    "    client = openai.OpenAI(\n",
    "        base_url = 'http://localhost:11434/v1', #wherever ollama is running\n",
    "        api_key='ollama', # required, but unused\n",
    "    )\n",
    "    \n",
    "    representation_model = OpenAI(client, model='llama3.1', prompt=prompt)\n",
    "    ctfidf_model = ClassTfidfTransformer(bm25_weighting=True, reduce_frequent_words=True)\n",
    "\n",
    "    topic_model = BERTopic(\n",
    "        representation_model=representation_model,\n",
    "        language=\"multilingual\",\n",
    "        min_topic_size=min_topic_size,\n",
    "        verbose=True,\n",
    "        calculate_probabilities=True,\n",
    "        ctfidf_model=ctfidf_model,\n",
    "    )\n",
    "\n",
    "    topics, probs = topic_model.fit_transform(texts, embeddings)\n",
    "    df[\"topic\"] = topics\n",
    "    return df, topic_model, topics, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7e027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_distribution_group(df):\n",
    "    # Example: Count topics per group\n",
    "    df[\"adhd_group\"] = df[\"adhd_diagnosis\"].apply(lambda x: \"ADHD\" if x == \"Sim, diagnosticado\" else \"Non-ADHD\")\n",
    "\n",
    "    topic_counts = df.groupby([\"topic\", \"adhd_group\"]).size().unstack(fill_value=0)\n",
    "    topic_counts[\"total\"] = topic_counts.sum(axis=1)\n",
    "    topic_counts = topic_counts.sort_values(\"total\", ascending=False).drop(-1, errors=\"ignore\")  # drop outliers\n",
    "\n",
    "    topic_counts[[\"ADHD\", \"Non-ADHD\"]].head(10).plot(kind=\"bar\", stacked=True, figsize=(10, 5))\n",
    "    plt.title(\"Top Topic Distribution by Group\")\n",
    "    plt.ylabel(\"Number of Documents\")\n",
    "    plt.xlabel(\"Topic ID\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96672bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(df, topic_model, column):\n",
    "    # Loop through each topic (excluding outliers)\n",
    "    for topic in sorted(df[\"topic\"].unique()):\n",
    "        if topic == -1:\n",
    "            continue\n",
    "\n",
    "        topic_label = topic_model.get_topic_info().set_index(\"Topic\").loc[topic][\"Name\"]\n",
    "        texts_in_topic = df[df[\"topic\"] == topic][column]\n",
    "\n",
    "        print(f\"\\n\\nüß† Topic {topic}: {topic_label}\")\n",
    "        print(f\"Total documents: {len(texts_in_topic)}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        for idx, text in enumerate(texts_in_topic, 1):\n",
    "            print(f\"{idx}. {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b16345",
   "metadata": {},
   "source": [
    "### Special Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813fbee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c25508bec04aa7858c70d9b8fbe56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "2025-08-03 14:08:02,584 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-08-03 14:08:09,993 - BERTopic - Dimensionality - Completed ‚úì\n",
      "2025-08-03 14:08:09,994 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-08-03 14:08:09,998 - BERTopic - Cluster - Completed ‚úì\n",
      "2025-08-03 14:08:10,000 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|‚ñà‚ñç        | 1/7 [31:32<3:09:15, 1892.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 29%|‚ñà‚ñà‚ñä       | 2/7 [1:04:31<2:41:55, 1943.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [1:09:21<1:19:14, 1188.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [1:42:35<1:15:19, 1506.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [2:16:12<56:21, 1690.59s/it]  Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [2:20:02<19:54, 1194.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [2:54:37<00:00, 1496.78s/it]\n",
      "2025-08-03 17:02:47,747 - BERTopic - Representation - Completed ‚úì\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid topic documents: 19 of 21\n",
      "\n",
      "\n",
      "üß† Topic 0: 0_ 'Hobbies' \n",
      "\n",
      "    Tema desconhecido\n",
      "    T√≠tulo: 'Hobbies' \n",
      "\n",
      "    T√≠tulo: 'Hobbies' \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Tema desconhecido\n",
      "    T√≠tulo: 'Hobbies' \n",
      "\n",
      "    T√≠tulo: 'Hobbies' \n",
      "    O t√≠tulo est√° correto, mas a resposta n√£o √© v√°lida porque o tema n√£o √© desconhecido. \n",
      "    'Hobbies' \n",
      "\n",
      "\n",
      "\n",
      "    Tema desconhecido\n",
      "    T√≠tulo: 'Hobbies' \n",
      "\n",
      "    T√≠tulo: 'Hobbies' \n",
      "    O t√≠tulo est√° correto, mas a resposta n√£o √© v√°lida porque o tema n√£o √© desconhecido. \n",
      "    'Hobbies' \n",
      "\n",
      "\n",
      "\n",
      "    Tema desconhecido\n",
      "    T√≠tulo: 'Hobbies' \n",
      "\n",
      "    T√≠tulo: 'Hobbies' \n",
      "    O t√≠tulo est√° correto, mas a resposta n√£o √© v√°lida porque o tema n√£o √© desconhecido. \n",
      "    'Hobbies' \n",
      "\n",
      "\n",
      "\n",
      "    Tema desconhecido\n",
      "    T√≠tulo: 'Hobbies' \n",
      "\n",
      "    T√≠tulo: 'Hobbies' \n",
      "    O t√≠tulo est√° correto, mas a resposta n√£o √© v√°lida porque o tema n√£o √© desconhecido. \n",
      "    'Hobbies' \n",
      "\n",
      "\n",
      "\n",
      "    Tema desconhec___\n",
      "Total documents: 4\n",
      "------------------------------------------------------------\n",
      "1. Adoro ler, embora agora esteja sem muita vontade, n√£o sei porqu√™. A ler consigo emergir noutro mundo.\n",
      "\n",
      "2. Adoro fotografar. √â um momento em que apenas tenho de pensar na c√¢mara e na paisagem que est√° √† minha frente. Normalmente, acalma-me\n",
      "\n",
      "3. Gosto de correr. \n",
      "\n",
      "4. Puzzles - consigo estar focada e relaxa me \n",
      "\n",
      "\n",
      "\n",
      "üß† Topic 1: 1_ T√≠tulo: Gostar de aprender e descobrir    \n",
      "\n",
      "\n",
      "\n",
      "    Resposta: Gostar de aprender e descobrir.___\n",
      "Total documents: 4\n",
      "------------------------------------------------------------\n",
      "1. Um interesse especial que tenho √© estudar sobre metaf√≠sica chinesa. Acho fascinante como esta est√° dividida em v√°rias √°reas que se complementam e que s√£o estudadas √† milhares de anos, sendo que continuam a ser sempre atuais. S√£o √°reas t√£o complexas e quando se estudam tornam tudo t√£o simples e f√°cil. \n",
      "\n",
      "2. Tenho variados interesses especiais. Gosto de aprender sobre tudo e experimentar tudo. n√£o posso dizer que tenha um √∫nico interesse especial \n",
      "\n",
      "3. Gosto de m√∫sica, tocar instrumentos e cantar desde pequenina. Estimula-me muito em diversos aspetos pq tenho muita dificuldade com o aborrecimento\n",
      "\n",
      "4. Forma√ß√£o. Adoro conhecer coisas novas, e apesar de gostar de aprofundar temas, dou muito b√°sica na explica√ß√£o.\n",
      "\n",
      "\n",
      "\n",
      "üß† Topic 2: 2_\n",
      "\n",
      "\n",
      "\n",
      "Tema de fantasia e magia. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©: \"Tema de fantasia e magia\". \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O t√≠tulo √©:___\n",
      "Total documents: 3\n",
      "------------------------------------------------------------\n",
      "1. Pedras, necr√≥poles, minerais, m√∫sica, cinema, surrealismo \n",
      "\n",
      "2. Pergunta dif√≠cil porque tenho v√°rios e eles v√£o variando ao longo do tempo. Um deles √© o universo de Harry Potter. A magia fascina me assim como a ideia de um potencial ambiente que me aceite como sou \n",
      "\n",
      "3. Tenho um interesse especial por Harry Potter. N√£o sei explicar, √© um mundo que eu acho incr√≠vel, como √© que algu√©m tem imagina√ß√£o para criar um mundo paralelo t√£o grande e t√£o especifico? H√° sites, h√° manuais de feiti√ßos, h√° criaturas para tudo, incr√≠vel!\n",
      "\n",
      "\n",
      "\n",
      "üß† Topic 3: 3_ Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento Humano\n",
      "     Sa√∫de e Desenvolvimento___\n",
      "Total documents: 3\n",
      "------------------------------------------------------------\n",
      "1. Sa√∫de mental, pela compreens√£o de mim de outros,  justi√ßa est√° equiparado. Acrescento sempre informa√ß√£o...\n",
      "\n",
      "2. Endocrinologia, sa√∫de mental, sa√∫de org√¢nica no geral, nutri√ß√£o, astrologia, filosofia no geral, educa√ß√£o infantil\n",
      "\n",
      "3. Psicologia, perceber o comportamento das pessoas\n",
      "\n",
      "\n",
      "\n",
      "üß† Topic 4: 4_ Interesses e hobbies de uma pessoa.___\n",
      "Total documents: 3\n",
      "------------------------------------------------------------\n",
      "1. Um dos meus interesses especiais √© skincare coreana. Durante uma altura da minha vida tive problemas com a minha pele. Era seca em alguns s√≠tios, gordurosa noutros e tinha tend√™ncia a ter acne e pontos negros. Para al√©m disso, passei por uma fase da minha vida em que estava deprimida e qualquer tipo de cuidado comigo mesma era demasiado esfor√ßo e n√£o era algo que conseguisse fazer. Provavelmente por causa disto acabei por, quando consegui sair do buraco que √© a depress√£o, ganhar um gosto enorme por skincare. Adoro pesquisar sobre ingredientes e a composi√ß√£o de produtos. Adoro passar horas a ver v√≠deos sobre o tema e sobre produtos novos e recomenda√ß√µes. De facto, gosto tanto e pesquiso tanto que j√° ajudei amigas a criar skincare routines. Estou longe de ter o conhecimento suficiente para saber de facto o que digo, mas pelo menos sei o suficiente para conseguir saber que ingredientes n√£o usar na minha pele e etc. Continuo a querer, um dia, ir ao dermatologista, mas √© caro e √© dif√≠cil marcar uma consulta, j√° que est√£o sempre ocupados at√© dali a 3-4 meses e para mim marcar com tanta anteced√™ncia acaba por ser mau, j√° que tenho uma mentalidade um bocado impulsiva e, quando vejo que n√£o d√° pra ser r√°pido acabo por desistir.\n",
      "Isto tudo para dizer que adoro skincare, adoro a minha hora e meia di√°ria a tomar conta de mim e a conectar-me comigo mesma enquanto lavo a cara e ponho os meus toners, s√©runs e cremes.\n",
      "\n",
      "2. Acho que j√° n√£o √© bem um interesse especial meu, porque hoje em dia parece que n√£o tenho um interesse especial por nada, excepto, sei l√°, dormir, mas quando era mi√∫da era obcecada com montes de cenas. A primeira foi Sailor Moon, sim o anime que passava no Canal Panda, foi a minha primeira e provavelmente maior pancada. Eu via aquilo religiosamente todos os dias, quando havia pausa de epis√≥dios, procurava-os no Youtube e tinha de ver em japon√™s com legendas espanholas que mal percebia, e depois passava o resto do dia a desenhar as personagens e a criar as minhas pr√≥prias. Lembro-me que queria imenso vestir-me como a Bunny/Usagi, que √© a personagem principal, e ter o fato dela, mas com o passar do tempo comecei a gostar mais de personagens secund√°rias tipo a Sailor Neptuno ou Sailor Saturno. Hoje em dia j√° n√£o sou completamente viciada no anime, mas a verdade √© que ainda compro algum merchandising da marca e vou acompanhando not√≠cias de parcerias ou da pr√≥pria autora porque sinto que esta s√©rie faz parte de mim, e vai sempre fazer. √â um bocadinho infantil, mas honestamente tudo na vida que n√£o sejam mem√≥rias de crian√ßa √© super deprimente, s√©rio e sem piada ou felicidade nenhuma e √© bom ter a Sailor Moon para me relembrar de momentos mais felizes ou coisas mais f√∫teis. Depois da Sailor Moon, comecei a ser viciada em The Hunger Games, o que honestamente √© um contraste demasiado grande e uma s√©rie demasiado s√©ria apesar de tamb√©m ser juvenil. De repente saltei de ser uma crian√ßa que gostava de meninas planetas para come√ßar a ler sobre uma distopia completamente deprimente que mostra as consequ√™ncias do capitalismo e a falta de regula√ß√µes sociais. Ainda continuam a ser os meus livros favoritos mas a verdade √© que ler sobre teoria politica mascarada de fic√ß√£o n√£o faz muito bem ao c√©rebro de uma mi√∫da de 10 anos ent√£o ya. Desde essa altura que passei a ser extremamente envolvida em assuntos pol√≠ticos e comecei a investigar sobre essa √°rea. Atualmente o meu grande interesse atual √© pol√≠tica e feminismo.\n",
      "\n",
      "3. Uma PHDA tem interesses transit√≥rios e hiperfoca intensamente em cada um deles at√© aparecer(em) outro(s) que ofere√ßam mais dopamina naquele momento\n",
      "\n",
      "\n",
      "\n",
      "üß† Topic 5: 5_ T√≠tulo: Prote√ß√£o Civil e Animais    \n",
      "\n",
      "\n",
      "\n",
      "   A resposta √© uma das 2 possibilidades de resposta que foram dadas. A outra √©:\n",
      "  Tema desconhecido    \n",
      "\n",
      "\n",
      "\n",
      "   Aqui ficou a resposta correta: Prote√ß√£o Civil e Animais. \n",
      "\n",
      "\n",
      "\n",
      "   E aqui ficou a outra possibilidade de resposta: Tema desconhecido. \n",
      "\n",
      "\n",
      "\n",
      "   Para a resposta correta: Prote√ß√£o Civil e Animais. \n",
      "\n",
      "\n",
      "\n",
      "   A an√°lise foi feita com base no seguinte: Prote√ß√£o Civil e Animais. \n",
      "\n",
      "\n",
      "\n",
      "   O resultado foi obtido com base na seguinte l√≥gica: \n",
      "\n",
      "\n",
      "\n",
      "   A resposta correta foi identificada porque prote√ß√£o civil e animais est√£o presentes na descri√ß√£o do tema. \n",
      "\n",
      "\n",
      "\n",
      "   A l√≥gica foi aplicada da seguinte forma: \n",
      "\n",
      "\n",
      "\n",
      "   Foi identificado o tema comum dos documentos de participantes, que inclui animais e prote√ß√£o civil. \n",
      "\n",
      "\n",
      "\n",
      "   Foi gerado um t√≠tulo curto e representativo para este tema, que inclui as palavras-chave prote√ß√£o civil e animais. \n",
      "\n",
      "\n",
      "\n",
      "   O t√≠tulo foi escolhido porque √© claro, direto e conciso, e reflete com precis√£o o conte√∫do dos documentos___\n",
      "Total documents: 2\n",
      "------------------------------------------------------------\n",
      "1. Animais, sempre amei animais e √© a minha maior paix√£o. \n",
      "\n",
      "2. √Åreas da Prote√ß√£o Civil, em especial a emerg√™ncia m√©dica, pois a adrenalina do momento deixa me muito focada, estou a trabalhar diretamente com as pessoas e com a vida delas e a imprevisibilidade do dia e de todas as situa√ß√µes bem como toda a log√≠stica associada.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "mask_women_adhd = (df_copy['sex']==\"Feminino\") & (df_copy['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "df_women_adhd = df_copy[mask_women_adhd]\n",
    "\n",
    "column = \"special_interest\"\n",
    "df_women_adhd, topic_model, topics, probs = run_bertopic_model(df_women_adhd, column, f\"{column}_embedding\", min_topic_size=2)\n",
    "valid_docs = df_women_adhd[df_women_adhd[\"topic\"] != -1]\n",
    "print(\"Valid topic documents:\", len(valid_docs), \"of\", len(df_women_adhd))\n",
    "get_topics(df_women_adhd, topic_model, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14ad7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de248899a62445c681e288d42d04ecdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "2025-08-03 17:02:50,751 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-08-03 17:02:51,299 - BERTopic - Dimensionality - Completed ‚úì\n",
      "2025-08-03 17:02:51,304 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-08-03 17:02:51,378 - BERTopic - Cluster - Completed ‚úì\n",
      "2025-08-03 17:02:51,385 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  0%|          | 0/2 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m df_others \u001b[38;5;241m=\u001b[39m df_copy[mask_others]\n\u001b[1;32m      5\u001b[0m column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecial_interest\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m df_others, topic_model, topics, probs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_bertopic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_others\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcolumn\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_embedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_topic_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m valid_docs \u001b[38;5;241m=\u001b[39m df_others[df_others[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid topic documents:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(valid_docs), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_others))\n",
      "Cell \u001b[0;32mIn[3], line 40\u001b[0m, in \u001b[0;36mrun_bertopic_model\u001b[0;34m(df, text_column, embedding_column, min_topic_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m ctfidf_model \u001b[38;5;241m=\u001b[39m ClassTfidfTransformer(bm25_weighting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_frequent_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m topic_model \u001b[38;5;241m=\u001b[39m BERTopic(\n\u001b[1;32m     32\u001b[0m     representation_model\u001b[38;5;241m=\u001b[39mrepresentation_model,\n\u001b[1;32m     33\u001b[0m     language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilingual\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     ctfidf_model\u001b[38;5;241m=\u001b[39mctfidf_model,\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m topics, probs \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m topics\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df, topic_model, topics, probs\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/bertopic/_bertopic.py:515\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_representative_docs(custom_documents)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;66;03m# Extract topics by calculating c-TF-IDF, reduce topics if needed, and get representations.\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_topics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfine_tune_representation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnr_topics\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_topics:\n\u001b[1;32m    519\u001b[0m         documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_topics(documents)\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/bertopic/_bertopic.py:4049\u001b[0m, in \u001b[0;36mBERTopic._extract_topics\u001b[0;34m(self, documents, embeddings, mappings, verbose, fine_tune_representation)\u001b[0m\n\u001b[1;32m   4047\u001b[0m documents_per_topic \u001b[38;5;241m=\u001b[39m documents\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m], as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin})\n\u001b[1;32m   4048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_tf_idf_, words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_tf_idf(documents_per_topic)\n\u001b[0;32m-> 4049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_representations_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_words_per_topic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfine_tune_representation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfine_tune_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalculate_aspects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfine_tune_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4054\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4055\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4056\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_topic_vectors(documents\u001b[38;5;241m=\u001b[39mdocuments, embeddings\u001b[38;5;241m=\u001b[39membeddings, mappings\u001b[38;5;241m=\u001b[39mmappings)\n\u001b[1;32m   4058\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/bertopic/_bertopic.py:4371\u001b[0m, in \u001b[0;36mBERTopic._extract_words_per_topic\u001b[0;34m(self, words, documents, c_tf_idf, fine_tune_representation, calculate_aspects, embeddings)\u001b[0m\n\u001b[1;32m   4369\u001b[0m     topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_model\u001b[38;5;241m.\u001b[39mextract_topics(\u001b[38;5;28mself\u001b[39m, documents, c_tf_idf, topics, embeddings)\n\u001b[1;32m   4370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fine_tune_representation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_model, BaseRepresentation):\n\u001b[0;32m-> 4371\u001b[0m     topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_tf_idf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fine_tune_representation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_model, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   4373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_model\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/bertopic/representation/_textgeneration.py:157\u001b[0m, in \u001b[0;36mTextGeneration.extract_topics\u001b[0;34m(self, topic_model, documents, c_tf_idf, topics)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts_\u001b[38;5;241m.\u001b[39mappend(prompt)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Extract result from generator and use that as label\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m topic_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m topic_description \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    159\u001b[0m     (description[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m description \u001b[38;5;129;01min\u001b[39;00m topic_description\n\u001b[1;32m    160\u001b[0m ]\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(topic_description) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m:\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:316\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1464\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1457\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1458\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         )\n\u001b[1;32m   1462\u001b[0m     )\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1471\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1470\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1471\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1472\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1371\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1370\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1371\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:414\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    412\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 414\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[1;32m    417\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msequences\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:2625\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2617\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2618\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2619\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2620\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2621\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2622\u001b[0m     )\n\u001b[1;32m   2624\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2625\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2636\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2637\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2638\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2639\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2640\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2641\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2642\u001b[0m     )\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:3606\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3603\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 3606\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3607\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:943\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    945\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:553\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    549\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    550\u001b[0m )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:943\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    945\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:441\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    439\u001b[0m     all_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[0;32m--> 441\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/modeling_layers.py:83\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:290\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:247\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    245\u001b[0m     attention_interface \u001b[38;5;241m=\u001b[39m ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_attn_implementation]\n\u001b[0;32m--> 247\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    259\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_proj(attn_output)\n",
      "File \u001b[0;32m~/adhd-linguistic-patterns-beliefs-portuguese-women/.venv/lib/python3.10/site-packages/transformers/integrations/sdpa_attention.py:66\u001b[0m, in \u001b[0;36msdpa_attention_forward\u001b[0;34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(is_causal, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     64\u001b[0m     is_causal \u001b[38;5;241m=\u001b[39m is_causal\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 66\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "mask_others = ~mask_women_adhd\n",
    "df_others = df_copy[mask_others]\n",
    "\n",
    "column = \"special_interest\"\n",
    "df_others, topic_model, topics, probs = run_bertopic_model(df_others, column, f\"{column}_embedding\", min_topic_size=2)\n",
    "valid_docs = df_others[df_others[\"topic\"] != -1]\n",
    "print(\"Valid topic documents:\", len(valid_docs), \"of\", len(df_others))\n",
    "get_topics(df_others, topic_model, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5533cce",
   "metadata": {},
   "source": [
    "### Diary Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "mask_women_adhd = (df_copy['sex']==\"Feminino\") & (df_copy['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "df_women_adhd = df_copy[mask_women_adhd]\n",
    "\n",
    "column = \"diary_entry\"\n",
    "df_women_adhd, topic_model, topics, probs = run_bertopic_model(df_women_adhd, column, f\"{column}_embedding\", min_topic_size=2)\n",
    "valid_docs = df_women_adhd[df_women_adhd[\"topic\"] != -1]\n",
    "print(\"Valid topic documents:\", len(valid_docs), \"of\", len(df_women_adhd))\n",
    "get_topics(df_women_adhd, topic_model, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a56401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "mask_others = ~mask_women_adhd\n",
    "df_others = df_copy[mask_others]\n",
    "\n",
    "column = \"diary_entry\"\n",
    "df_others, topic_model, topics, probs = run_bertopic_model(df_others, column, f\"{column}_embedding\", min_topic_size=2)\n",
    "valid_docs = df_others[df_others[\"topic\"] != -1]\n",
    "print(\"Valid topic documents:\", len(valid_docs), \"of\", len(df_others))\n",
    "get_topics(df_others, topic_model, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82325ff7",
   "metadata": {},
   "source": [
    "### Self-Defining Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590eabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "mask_women_adhd = (df_copy['sex']==\"Feminino\") & (df_copy['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "df_women_adhd = df_copy[mask_women_adhd]\n",
    "\n",
    "column = \"selfdefining_memory\"\n",
    "df_women_adhd, topic_model, topics, probs = run_bertopic_model(df_women_adhd, column, f\"{column}_embedding\", min_topic_size=2)\n",
    "valid_docs = df_women_adhd[df_women_adhd[\"topic\"] != -1]\n",
    "print(\"Valid topic documents:\", len(valid_docs), \"of\", len(df_women_adhd))\n",
    "get_topics(df_women_adhd, topic_model, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1499e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "mask_others = ~mask_women_adhd\n",
    "df_others = df_copy[mask_others]\n",
    "\n",
    "column = \"selfdefining_memory\"\n",
    "df_others, topic_model, topics, probs = run_bertopic_model(df_others, column, f\"{column}_embedding\", min_topic_size=2)\n",
    "valid_docs = df_others[df_others[\"topic\"] != -1]\n",
    "print(\"Valid topic documents:\", len(valid_docs), \"of\", len(df_others))\n",
    "get_topics(df_others, topic_model, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f514f",
   "metadata": {},
   "source": [
    "### Empty Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bab1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "mask_women_adhd = (df_copy['sex']==\"Feminino\") & (df_copy['adhd_diagnosis']==\"Sim, diagnosticado\")\n",
    "df_women_adhd = df_copy[mask_women_adhd]\n",
    "\n",
    "column = \"empty_sheet\"\n",
    "df_women_adhd, topic_model, topics, probs = run_bertopic_model(df_women_adhd, column, f\"{column}_embedding\", min_topic_size=2)\n",
    "valid_docs = df_women_adhd[df_women_adhd[\"topic\"] != -1]\n",
    "print(\"Valid topic documents:\", len(valid_docs), \"of\", len(df_women_adhd))\n",
    "get_topics(df_women_adhd, topic_model, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb454f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "mask_others = ~mask_women_adhd\n",
    "df_others = df_copy[mask_others]\n",
    "\n",
    "column = \"empty_sheet\"\n",
    "df_others, topic_model, topics, probs = run_bertopic_model(df_others, column, f\"{column}_embedding\", min_topic_size=2)\n",
    "valid_docs = df_others[df_others[\"topic\"] != -1]\n",
    "print(\"Valid topic documents:\", len(valid_docs), \"of\", len(df_others))\n",
    "get_topics(df_others, topic_model, column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adhd-linguistic-patterns-beliefs-portuguese-women",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
