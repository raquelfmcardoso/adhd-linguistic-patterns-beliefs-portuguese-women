{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from bertopic.representation import TextGeneration\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from umap import UMAP\n",
    "import hdbscan\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import openai\n",
    "import spacy\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, OpenAI, PartOfSpeech\n",
    "from sklearn.metrics import silhouette_score\n",
    "import os\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087b45f",
   "metadata": {},
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_save_figure(fig, figure_name, save_formats=['png'], \n",
    "                    width=1000, height=700, scale=2, output_dir=\"../../outputs/plots\"):\n",
    "    \"\"\"\n",
    "    Automatically save any Plotly or Matplotlib figure to disk with multiple formats and timestamp\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fig : plotly.graph_objects.Figure or matplotlib.figure.Figure\n",
    "        The figure to save (supports both Plotly and Matplotlib)\n",
    "    figure_name : str\n",
    "        Descriptive name for the figure (will be used in filename)\n",
    "    save_formats : list\n",
    "        List of formats to save ['png', 'html', 'pdf', 'svg', 'jpeg']\n",
    "    width : int\n",
    "        Width of the saved image\n",
    "    height : int\n",
    "        Height of the saved image\n",
    "    scale : int\n",
    "        Scale factor for image resolution (higher = better quality)\n",
    "    output_dir : str\n",
    "        Directory to save the figures\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with saved file paths\n",
    "    \"\"\"\n",
    "    if fig is None:\n",
    "        print(f\"‚ùå No figure provided for '{figure_name}'\")\n",
    "        return {}\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate timestamp for unique filenames\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    saved_files = {}\n",
    "    \n",
    "    # Detect figure type\n",
    "    is_plotly = hasattr(fig, 'write_image') and hasattr(fig, 'write_html')\n",
    "    is_matplotlib = hasattr(fig, 'savefig')\n",
    "    \n",
    "    if not is_plotly and not is_matplotlib:\n",
    "        print(f\"‚ùå Unsupported figure type for '{figure_name}': {type(fig)}\")\n",
    "        return {}\n",
    "    \n",
    "    for format_type in save_formats:\n",
    "        # Clean figure name for filename (remove spaces, special chars)\n",
    "        clean_name = \"\".join(c for c in figure_name if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "        clean_name = clean_name.replace(' ', '_').lower()\n",
    "        \n",
    "        filename = f\"{timestamp}_{clean_name}.{format_type}\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            if is_plotly:\n",
    "                # Handle Plotly figures\n",
    "                if format_type == 'html':\n",
    "                    fig.write_html(filepath)\n",
    "                    print(f\"üìä Saved {figure_name} as HTML: {filename}\")\n",
    "                elif format_type in ['png', 'pdf', 'svg', 'jpeg']:\n",
    "                    fig.write_image(\n",
    "                        filepath,\n",
    "                        width=width,\n",
    "                        height=height,\n",
    "                        scale=scale,\n",
    "                        format=format_type\n",
    "                    )\n",
    "                    print(f\"üñºÔ∏è  Saved {figure_name} as {format_type.upper()}: {filename}\")\n",
    "                    \n",
    "            elif is_matplotlib:\n",
    "                # Handle Matplotlib figures\n",
    "                if format_type == 'html':\n",
    "                    # Convert matplotlib to HTML via mpld3 (if available) or skip\n",
    "                    try:\n",
    "                        import mpld3\n",
    "                        html_str = mpld3.fig_to_html(fig)\n",
    "                        with open(filepath, 'w') as f:\n",
    "                            f.write(html_str)\n",
    "                        print(f\"üìä Saved {figure_name} as HTML: {filename}\")\n",
    "                    except ImportError:\n",
    "                        print(f\"‚ö†Ô∏è  Skipping HTML for matplotlib figure '{figure_name}' (mpld3 not available)\")\n",
    "                        continue\n",
    "                elif format_type in ['png', 'pdf', 'svg', 'jpeg']:\n",
    "                    # Set DPI based on scale\n",
    "                    dpi = 100 * scale\n",
    "                    fig.savefig(\n",
    "                        filepath,\n",
    "                        format=format_type,\n",
    "                        dpi=dpi,\n",
    "                        bbox_inches='tight',\n",
    "                        facecolor='white',\n",
    "                        edgecolor='none'\n",
    "                    )\n",
    "                    print(f\"üñºÔ∏è  Saved {figure_name} as {format_type.upper()}: {filename}\")\n",
    "            \n",
    "            saved_files[format_type] = os.path.abspath(filepath)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving {figure_name} as {format_type}: {e}\")\n",
    "    \n",
    "    if saved_files:\n",
    "        print(f\"‚úÖ Total saved: {len(saved_files)} file(s) for '{figure_name}'\")\n",
    "        print(f\"üìÅ Location: {os.path.abspath(output_dir)}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    return saved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ff860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_bertopic_figure(fig, viz_type):\n",
    "    \"\"\"\n",
    "    Enhance BERTopic figures with specific optimizations for each visualization type\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fig : plotly.graph_objects.Figure\n",
    "        The BERTopic figure to enhance\n",
    "    viz_type : str\n",
    "        Type of visualization ('topics', 'topics_per_class', 'heatmap', etc.)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    plotly.graph_objects.Figure : Enhanced figure\n",
    "    \"\"\"\n",
    "    if fig is None:\n",
    "        return fig\n",
    "        \n",
    "    try:\n",
    "        if viz_type == 'topics':\n",
    "            # Fix intertopic distance map cropping issues\n",
    "            fig.update_layout(\n",
    "                # Increase margins to prevent cropping\n",
    "                margin=dict(l=80, r=80, t=100, b=80),\n",
    "                # Ensure proper aspect ratio\n",
    "                width=1200,\n",
    "                height=900,\n",
    "                # Add padding to prevent cluster cutoff\n",
    "                xaxis=dict(\n",
    "                    range=None,  # Let plotly auto-scale\n",
    "                    automargin=True,\n",
    "                    showgrid=True,\n",
    "                    gridcolor='rgba(0,0,0,0.1)'\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    range=None,  # Let plotly auto-scale  \n",
    "                    automargin=True,\n",
    "                    showgrid=True,\n",
    "                    gridcolor='rgba(0,0,0,0.1)'\n",
    "                ),\n",
    "                # Improve title positioning\n",
    "                title=dict(\n",
    "                    x=0.5,\n",
    "                    xanchor='center',\n",
    "                    y=0.95,\n",
    "                    font=dict(size=16)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        elif viz_type == 'topics_per_class':\n",
    "            # Ensure all topics are visible (not just the first one)\n",
    "            # Make all traces visible by default\n",
    "            if hasattr(fig, 'data'):\n",
    "                for trace in fig.data:\n",
    "                    trace.visible = True\n",
    "                    \n",
    "            # Improve layout for topics per class\n",
    "            fig.update_layout(\n",
    "                margin=dict(l=60, r=60, t=120, b=60),\n",
    "                width=1200,\n",
    "                height=800,\n",
    "                # Ensure legend is visible and functional\n",
    "                showlegend=True,\n",
    "                legend=dict(\n",
    "                    orientation=\"v\",\n",
    "                    yanchor=\"top\",\n",
    "                    y=1,\n",
    "                    xanchor=\"left\",\n",
    "                    x=1.02,\n",
    "                    bgcolor='rgba(255,255,255,0.8)',\n",
    "                    bordercolor='rgba(0,0,0,0.3)',\n",
    "                    borderwidth=1\n",
    "                ),\n",
    "                # Improve title\n",
    "                title=dict(\n",
    "                    x=0.5,\n",
    "                    xanchor='center',\n",
    "                    font=dict(size=16)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        elif viz_type == 'heatmap':\n",
    "            # Optimize heatmap layout\n",
    "            fig.update_layout(\n",
    "                margin=dict(l=120, r=80, t=100, b=120),\n",
    "                width=1000,\n",
    "                height=700\n",
    "            )\n",
    "            \n",
    "        elif viz_type == 'document_datamap':\n",
    "            # Optimize document datamap\n",
    "            fig.update_layout(\n",
    "                margin=dict(l=80, r=80, t=100, b=80),\n",
    "                width=1200,\n",
    "                height=900\n",
    "            )\n",
    "            \n",
    "        elif viz_type == 'hierarchy':\n",
    "            # Optimize hierarchy plot\n",
    "            fig.update_layout(\n",
    "                margin=dict(l=100, r=100, t=100, b=100),\n",
    "                width=1400,\n",
    "                height=800\n",
    "            )\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Could not enhance {viz_type} figure: {e}\")\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_figure_dimensions(fig):\n",
    "    \"\"\"\n",
    "    Safely extract width and height from a Plotly figure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to access width and height from layout\n",
    "        layout = fig.layout if hasattr(fig, 'layout') else None\n",
    "        if layout:\n",
    "            width = getattr(layout, 'width', None) or 1000\n",
    "            height = getattr(layout, 'height', None) or 700\n",
    "            return width, height\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback to defaults\n",
    "    return 1000, 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fc01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced wrapper function for BERTopic visualizations with optimizations\n",
    "def save_bertopic_figure_enhanced(fig, viz_type, group_name=\"Female_ADHD\", apply_enhancements=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Enhanced function for saving BERTopic visualizations with automatic optimizations\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fig : plotly.graph_objects.Figure or matplotlib.figure.Figure\n",
    "        The BERTopic figure to save\n",
    "    viz_type : str\n",
    "        Type of visualization ('topics', 'heatmap', 'hierarchy', 'topics_per_class', etc.)\n",
    "    group_name : str\n",
    "        Name of the group being analyzed\n",
    "    apply_enhancements : bool\n",
    "        Whether to apply BERTopic-specific enhancements (default: True)\n",
    "    **kwargs : additional arguments passed to auto_save_figure\n",
    "    \"\"\"\n",
    "    # Apply enhancements if requested and if it's a Plotly figure\n",
    "    if apply_enhancements and hasattr(fig, 'update_layout'):\n",
    "        print(f\"üîß Applying {viz_type} specific optimizations...\")\n",
    "        fig = enhance_bertopic_figure(fig, viz_type)\n",
    "    \n",
    "    figure_name = f\"bertopic_{viz_type}_{group_name}\"\n",
    "    \n",
    "    # Set default high-quality settings for BERTopic figures\n",
    "    kwargs.setdefault('save_formats', ['png', 'html'])\n",
    "    kwargs.setdefault('scale', 2)\n",
    "    \n",
    "    # Safely get figure dimensions\n",
    "    width, height = get_figure_dimensions(fig)\n",
    "    kwargs.setdefault('width', width)\n",
    "    kwargs.setdefault('height', height)\n",
    "    \n",
    "    return auto_save_figure(fig, figure_name, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496804d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_topic_words(topic_model, target_language='en', source_language='pt'):\n",
    "    \"\"\"\n",
    "    Translate topic words from Portuguese to English\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=source_language, target=target_language)\n",
    "    \n",
    "    # Hardcoded translations for specific terms\n",
    "    hardcoded_translations = {\n",
    "        'phda': 'adhd',\n",
    "        'PHDA': 'ADHD',\n",
    "        'Phda': 'ADHD'\n",
    "    }\n",
    "    \n",
    "    topics_dict = topic_model.get_topics()\n",
    "    translated_topics = {}\n",
    "    \n",
    "    for topic_id, words_scores in topics_dict.items():\n",
    "        if topic_id == -1:  # Skip noise topic\n",
    "            continue\n",
    "            \n",
    "        # Extract just the words (first element of each tuple)\n",
    "        words = [word for word, score in words_scores]\n",
    "        \n",
    "        # Translate words\n",
    "        try:\n",
    "            translated_words = []\n",
    "            for word in words:\n",
    "                # Check if we have a hardcoded translation first\n",
    "                if word in hardcoded_translations:\n",
    "                    translated = hardcoded_translations[word]\n",
    "                else:\n",
    "                    translated = translator.translate(word)\n",
    "                translated_words.append(translated)\n",
    "            \n",
    "            # Keep the same scores but with translated words\n",
    "            translated_topic = [(translated_words[i], score) for i, (word, score) in enumerate(words_scores)]\n",
    "            translated_topics[topic_id] = translated_topic\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error translating topic {topic_id}: {e}\")\n",
    "            # Keep original if translation fails\n",
    "            translated_topics[topic_id] = words_scores\n",
    "    \n",
    "    return translated_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba586755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_barchart_translated_fixed(topic_model, translated_topics, topics=None, top_k_topics=6, n_words=5, \n",
    "                                        custom_labels=True, title=\"<b>Topic Word Scores</b>\", \n",
    "                                        width=800, height=600):\n",
    "    \"\"\"\n",
    "    Create a bar chart visualization in the exact same style as BERTopic's visualize_barchart\n",
    "    but with translated words - FIXED VERSION for proper label mapping\n",
    "    \"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    # Get topic information and prepare data\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    \n",
    "    # Select topics to show (excluding outliers/noise topic -1)\n",
    "    if topics is None:\n",
    "        # Get top k topics by size (excluding noise topic -1)\n",
    "        selected_topics = topic_info[topic_info['Topic'] != -1].head(top_k_topics)['Topic'].tolist()\n",
    "    else:\n",
    "        # Filter out -1 from provided topics\n",
    "        selected_topics = [t for t in topics if t != -1]\n",
    "    \n",
    "    # Filter selected_topics to only include those that exist in translated_topics\n",
    "    available_topics = [topic_id for topic_id in selected_topics if topic_id in translated_topics]\n",
    "    \n",
    "    print(f\"DEBUG: Available topics for plotting: {available_topics}\")\n",
    "    \n",
    "    # Create subplot titles ONLY for the topics that will actually be plotted\n",
    "    # The key fix: properly map topic IDs to their position in the topic_info dataframe\n",
    "    subplot_titles = []\n",
    "    for topic_id in available_topics:\n",
    "        if custom_labels and hasattr(topic_model, 'custom_labels_') and topic_model.custom_labels_:\n",
    "            # Find the topic in topic_info and get its custom label\n",
    "            topic_row = topic_info[topic_info['Topic'] == topic_id]\n",
    "            if not topic_row.empty and 'CustomName' in topic_row.columns:\n",
    "                topic_label = topic_row.iloc[0]['CustomName']\n",
    "            elif not topic_row.empty and 'Name' in topic_row.columns:\n",
    "                topic_label = topic_row.iloc[0]['Name']\n",
    "            else:\n",
    "                # Fallback: try to get from custom_labels_ array using topic position\n",
    "                # Find the position of this topic in the topic_info (excluding outliers)\n",
    "                non_outlier_topics = topic_info[topic_info['Topic'] != -1]\n",
    "                topic_position = None\n",
    "                for idx, row in non_outlier_topics.iterrows():\n",
    "                    if row['Topic'] == topic_id:\n",
    "                        topic_position = list(non_outlier_topics.index).index(idx)\n",
    "                        break\n",
    "                \n",
    "                if topic_position is not None and topic_position < len(topic_model.custom_labels_):\n",
    "                    topic_label = topic_model.custom_labels_[topic_position]\n",
    "                else:\n",
    "                    topic_label = f\"Topic {topic_id}\"\n",
    "        else:\n",
    "            topic_label = f\"Topic {topic_id}\"\n",
    "        \n",
    "        print(f\"DEBUG: Topic {topic_id} -> Label: {topic_label}\")\n",
    "        subplot_titles.append(topic_label)\n",
    "    \n",
    "    # Prepare subplot structure - one row per topic that will actually be plotted\n",
    "    n_topics = len(available_topics)\n",
    "    if n_topics == 0:\n",
    "        print(\"No topics available for plotting\")\n",
    "        return None\n",
    "        \n",
    "    fig = make_subplots(\n",
    "        rows=n_topics, \n",
    "        cols=1,\n",
    "        shared_xaxes=False,\n",
    "        vertical_spacing=0.08,\n",
    "        subplot_titles=subplot_titles\n",
    "    )\n",
    "    \n",
    "    # Color scheme similar to BERTopic\n",
    "    colors = [\"#D55E00\", \"#0072B2\", \"#CC79A7\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\"]\n",
    "    \n",
    "    # Process each topic that will actually be plotted\n",
    "    for i, topic_id in enumerate(available_topics):\n",
    "        # Get translated words and scores\n",
    "        words_scores = translated_topics[topic_id][:n_words]\n",
    "        words = [word for word, score in words_scores]\n",
    "        scores = [score for word, score in words_scores]\n",
    "        \n",
    "        # Reverse order for proper display (highest scores at top)\n",
    "        words = words[::-1]\n",
    "        scores = scores[::-1]\n",
    "        \n",
    "        # Create horizontal bar trace\n",
    "        trace = go.Bar(\n",
    "            y=words,\n",
    "            x=scores,\n",
    "            orientation='h',\n",
    "            marker=dict(\n",
    "                color=colors[i % len(colors)],\n",
    "                line=dict(color='rgba(0,0,0,0.3)', width=0.5)\n",
    "            ),\n",
    "            text=[f\"{score:.3f}\" for score in scores],\n",
    "            textposition='outside',\n",
    "            textfont=dict(size=11),\n",
    "            hovertemplate='<b>%{y}</b><br>Score: %{x:.3f}<extra></extra>',\n",
    "            showlegend=False,\n",
    "            name=f\"Topic {topic_id}\"\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(trace, row=i+1, col=1)\n",
    "    \n",
    "    # Update layout to match BERTopic style\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=title,\n",
    "            x=0.5,\n",
    "            xanchor=\"center\",\n",
    "            font=dict(size=16, color=\"black\")\n",
    "        ),\n",
    "        height=height,\n",
    "        width=width,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        font=dict(color=\"black\", size=11),\n",
    "        margin=dict(l=10, r=10, t=60, b=10)\n",
    "    )\n",
    "    \n",
    "    # Update axes for each subplot\n",
    "    for i in range(n_topics):\n",
    "        # X-axis\n",
    "        fig.update_xaxes(\n",
    "            showgrid=True,\n",
    "            gridwidth=1,\n",
    "            gridcolor='rgba(0,0,0,0.1)',\n",
    "            zeroline=True,\n",
    "            zerolinewidth=1,\n",
    "            zerolinecolor='rgba(0,0,0,0.3)',\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor='black',\n",
    "            row=i+1, col=1\n",
    "        )\n",
    "        \n",
    "        # Y-axis\n",
    "        fig.update_yaxes(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor='black',\n",
    "            tickfont=dict(size=10),\n",
    "            row=i+1, col=1\n",
    "        )\n",
    "    \n",
    "    # Update annotation style for subplot titles\n",
    "    fig.update_annotations(font_size=12, font_color=\"black\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb723fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhouette_score(topic_model, embeddings):\n",
    "    \"\"\"\n",
    "    Calculate silhouette score for topic clustering quality assessment\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    topic_model : BERTopic\n",
    "        The trained BERTopic model\n",
    "    embeddings : np.array\n",
    "        Original document embeddings used for training\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Silhouette score (-1 to 1, higher is better)\n",
    "    \"\"\"\n",
    "    # Get document-topic assignments\n",
    "    document_topics = topic_model.topics_\n",
    "    \n",
    "    # Validate inputs\n",
    "    if len(embeddings) != len(document_topics):\n",
    "        print(f\"Warning: Embedding length ({len(embeddings)}) != topic assignments length ({len(document_topics)})\")\n",
    "        # Use the minimum length to avoid index errors\n",
    "        min_len = min(len(embeddings), len(document_topics))\n",
    "        embeddings = embeddings[:min_len]\n",
    "        document_topics = document_topics[:min_len]\n",
    "    \n",
    "    # Filter out outlier/noise topics (-1)\n",
    "    valid_indices = [i for i, topic in enumerate(document_topics) if topic != -1]\n",
    "    \n",
    "    # Check if we have enough valid documents and topics\n",
    "    if len(valid_indices) < 2:\n",
    "        print(\"Warning: Not enough valid documents (non-outlier) for silhouette score calculation\")\n",
    "        return 0.0\n",
    "    \n",
    "    # Get unique topics (excluding -1)\n",
    "    unique_topics = list(set([topic for topic in document_topics if topic != -1]))\n",
    "    if len(unique_topics) < 2:\n",
    "        print(\"Warning: Need at least 2 topics for silhouette score calculation\")\n",
    "        return 0.0\n",
    "    \n",
    "    # Use UMAP embeddings for silhouette calculation (lower dimensional space)\n",
    "    try:\n",
    "        # Transform embeddings to UMAP space\n",
    "        umap_embeddings = topic_model.umap_model.transform(embeddings)\n",
    "        \n",
    "        # Filter to valid documents only\n",
    "        X_valid = umap_embeddings[valid_indices]\n",
    "        labels_valid = [document_topics[i] for i in valid_indices]\n",
    "        \n",
    "        # Calculate silhouette score\n",
    "        score = silhouette_score(X_valid, labels_valid)\n",
    "        \n",
    "        print(f\"Silhouette score calculated on {len(X_valid)} documents across {len(unique_topics)} topics\")\n",
    "        return score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating silhouette score: {e}\")\n",
    "        print(\"Falling back to original embeddings...\")\n",
    "        \n",
    "        # Fallback: use original embeddings if UMAP transform fails\n",
    "        try:\n",
    "            X_valid = embeddings[valid_indices]\n",
    "            labels_valid = [document_topics[i] for i in valid_indices]\n",
    "            score = silhouette_score(X_valid, labels_valid)\n",
    "            print(f\"Silhouette score calculated on original embeddings: {len(X_valid)} documents\")\n",
    "            return score\n",
    "        except Exception as e2:\n",
    "            print(f\"Error with fallback calculation: {e2}\")\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba86719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topic_coherence_umass(topic_model, texts, vectorizer_model=None, top_k_words=10):\n",
    "    \"\"\"\n",
    "    UMass topic coherence (Mimno et al.): average over ordered word pairs (j<i) of\n",
    "        log((D(w_i, w_j) + 1) / D(w_j)),\n",
    "    where D(.) counts documents containing the term(s). Scores are typically negative;\n",
    "    higher (closer to 0) is better.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy import sparse\n",
    "\n",
    "    # Prefer the model's vectorizer to keep vocab/preprocessing aligned\n",
    "    if vectorizer_model is None and hasattr(topic_model, \"vectorizer_model\") and topic_model.vectorizer_model is not None:\n",
    "        print(\"Vectorizer available!\")\n",
    "        vectorizer_model = topic_model.vectorizer_model\n",
    "\n",
    "    # Fallback if the model has none\n",
    "    if vectorizer_model is None:\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        vectorizer_model = CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            lowercase=True,\n",
    "            token_pattern=r\"(?u)\\b\\w\\w+\\b\"\n",
    "        )\n",
    "\n",
    "    # Use transform if already fitted to preserve vocab; else fit\n",
    "    if hasattr(vectorizer_model, \"vocabulary_\") and vectorizer_model.vocabulary_:\n",
    "        X = vectorizer_model.transform(texts)\n",
    "        feature_names = np.array(sorted(vectorizer_model.vocabulary_, key=vectorizer_model.vocabulary_.get))\n",
    "    else:\n",
    "        X = vectorizer_model.fit_transform(texts)\n",
    "        feature_names = vectorizer_model.get_feature_names_out()\n",
    "\n",
    "    # Boolean presence matrix (sparse)\n",
    "    X = X.astype(bool).astype(int)  # keeps it sparse CSR\n",
    "\n",
    "    # Fast doc freq helper on sparse columns\n",
    "    def df(col_idx):\n",
    "        return X[:, col_idx].sum()\n",
    "\n",
    "    # Word -> column index\n",
    "    word_to_idx = {w: i for i, w in enumerate(feature_names)}\n",
    "\n",
    "    topics = topic_model.get_topics()\n",
    "    topic_coherences = {}\n",
    "\n",
    "    for topic_id, word_scores in topics.items():\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "        words = [w for (w, _) in word_scores[:top_k_words]]\n",
    "\n",
    "        pair_scores = []\n",
    "        for i in range(1, len(words)):\n",
    "            wi = words[i]\n",
    "            if wi not in word_to_idx:\n",
    "                continue\n",
    "            i_idx = word_to_idx[wi]\n",
    "            for j in range(i):\n",
    "                wj = words[j]\n",
    "                if wj not in word_to_idx:\n",
    "                    continue\n",
    "                j_idx = word_to_idx[wj]\n",
    "\n",
    "                Dj = df(j_idx)\n",
    "                if Dj == 0:\n",
    "                    continue  # undefined conditioning; skip\n",
    "\n",
    "                # co-doc frequency via elementwise multiply (still sparse)\n",
    "                Dij = X[:, i_idx].multiply(X[:, j_idx]).sum()\n",
    "\n",
    "                # UMass with +1 smoothing on the numerator\n",
    "                pair_scores.append(np.log((Dij + 1.0) / Dj))\n",
    "\n",
    "        topic_coherences[topic_id] = float(np.mean(pair_scores)) if pair_scores else float(\"nan\")\n",
    "\n",
    "    # Average across non-NaN topics\n",
    "    valid = [v for v in topic_coherences.values() if np.isfinite(v)]\n",
    "    avg = float(np.mean(valid)) if valid else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"topic_coherences\": topic_coherences,\n",
    "        \"average_coherence\": avg,\n",
    "        \"method\": \"UMass\",\n",
    "        \"top_k_words\": top_k_words,\n",
    "        \"description\": \"UMass coherence using document co-occurrence with +1 smoothing; higher (less negative) is better.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e743c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert_model(path):\n",
    "    return BERTopic.load(path, embedding_model=SentenceTransformer(\"PORTULAN/serafim-900m-portuguese-pt-sentence-encoder\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corresponding_df(df, group_name):\n",
    "    if group_name == \"Female_ADHD\":\n",
    "        topic_df = df[df[\"group\"] == \"Female_ADHD\"]\n",
    "        print(\"Female_ADHD\")\n",
    "    elif group_name == \"Female_noADHD\":\n",
    "        topic_df = df[df[\"group\"] == \"Female_noADHD\"]\n",
    "        print(\"Female_noADHD\")\n",
    "    elif group_name == \"ADHD\":\n",
    "        topic_df = df[df[\"group\"].isin([\"Male_ADHD\", \"Female_ADHD\"])]\n",
    "        print(\"ADHD\")\n",
    "    elif group_name == \"noADHD\":\n",
    "        topic_df = df[df[\"group\"].isin([\"Male_noADHD\", \"Female_noADHD\"])]\n",
    "        print(\"noADHD\")\n",
    "    return topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58555959",
   "metadata": {},
   "source": [
    "# Preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20385159",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = pd.read_pickle(\"../../data/adhd-beliefs-pt/adhd-beliefs-pt-embeddings-serafim-bertopic.pkl\")\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preliminary_steps(group_name, folder):\n",
    "    print(f\"Running preliminary steps for group: {group_name}, folder: {folder}\")\n",
    "    df_group = get_corresponding_df(topic_df, group_name)\n",
    "    path = f\"../../data/adhd-beliefs-pt/bertopic_tuning/{group_name}/{folder}/\"\n",
    "    output_folder = f\"../../outputs/bertopic_tuning/{group_name}/{folder}/\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    topic_model = load_bert_model(path)\n",
    "    return df_group, topic_model, output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hierarchy(topic_model, df_group, output_folder, group_name):\n",
    "    texts = df_group[\"response\"].tolist()\n",
    "    \n",
    "    # Generate and save hierarchical topics (this usually works fine)\n",
    "    try:\n",
    "        print(\"üîÑ Generating hierarchical topics...\")\n",
    "        hierarchical_topics = topic_model.hierarchical_topics(texts)\n",
    "        print(\"‚úÖ Hierarchical topics generated successfully\")\n",
    "        \n",
    "        # Visualize hierarchy (this also usually works)\n",
    "        try:\n",
    "            print(\"üîÑ Creating hierarchy visualization...\")\n",
    "            fig_hierarchy = topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics, custom_labels=True)\n",
    "            save_bertopic_figure_enhanced(fig_hierarchy, 'hierarchy', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "            print(\"‚úÖ Hierarchy visualization saved\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Warning: Could not create hierarchy visualization: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Could not generate hierarchical topics: {e}\")\n",
    "    \n",
    "    # Get and save topic info (this always works)\n",
    "    try:\n",
    "        topic_info = topic_model.get_topic_info()\n",
    "        topic_info.to_csv(f\"{output_folder}/topic_info.csv\", index=False)\n",
    "        \n",
    "        num_unique_topics = topic_info['Topic'].nunique()\n",
    "        num_real_topics = len(topic_info[topic_info['Topic'] != -1])  # Exclude outlier topic\n",
    "        \n",
    "        print(f\"üìä Number of unique topics: {num_unique_topics}\")\n",
    "        print(f\"üìä Number of real topics (excluding outliers): {num_real_topics}\")\n",
    "        \n",
    "        # Save topic summary\n",
    "        with open(f\"{output_folder}/topic_summary.txt\", \"w\") as f:\n",
    "            f.write(f\"Total unique topics: {num_unique_topics}\\n\")\n",
    "            f.write(f\"Real topics (excluding outliers): {num_real_topics}\\n\")\n",
    "            f.write(f\"Total documents: {len(texts)}\\n\")\n",
    "            f.write(f\"Documents per topic (avg): {len(texts) / max(num_real_topics, 1):.2f}\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting topic info: {e}\")\n",
    "        return topic_model\n",
    "    \n",
    "    # Try to create topic visualization with enhanced error handling\n",
    "    if num_real_topics <= 3:\n",
    "        print(\"‚ö†Ô∏è  Cannot create topic visualization: Need at least 3 real topics\")\n",
    "        print(\"üí° This model has too few distinct topics for meaningful visualization\")\n",
    "        \n",
    "        # Save a note about why visualization was skipped\n",
    "        with open(f\"{output_folder}/visualization_notes.txt\", \"w\") as f:\n",
    "            f.write(f\"Topic visualization skipped: Only {num_real_topics} real topics found\\n\")\n",
    "            f.write(\"Minimum 2 topics required for UMAP dimensionality reduction\\n\")\n",
    "            \n",
    "    elif num_real_topics <= 4:\n",
    "        print(\"‚ö†Ô∏è  Very few topics detected. Attempting visualization with fallback options...\")\n",
    "        \n",
    "        # Try with different UMAP parameters for small datasets\n",
    "        try:\n",
    "            print(\"üîÑ Attempting topic visualization with adjusted parameters...\")\n",
    "            \n",
    "            # Create a custom UMAP with parameters suitable for small datasets\n",
    "            from umap import UMAP\n",
    "            \n",
    "            # Override the model's UMAP temporarily with safer parameters\n",
    "            original_umap = topic_model.umap_model\n",
    "            \n",
    "            # Use parameters that work better with few topics\n",
    "            safe_umap = UMAP(\n",
    "                n_neighbors=min(2, num_real_topics),  # Very small n_neighbors\n",
    "                n_components=2,\n",
    "                metric=\"cosine\",\n",
    "                random_state=42,\n",
    "                min_dist=0.1,\n",
    "                spread=1.0\n",
    "            )\n",
    "            \n",
    "            topic_model.umap_model = safe_umap\n",
    "            \n",
    "            # Try the visualization\n",
    "            fig_topics = topic_model.visualize_topics(custom_labels=True)\n",
    "            save_bertopic_figure_enhanced(fig_topics, 'topics', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "            print(\"‚úÖ Topic visualization created with adjusted parameters\")\n",
    "            \n",
    "            # Restore original UMAP\n",
    "            topic_model.umap_model = original_umap\n",
    "            \n",
    "        except (TypeError, ValueError) as e:\n",
    "            if \"k >= N\" in str(e) or \"zero-size array\" in str(e):\n",
    "                print(\"‚ö†Ô∏è  UMAP spectral initialization failed due to insufficient data\")\n",
    "                print(\"üí° This is expected with very few topics - the model is still valid\")\n",
    "                \n",
    "                # Save detailed error info\n",
    "                with open(f\"{output_folder}/visualization_error.txt\", \"w\") as f:\n",
    "                    f.write(f\"Visualization failed due to insufficient topic diversity\\n\")\n",
    "                    f.write(f\"Error: {str(e)}\\n\")\n",
    "                    f.write(f\"Real topics: {num_real_topics}\\n\")\n",
    "                    f.write(f\"This is a known limitation when fewer than 5-6 topics exist\\n\")\n",
    "                    \n",
    "            else:\n",
    "                print(f\"‚ùå Unexpected error in topic visualization: {e}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Other error in topic visualization: {e}\")\n",
    "            \n",
    "    else:\n",
    "        # Normal case: enough topics for standard visualization\n",
    "        try:\n",
    "            print(\"üîÑ Creating standard topic visualization...\")\n",
    "            fig_topics = topic_model.visualize_topics(custom_labels=True)\n",
    "            save_bertopic_figure_enhanced(fig_topics, 'topics', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "            print(\"‚úÖ Topic visualization created successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in standard topic visualization: {e}\")\n",
    "    \n",
    "    return topic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bertopic_evals(topic_model, df_group, output_folder):\n",
    "    embeddings = np.vstack(df_group[\"response_embedding\"])\n",
    "    texts = df_group[\"response\"].tolist()\n",
    "    \n",
    "    # SILHOUETTE SCORE\n",
    "    silhouette_score = get_silhouette_score(topic_model, embeddings)\n",
    "    print(f\"Silhouette Score: {silhouette_score:.4f}\")\n",
    "    with open(f\"{output_folder}/silhouette_score.txt\", \"w\") as f:\n",
    "        f.write(f\"{silhouette_score}\")\n",
    "    \n",
    "    # COHERENCE SCORE - Updated to use UMass\n",
    "    print(\"Calculating topic coherence using UMass metric...\")\n",
    "    coherence_results = calculate_topic_coherence_umass(topic_model, texts, top_k_words=10)\n",
    "    avg_coherence = coherence_results['average_coherence']\n",
    "    topic_coherences = coherence_results['topic_coherences']\n",
    "    \n",
    "    print(f\"Average Topic Coherence (UMass): {avg_coherence:.4f}\")\n",
    "    print(\"Individual Topic Coherences:\")\n",
    "    for topic_id, coherence in topic_coherences.items():\n",
    "        print(f\"  Topic {topic_id}: {coherence:.4f}\")\n",
    "    \n",
    "    # Save coherence results\n",
    "    with open(f\"{output_folder}/coherence_score.txt\", \"w\") as f:\n",
    "        f.write(f\"Average Coherence (UMass): {avg_coherence}\\n\")\n",
    "        f.write(\"Individual Topic Coherences:\\n\")\n",
    "        for topic_id, coherence in topic_coherences.items():\n",
    "            f.write(f\"Topic {topic_id}: {coherence}\\n\")\n",
    "    \n",
    "    # Save detailed coherence results as JSON for further analysis\n",
    "    import json\n",
    "    with open(f\"{output_folder}/coherence_detailed.json\", \"w\") as f:\n",
    "        json.dump(coherence_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Coherence results saved to {output_folder}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bertopic_viz(topic_model, df_group, output_folder, group_name):\n",
    "    texts = df_group[\"response\"].tolist()\n",
    "    print(f\"Number of texts: {len(texts)}\")\n",
    "    print(f\"Number of topics: {len(topic_model.topics_)}\")\n",
    "    \n",
    "    # Check topic distribution before attempting datamap\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    real_topics = topic_info[topic_info['Topic'] != -1]\n",
    "    print(f\"Number of real topics (excluding outliers): {len(real_topics)}\")\n",
    "    \n",
    "    if len(texts) != len(topic_model.topics_):\n",
    "        print(\"Length mismatch detected. The model topics were from different training data.\")\n",
    "        print(\"Using topic info instead of document info.\")\n",
    "        display(topic_model.get_topic_info())\n",
    "    else:\n",
    "        document_info = topic_model.get_document_info(texts)\n",
    "        document_info.to_csv(f\"{output_folder}/document_info.csv\", index=False)\n",
    "        display(document_info)\n",
    "    print(\"=\" * 60)\n",
    "        \n",
    "    fig_heatmap = topic_model.visualize_heatmap(custom_labels=True)\n",
    "    save_bertopic_figure_enhanced(fig_heatmap, 'heatmap', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "    \n",
    "    classes = df_group[\"question\"].tolist()\n",
    "    topics_per_class = topic_model.topics_per_class(texts, classes=classes)\n",
    "    fig_topics_per_class = topic_model.visualize_topics_per_class(topics_per_class, custom_labels=True)\n",
    "    save_bertopic_figure_enhanced(fig_topics_per_class, 'topics_per_class', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "\n",
    "    # Check if we have enough valid topics for datamap visualization\n",
    "    if len(real_topics) < 2:\n",
    "        print(f\"‚ö†Ô∏è  Skipping document datamap: Only {len(real_topics)} real topics found (minimum 2 required)\")\n",
    "        with open(f\"{output_folder}/datamap_skipped.txt\", \"w\") as f:\n",
    "            f.write(f\"Document datamap skipped: Only {len(real_topics)} real topics found\\n\")\n",
    "            f.write(\"Minimum 2 real topics required for meaningful datamap visualization\\n\")\n",
    "    else:\n",
    "        try:\n",
    "            print(\"üîÑ Creating document datamap...\")\n",
    "            embeddings = np.vstack(df_group[\"response_embedding\"])\n",
    "            fig_document_datamap = topic_model.visualize_document_datamap(texts, embeddings=embeddings, custom_labels=True)\n",
    "            save_bertopic_figure_enhanced(fig_document_datamap, 'document_datamap', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "            print(\"‚úÖ Document datamap created successfully\")\n",
    "        except ValueError as e:\n",
    "            if \"array of sample points is empty\" in str(e):\n",
    "                print(\"‚ö†Ô∏è  Skipping document datamap: Insufficient valid data points for visualization\")\n",
    "                print(\"üí° This typically happens when most documents are classified as outliers\")\n",
    "                with open(f\"{output_folder}/datamap_error.txt\", \"w\") as f:\n",
    "                    f.write(f\"Document datamap failed: {str(e)}\\n\")\n",
    "                    f.write(\"This typically indicates insufficient topic diversity or too many outliers\\n\")\n",
    "            else:\n",
    "                print(f\"‚ùå Unexpected error in document datamap: {e}\")\n",
    "                raise e\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating document datamap: {e}\")\n",
    "\n",
    "    # Get translated topics\n",
    "    print(\"Translating topic words to English...\")\n",
    "    translated_topics = translate_topic_words(topic_model)\n",
    "\n",
    "    # Save translated topics\n",
    "    print(\"\\nTranslated Topics (Portuguese ‚Üí English):\")\n",
    "    print(\"=\"*60)\n",
    "    for topic_id, words_scores in translated_topics.items():\n",
    "        words = [word for word, score in words_scores[:5]]  # Top 5 words\n",
    "        print(f\"Topic {topic_id}: {', '.join(words)}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    fig_bertopic_style_fixed = visualize_barchart_translated_fixed(\n",
    "        topic_model, \n",
    "        translated_topics, \n",
    "        top_k_topics=6, \n",
    "        n_words=5,\n",
    "        custom_labels=True,\n",
    "        width=1000,\n",
    "        height=700\n",
    "    )\n",
    "        \n",
    "    if fig_bertopic_style_fixed:\n",
    "        save_bertopic_figure_enhanced(fig_bertopic_style_fixed, 'translated_barchart', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "    else:\n",
    "        print(\"No valid topics to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90ad45",
   "metadata": {},
   "source": [
    "# Female ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4838b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"Female_ADHD\"\n",
    "folders = [name for name in os.listdir(f\"../../data/adhd-beliefs-pt/bertopic_tuning/{group_name}/\") if os.path.isdir(os.path.join(f\"../../data/adhd-beliefs-pt/bertopic_tuning/{group_name}/\", name))]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Found folder: {folder}\")\n",
    "    print(\"=\" * 60)\n",
    "    df_group, topic_model, output_folder = preliminary_steps(group_name, folder)\n",
    "    check_hierarchy(topic_model, df_group, output_folder, group_name)\n",
    "    run_bertopic_evals(topic_model, df_group, output_folder)\n",
    "    run_bertopic_viz(topic_model, df_group, output_folder, group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f95345",
   "metadata": {},
   "source": [
    "# Female no-ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28567e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"Female_noADHD\"\n",
    "folders = [name for name in os.listdir(f\"../../data/adhd-beliefs-pt/bertopic_tuning/{group_name}/\") if os.path.isdir(os.path.join(f\"../../data/adhd-beliefs-pt/bertopic_tuning/{group_name}/\", name))]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Found folder: {folder}\")\n",
    "    print(\"=\" * 60)\n",
    "    df_group, topic_model, output_folder = preliminary_steps(group_name, folder)\n",
    "    check_hierarchy(topic_model, df_group, output_folder, group_name)\n",
    "    run_bertopic_evals(topic_model, df_group, output_folder)\n",
    "    run_bertopic_viz(topic_model, df_group, output_folder, group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af34af3",
   "metadata": {},
   "source": [
    "# ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4432b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"ADHD\"\n",
    "folders = [name for name in os.listdir(f\"../../data/adhd-beliefs-pt/bertopic_tuning/{group_name}/\") if os.path.isdir(os.path.join(f\"../../data/adhd-beliefs-pt/bertopic_tuning/{group_name}/\", name))]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d4bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Found folder: {folder}\")\n",
    "    print(\"=\" * 60)\n",
    "    df_group, topic_model, output_folder = preliminary_steps(group_name, folder)\n",
    "    check_hierarchy(topic_model, df_group, output_folder, group_name)\n",
    "    run_bertopic_evals(topic_model, df_group, output_folder)\n",
    "    run_bertopic_viz(topic_model, df_group, output_folder, group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f37cdc9",
   "metadata": {},
   "source": [
    "# no-ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"noADHD\"\n",
    "folders = [name for name in os.listdir(f\"../../data/adhd-beliefs-pt/bertopic_tuning/{group_name}/\") if os.path.isdir(os.path.join(f\"../../data/adhd-beliefs-pt/bertopic_tuning/{group_name}/\", name))]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6917e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Found folder: {folder}\")\n",
    "    print(\"=\" * 60)\n",
    "    df_group, topic_model, output_folder = preliminary_steps(group_name, folder)\n",
    "    check_hierarchy(topic_model, df_group, output_folder, group_name)\n",
    "    run_bertopic_evals(topic_model, df_group, output_folder)\n",
    "    run_bertopic_viz(topic_model, df_group, output_folder, group_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adhd-linguistic-patterns-beliefs-portuguese-women",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
