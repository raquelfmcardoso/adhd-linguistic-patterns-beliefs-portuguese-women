{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from bertopic.representation import TextGeneration\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from umap import UMAP\n",
    "import hdbscan\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import openai\n",
    "import spacy\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, OpenAI, PartOfSpeech\n",
    "from sklearn.metrics import silhouette_score\n",
    "import os\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_translator import GoogleTranslator\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087b45f",
   "metadata": {},
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_save_figure(fig, figure_name, save_formats=['png'], \n",
    "                    width=1000, height=700, scale=2, output_dir=\"../../outputs/plots\"):\n",
    "    \"\"\"\n",
    "    Automatically save any Plotly or Matplotlib figure to disk with multiple formats and timestamp\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fig : plotly.graph_objects.Figure or matplotlib.figure.Figure\n",
    "        The figure to save (supports both Plotly and Matplotlib)\n",
    "    figure_name : str\n",
    "        Descriptive name for the figure (will be used in filename)\n",
    "    save_formats : list\n",
    "        List of formats to save ['png', 'html', 'pdf', 'svg', 'jpeg']\n",
    "    width : int\n",
    "        Width of the saved image\n",
    "    height : int\n",
    "        Height of the saved image\n",
    "    scale : int\n",
    "        Scale factor for image resolution (higher = better quality)\n",
    "    output_dir : str\n",
    "        Directory to save the figures\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with saved file paths\n",
    "    \"\"\"\n",
    "    if fig is None:\n",
    "        print(f\"‚ùå No figure provided for '{figure_name}'\")\n",
    "        return {}\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate timestamp for unique filenames\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    saved_files = {}\n",
    "    \n",
    "    # Detect figure type\n",
    "    is_plotly = hasattr(fig, 'write_image') and hasattr(fig, 'write_html')\n",
    "    is_matplotlib = hasattr(fig, 'savefig')\n",
    "    \n",
    "    if not is_plotly and not is_matplotlib:\n",
    "        print(f\"‚ùå Unsupported figure type for '{figure_name}': {type(fig)}\")\n",
    "        return {}\n",
    "    \n",
    "    for format_type in save_formats:\n",
    "        # Clean figure name for filename (remove spaces, special chars)\n",
    "        clean_name = \"\".join(c for c in figure_name if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "        clean_name = clean_name.replace(' ', '_').lower()\n",
    "        \n",
    "        filename = f\"{timestamp}_{clean_name}.{format_type}\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            if is_plotly:\n",
    "                # Handle Plotly figures\n",
    "                if format_type == 'html':\n",
    "                    fig.write_html(filepath)\n",
    "                    print(f\"üìä Saved {figure_name} as HTML: {filename}\")\n",
    "                elif format_type in ['png', 'pdf', 'svg', 'jpeg']:\n",
    "                    fig.write_image(\n",
    "                        filepath,\n",
    "                        width=width,\n",
    "                        height=height,\n",
    "                        scale=scale,\n",
    "                        format=format_type\n",
    "                    )\n",
    "                    print(f\"üñºÔ∏è  Saved {figure_name} as {format_type.upper()}: {filename}\")\n",
    "                    \n",
    "            elif is_matplotlib:\n",
    "                # Handle Matplotlib figures\n",
    "                if format_type == 'html':\n",
    "                    # Convert matplotlib to HTML via mpld3 (if available) or skip\n",
    "                    try:\n",
    "                        import mpld3\n",
    "                        html_str = mpld3.fig_to_html(fig)\n",
    "                        with open(filepath, 'w') as f:\n",
    "                            f.write(html_str)\n",
    "                        print(f\"üìä Saved {figure_name} as HTML: {filename}\")\n",
    "                    except ImportError:\n",
    "                        print(f\"‚ö†Ô∏è  Skipping HTML for matplotlib figure '{figure_name}' (mpld3 not available)\")\n",
    "                        continue\n",
    "                elif format_type in ['png', 'pdf', 'svg', 'jpeg']:\n",
    "                    # Set DPI based on scale\n",
    "                    dpi = 100 * scale\n",
    "                    fig.savefig(\n",
    "                        filepath,\n",
    "                        format=format_type,\n",
    "                        dpi=dpi,\n",
    "                        bbox_inches='tight',\n",
    "                        facecolor='white',\n",
    "                        edgecolor='none'\n",
    "                    )\n",
    "                    print(f\"üñºÔ∏è  Saved {figure_name} as {format_type.upper()}: {filename}\")\n",
    "            \n",
    "            saved_files[format_type] = os.path.abspath(filepath)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving {figure_name} as {format_type}: {e}\")\n",
    "    \n",
    "    if saved_files:\n",
    "        print(f\"‚úÖ Total saved: {len(saved_files)} file(s) for '{figure_name}'\")\n",
    "        print(f\"üìÅ Location: {os.path.abspath(output_dir)}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    return saved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ff860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_bertopic_figure(fig, viz_type):\n",
    "    \"\"\"\n",
    "    Enhance BERTopic figures with specific optimizations for each visualization type\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fig : plotly.graph_objects.Figure\n",
    "        The BERTopic figure to enhance\n",
    "    viz_type : str\n",
    "        Type of visualization ('topics', 'topics_per_class', 'heatmap', etc.)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    plotly.graph_objects.Figure : Enhanced figure\n",
    "    \"\"\"\n",
    "    if fig is None:\n",
    "        return fig\n",
    "        \n",
    "    try:\n",
    "        if viz_type == 'topics':\n",
    "            # Fix intertopic distance map cropping issues\n",
    "            fig.update_layout(\n",
    "                # Increase margins to prevent cropping\n",
    "                margin=dict(l=80, r=80, t=100, b=80),\n",
    "                # Ensure proper aspect ratio\n",
    "                width=1200,\n",
    "                height=900,\n",
    "                # Add padding to prevent cluster cutoff\n",
    "                xaxis=dict(\n",
    "                    range=None,  # Let plotly auto-scale\n",
    "                    automargin=True,\n",
    "                    showgrid=True,\n",
    "                    gridcolor='rgba(0,0,0,0.1)'\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    range=None,  # Let plotly auto-scale  \n",
    "                    automargin=True,\n",
    "                    showgrid=True,\n",
    "                    gridcolor='rgba(0,0,0,0.1)'\n",
    "                ),\n",
    "                # Improve title positioning\n",
    "                title=dict(\n",
    "                    x=0.5,\n",
    "                    xanchor='center',\n",
    "                    y=0.95,\n",
    "                    font=dict(size=16)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        elif viz_type == 'topics_per_class':\n",
    "            # Ensure all topics are visible (not just the first one)\n",
    "            # Make all traces visible by default\n",
    "            if hasattr(fig, 'data'):\n",
    "                for trace in fig.data:\n",
    "                    trace.visible = True\n",
    "                    \n",
    "            # Improve layout for topics per class\n",
    "            fig.update_layout(\n",
    "                margin=dict(l=150, r=100, t=120, b=60),  # Increased left margin for longer class names\n",
    "                width=1200,\n",
    "                height=800,\n",
    "                # Ensure legend is visible and functional\n",
    "                showlegend=True,\n",
    "                legend=dict(\n",
    "                    orientation=\"v\",\n",
    "                    yanchor=\"top\",\n",
    "                    y=1,\n",
    "                    xanchor=\"left\",\n",
    "                    x=1.02,\n",
    "                    bgcolor='rgba(255,255,255,0.8)',\n",
    "                    bordercolor='rgba(0,0,0,0.3)',\n",
    "                    borderwidth=1\n",
    "                ),\n",
    "                # Improve title\n",
    "                title=dict(\n",
    "                    x=0.5,\n",
    "                    xanchor='center',\n",
    "                    font=dict(size=18)\n",
    "                ),\n",
    "                plot_bgcolor='white',\n",
    "                paper_bgcolor='white'\n",
    "            )\n",
    "            \n",
    "        elif viz_type == 'heatmap':\n",
    "            # Optimize heatmap layout\n",
    "            fig.update_layout(\n",
    "                margin=dict(l=120, r=80, t=100, b=120),\n",
    "                width=1000,\n",
    "                height=700\n",
    "            )\n",
    "            \n",
    "        elif viz_type == 'document_datamap':\n",
    "            # Optimize document datamap\n",
    "            fig.update_layout(\n",
    "                margin=dict(l=80, r=80, t=100, b=80),\n",
    "                width=1200,\n",
    "                height=900\n",
    "            )\n",
    "            \n",
    "        elif viz_type == 'hierarchy':\n",
    "            # Optimize hierarchy plot\n",
    "            fig.update_layout(\n",
    "                margin=dict(l=100, r=100, t=100, b=100),\n",
    "                width=1400,\n",
    "                height=800\n",
    "            )\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Could not enhance {viz_type} figure: {e}\")\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_figure_dimensions(fig):\n",
    "    \"\"\"\n",
    "    Safely extract width and height from a Plotly figure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to access width and height from layout\n",
    "        layout = fig.layout if hasattr(fig, 'layout') else None\n",
    "        if layout:\n",
    "            width = getattr(layout, 'width', None) or 1000\n",
    "            height = getattr(layout, 'height', None) or 700\n",
    "            return width, height\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback to defaults\n",
    "    return 1000, 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fc01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced wrapper function for BERTopic visualizations with optimizations\n",
    "def save_bertopic_figure_enhanced(fig, viz_type, group_name=\"Female_ADHD\", apply_enhancements=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Enhanced function for saving BERTopic visualizations with automatic optimizations\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fig : plotly.graph_objects.Figure or matplotlib.figure.Figure\n",
    "        The BERTopic figure to save\n",
    "    viz_type : str\n",
    "        Type of visualization ('topics', 'heatmap', 'hierarchy', 'topics_per_class', etc.)\n",
    "    group_name : str\n",
    "        Name of the group being analyzed\n",
    "    apply_enhancements : bool\n",
    "        Whether to apply BERTopic-specific enhancements (default: True)\n",
    "    **kwargs : additional arguments passed to auto_save_figure\n",
    "    \"\"\"\n",
    "    # Apply enhancements if requested and if it's a Plotly figure\n",
    "    if apply_enhancements and hasattr(fig, 'update_layout'):\n",
    "        print(f\"üîß Applying {viz_type} specific optimizations...\")\n",
    "        fig = enhance_bertopic_figure(fig, viz_type)\n",
    "    \n",
    "    figure_name = f\"bertopic_{viz_type}_{group_name}\"\n",
    "    \n",
    "    # Set default high-quality settings for BERTopic figures\n",
    "    kwargs.setdefault('save_formats', ['png', 'html'])\n",
    "    kwargs.setdefault('scale', 2)\n",
    "    \n",
    "    # Safely get figure dimensions\n",
    "    width, height = get_figure_dimensions(fig)\n",
    "    kwargs.setdefault('width', width)\n",
    "    kwargs.setdefault('height', height)\n",
    "    \n",
    "    return auto_save_figure(fig, figure_name, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496804d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_topic_words(topic_model, target_language='en', source_language='pt'):\n",
    "    \"\"\"\n",
    "    Translate topic words from Portuguese to English\n",
    "    \"\"\"\n",
    "    translator = GoogleTranslator(source=source_language, target=target_language)\n",
    "    \n",
    "    # Hardcoded translations for specific terms\n",
    "    hardcoded_translations = {\n",
    "        'phda': 'adhd',\n",
    "        'PHDA': 'ADHD',\n",
    "        'Phda': 'ADHD'\n",
    "    }\n",
    "    \n",
    "    topics_dict = topic_model.get_topics()\n",
    "    translated_topics = {}\n",
    "    \n",
    "    for topic_id, words_scores in topics_dict.items():\n",
    "        if topic_id == -1:  # Skip noise topic\n",
    "            continue\n",
    "            \n",
    "        # Extract just the words (first element of each tuple)\n",
    "        words = [word for word, score in words_scores]\n",
    "        \n",
    "        # Translate words\n",
    "        try:\n",
    "            translated_words = []\n",
    "            for word in words:\n",
    "                # Check if we have a hardcoded translation first\n",
    "                if word in hardcoded_translations:\n",
    "                    translated = hardcoded_translations[word]\n",
    "                else:\n",
    "                    translated = translator.translate(word)\n",
    "                translated_words.append(translated)\n",
    "            \n",
    "            # Keep the same scores but with translated words\n",
    "            translated_topic = [(translated_words[i], score) for i, (word, score) in enumerate(words_scores)]\n",
    "            translated_topics[topic_id] = translated_topic\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error translating topic {topic_id}: {e}\")\n",
    "            # Keep original if translation fails\n",
    "            translated_topics[topic_id] = words_scores\n",
    "    \n",
    "    return translated_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ce675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_topics_per_class_figure(fig, custom_title=None):\n",
    "    \"\"\"\n",
    "    Customize the topics per class figure with custom title, colors, and class name mapping.\n",
    "    Adds dashed separators between classes on the y-axis.\n",
    "    \"\"\"\n",
    "    if fig is None:\n",
    "        return fig\n",
    "\n",
    "    # Set custom title\n",
    "    if custom_title:\n",
    "        fig.update_layout(\n",
    "            title=dict(\n",
    "                text=f\"<b>{custom_title}</b>\",\n",
    "                x=0.5,\n",
    "                xanchor='center',\n",
    "                font=dict(size=18)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # colors = [\n",
    "    #     \"#e69f00\", \"#56b4e9\", \"#009e73\", \"#fde59\", \"#d55e00\", \"#0072b2\",\n",
    "    #     \"#ff9896\", \"#8c52ff\", \"#af4c0f\", \"#507736\", \"#1800ad\", \"#0097b2\",\n",
    "    #     \"#ffbb78\", \"#98df8a\", \"#ff5757\", \"#c5b0d5\", \"#c49c94\", \"#f7b6d3\",\n",
    "    #     \"#420303\", \"#a6a6a6\", \"#cb6ce6\", \"#00bf63\", \"#3f5757\", \"#883c5e\",\n",
    "    #     \"#b18164\", \"#576580\",\n",
    "    # ]\n",
    "    \n",
    "    colors = [\n",
    "        \"#e6194b\", \"#f58231\", \"#ffe119\", \"#bfef45\", \"#3cb44b\", \"#42d4f4\",\n",
    "        \"#4363d8\", \"#911eb4\", \"#f032e6\", \"#a9a9a9\", \"#800000\", \"#883c5e\",\n",
    "        \"#9a6324\", \"#808000\", \"#527564\", \"#469990\", \"#0a6161\", \"#13501b\",\n",
    "        \"#000075\", \"#3D0A55\", \"#7284A8\", \"#dcbeff\", \"#fabed4\", \"#fdc791\",\n",
    "        \"#fffac8\", \"#aaffc3\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Update trace colors and ensure all are visible\n",
    "        for i, trace in enumerate(fig.data):\n",
    "            color = colors[i % len(colors)]\n",
    "            trace.update(\n",
    "                marker=dict(color=color),\n",
    "                visible=True\n",
    "            )\n",
    "\n",
    "        # Add dashed separators between classes\n",
    "        print(\"üîç DEBUG: Analyzing figure structure for class separators...\")\n",
    "        \n",
    "        # Method 1: Try to get y-axis categories from layout\n",
    "        y_categories = None\n",
    "        if hasattr(fig, 'layout') and hasattr(fig.layout, 'yaxis'):\n",
    "            yaxis = fig.layout.yaxis\n",
    "            \n",
    "            # Check different possible locations for y-axis labels\n",
    "            if hasattr(yaxis, 'categoryarray') and yaxis.categoryarray:\n",
    "                y_categories = list(yaxis.categoryarray)\n",
    "                print(f\"üìã Found categoryarray: {y_categories}\")\n",
    "            elif hasattr(yaxis, 'ticktext') and yaxis.ticktext:\n",
    "                y_categories = list(yaxis.ticktext)\n",
    "                print(f\"üìã Found ticktext: {y_categories}\")\n",
    "        \n",
    "        # Method 2: Extract y-values from traces if categories not found in layout\n",
    "        if not y_categories:\n",
    "            print(\"üîç Extracting y-values from trace data...\")\n",
    "            y_values_set = set()\n",
    "            \n",
    "            for trace in fig.data:\n",
    "                if hasattr(trace, 'y') and trace.y is not None:\n",
    "                    if hasattr(trace.y, '__iter__'):\n",
    "                        y_values_set.update(trace.y)\n",
    "                    else:\n",
    "                        y_values_set.add(trace.y)\n",
    "            \n",
    "            if y_values_set:\n",
    "                y_categories = sorted(list(y_values_set))\n",
    "                print(f\"üìã Extracted y-categories from traces: {y_categories}\")\n",
    "        \n",
    "        # Add dashed separators if we found categories\n",
    "        if y_categories and len(y_categories) > 1:\n",
    "            print(f\"üîß Adding dashed separators for {len(y_categories)} categories...\")\n",
    "            \n",
    "            # Expected class names (in the order they should appear)\n",
    "            expected_classes = ['Free Writing', 'Special Interest', 'Diary Entry', 'Self-Defining Memory']\n",
    "            \n",
    "            # Find where each class ends to place separators\n",
    "            class_boundaries = []\n",
    "            \n",
    "            # Group categories by class\n",
    "            current_class = None\n",
    "            class_start_idx = 0\n",
    "            \n",
    "            for i, category in enumerate(y_categories):\n",
    "                # Determine which class this category belongs to\n",
    "                category_class = None\n",
    "                for class_name in expected_classes:\n",
    "                    if class_name in str(category):\n",
    "                        category_class = class_name\n",
    "                        break\n",
    "                \n",
    "                # If we've moved to a new class, mark the boundary\n",
    "                if current_class is not None and category_class != current_class:\n",
    "                    # Add separator at the boundary (between classes)\n",
    "                    class_boundaries.append(i - 0.5)  # Place line between current and previous\n",
    "                    print(f\"  Boundary between '{current_class}' and '{category_class}' at position {i - 0.5}\")\n",
    "                \n",
    "                current_class = category_class\n",
    "            \n",
    "            # Alternative approach: Add separators at regular intervals if class detection fails\n",
    "            if not class_boundaries:\n",
    "                print(\"‚ö†Ô∏è  Could not detect class boundaries automatically. Using regular intervals...\")\n",
    "                # Assume 4 classes with roughly equal number of topics each\n",
    "                n_categories = len(y_categories)\n",
    "                class_size = n_categories / 4  # 4 expected classes\n",
    "                \n",
    "                for i in range(1, 4):  # Add 3 separators for 4 classes\n",
    "                    boundary_pos = i * class_size - 0.5\n",
    "                    class_boundaries.append(boundary_pos)\n",
    "                    print(f\"  Regular boundary at position {boundary_pos}\")\n",
    "            \n",
    "            # Create dashed line shapes\n",
    "            shapes = []\n",
    "            for boundary_pos in class_boundaries:\n",
    "                shapes.append(dict(\n",
    "                    type=\"line\",\n",
    "                    xref=\"paper\",  # Reference to paper coordinates (0 to 1)\n",
    "                    yref=\"y\",      # Reference to y-axis data coordinates\n",
    "                    x0=0,          # Start at left edge\n",
    "                    x1=1,          # End at right edge\n",
    "                    y0=boundary_pos,   # Y position of the line\n",
    "                    y1=boundary_pos,   # Same Y position (horizontal line)\n",
    "                    line=dict(\n",
    "                        color=\"gray\",\n",
    "                        width=2,\n",
    "                        dash=\"dash\"\n",
    "                    ),\n",
    "                    layer=\"above\"  # Draw on top of the plot\n",
    "                ))\n",
    "            \n",
    "            if shapes:\n",
    "                fig.update_layout(shapes=shapes)\n",
    "                print(f\"‚úÖ Added {len(shapes)} dashed separators between classes\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  No class boundaries detected - no separators added\")\n",
    "        \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Could not find y-categories for separator placement\")\n",
    "\n",
    "        # Legend and layout\n",
    "        if len(fig.data) > 1:\n",
    "            fig.update_layout(\n",
    "                showlegend=True,\n",
    "                legend=dict(\n",
    "                    orientation=\"v\",\n",
    "                    yanchor=\"top\",\n",
    "                    y=1,\n",
    "                    xanchor=\"left\",\n",
    "                    x=1.02,\n",
    "                    bgcolor='rgba(255,255,255,0.8)',\n",
    "                    bordercolor='rgba(0,0,0,0.3)',\n",
    "                    borderwidth=1\n",
    "                )\n",
    "            )\n",
    "\n",
    "        fig.update_layout(\n",
    "            margin=dict(l=150, r=100, t=120, b=60),\n",
    "            width=1200,\n",
    "            height=800,\n",
    "            plot_bgcolor='white',\n",
    "            paper_bgcolor='white'\n",
    "        )\n",
    "\n",
    "        print(\"‚úÖ Successfully customized topics per class figure with dashed separators\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Could not fully customize figure: {e}\")\n",
    "        import traceback\n",
    "        print(f\"üîç Detailed error: {traceback.format_exc()}\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba586755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_barchart_translated_fixed(topic_model, translated_topics, topics=None, top_k_topics=11, n_words=5, \n",
    "                                        custom_labels=True, title=\"<b>Topic Word Scores</b>\", \n",
    "                                        width=1600, height=1200):\n",
    "    \"\"\"\n",
    "    Create a bar chart visualization in the exact same style as BERTopic's visualize_barchart\n",
    "    but with translated words - FIXED VERSION for proper label mapping\n",
    "    Now displays topics in 2 columns (5 left, 5 right) for better readability\n",
    "    \"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    # Get topic information and prepare data\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    \n",
    "    # Select topics to show (excluding outliers/noise topic -1)\n",
    "    if topics is None:\n",
    "        # Get top k topics by size (excluding noise topic -1)\n",
    "        selected_topics = topic_info[topic_info['Topic'] != -1].head(top_k_topics)['Topic'].tolist()\n",
    "    else:\n",
    "        # Filter out -1 from provided topics\n",
    "        selected_topics = [t for t in topics if t != -1]\n",
    "    \n",
    "    # Filter selected_topics to only include those that exist in translated_topics\n",
    "    available_topics = [topic_id for topic_id in selected_topics if topic_id in translated_topics]\n",
    "    \n",
    "    print(f\"DEBUG: Available topics for plotting: {available_topics}\")\n",
    "    \n",
    "    # Create subplot titles ONLY for the topics that will actually be plotted\n",
    "    # The key fix: properly map topic IDs to their position in the topic_info dataframe\n",
    "    subplot_titles = []\n",
    "    for topic_id in available_topics:\n",
    "        if custom_labels and hasattr(topic_model, 'custom_labels_') and topic_model.custom_labels_:\n",
    "            # Find the topic in topic_info and get its custom label\n",
    "            topic_row = topic_info[topic_info['Topic'] == topic_id]\n",
    "            if not topic_row.empty and 'CustomName' in topic_row.columns:\n",
    "                topic_label = topic_row.iloc[0]['CustomName']\n",
    "            elif not topic_row.empty and 'Name' in topic_row.columns:\n",
    "                topic_label = topic_row.iloc[0]['Name']\n",
    "            else:\n",
    "                # Fallback: try to get from custom_labels_ array using topic position\n",
    "                # Find the position of this topic in the topic_info (excluding outliers)\n",
    "                non_outlier_topics = topic_info[topic_info['Topic'] != -1]\n",
    "                topic_position = None\n",
    "                for idx, row in non_outlier_topics.iterrows():\n",
    "                    if row['Topic'] == topic_id:\n",
    "                        topic_position = list(non_outlier_topics.index).index(idx)\n",
    "                        break\n",
    "                \n",
    "                if topic_position is not None and topic_position < len(topic_model.custom_labels_):\n",
    "                    topic_label = topic_model.custom_labels_[topic_position]\n",
    "                else:\n",
    "                    topic_label = f\"Topic {topic_id}\"\n",
    "        else:\n",
    "            topic_label = f\"Topic {topic_id}\"\n",
    "        \n",
    "        print(f\"DEBUG: Topic {topic_id} -> Label: {topic_label}\")\n",
    "        subplot_titles.append(topic_label)\n",
    "    \n",
    "    # Prepare subplot structure - 2 columns layout (5 topics per column)\n",
    "    n_topics = len(available_topics)\n",
    "    if n_topics == 0:\n",
    "        print(\"No topics available for plotting\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate rows and columns for 2-column layout\n",
    "    n_cols = 2\n",
    "    n_rows = (n_topics + 1) // 2  # Ceiling division to get enough rows\n",
    "    \n",
    "    # Pad subplot_titles to match the grid if needed\n",
    "    while len(subplot_titles) < n_rows * n_cols:\n",
    "        subplot_titles.append(\"\")\n",
    "        \n",
    "    fig = make_subplots(\n",
    "        rows=n_rows, \n",
    "        cols=n_cols,\n",
    "        shared_xaxes=False,\n",
    "        horizontal_spacing=0.12,  # Space between columns\n",
    "        vertical_spacing=0.15,   # Space between rows\n",
    "        subplot_titles=subplot_titles[:n_topics]  # Only use titles for actual topics\n",
    "    )\n",
    "    \n",
    "    # Color scheme similar to BERTopic\n",
    "    colors = [\n",
    "        \"#e6194b\", \"#f58231\", \"#ffe119\", \"#bfef45\", \"#3cb44b\", \"#42d4f4\",\n",
    "        \"#4363d8\", \"#911eb4\", \"#f032e6\", \"#a9a9a9\", \"#800000\", \"#883c5e\",\n",
    "        \"#9a6324\", \"#808000\", \"#527564\", \"#469990\", \"#0a6161\", \"#13501b\",\n",
    "        \"#000075\", \"#3D0A55\", \"#7284A8\", \"#dcbeff\", \"#fabed4\", \"#fdc791\",\n",
    "        \"#fffac8\", \"#aaffc3\"\n",
    "    ]\n",
    "    \n",
    "    # Process each topic that will actually be plotted\n",
    "    for i, topic_id in enumerate(available_topics):\n",
    "        # Calculate row and column position for 2-column grid\n",
    "        row = (i // 2) + 1  # Row number (1-indexed)\n",
    "        col = (i % 2) + 1   # Column number (1-indexed)\n",
    "        \n",
    "        # Get translated words and scores\n",
    "        words_scores = translated_topics[topic_id][:n_words]\n",
    "        words = [word for word, score in words_scores]\n",
    "        scores = [score for word, score in words_scores]\n",
    "        \n",
    "        # Reverse order for proper display (highest scores at top)\n",
    "        words = words[::-1]\n",
    "        scores = scores[::-1]\n",
    "        \n",
    "        # Create horizontal bar trace\n",
    "        trace = go.Bar(\n",
    "            y=words,\n",
    "            x=scores,\n",
    "            orientation='h',\n",
    "            marker=dict(\n",
    "                color=colors[i % len(colors)],\n",
    "                line=dict(color='rgba(0,0,0,0.3)', width=0.5)\n",
    "            ),\n",
    "            text=[f\"<b>{score:.3f}</b>\" for score in scores],  # Bold text for better visibility\n",
    "            textposition='auto',  # Changed from 'outside' to 'auto' to prevent cutoff\n",
    "            textfont=dict(size=11, color='white'),  # White text for better contrast\n",
    "            hovertemplate='<b>%{y}</b><br>Score: %{x:.3f}<extra></extra>',\n",
    "            showlegend=False,\n",
    "            name=f\"Topic {topic_id}\"\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(trace, row=row, col=col)\n",
    "    \n",
    "    # Update layout to match BERTopic style with better spacing for 2-column layout\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=title,\n",
    "            x=0.5,\n",
    "            xanchor=\"center\",\n",
    "            font=dict(size=18, color=\"black\")  # Larger title font\n",
    "        ),\n",
    "        height=height,\n",
    "        width=width,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        font=dict(color=\"black\", size=12),  # Larger general font\n",
    "        margin=dict(l=40, r=40, t=80, b=40)  # Increased margins to prevent text cutoff\n",
    "    )\n",
    "    \n",
    "    # Update axes for each subplot in the 2-column grid\n",
    "    for i in range(n_topics):\n",
    "        row = (i // 2) + 1\n",
    "        col = (i % 2) + 1\n",
    "        \n",
    "        # X-axis\n",
    "        fig.update_xaxes(\n",
    "            showgrid=True,\n",
    "            gridwidth=1,\n",
    "            gridcolor='rgba(0,0,0,0.1)',\n",
    "            zeroline=True,\n",
    "            zerolinewidth=1,\n",
    "            zerolinecolor='rgba(0,0,0,0.3)',\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor='black',\n",
    "            tickfont=dict(size=11),  # Readable tick font\n",
    "            automargin=True,  # Automatically adjust margins to fit text\n",
    "            row=row, col=col\n",
    "        )\n",
    "        \n",
    "        # Y-axis\n",
    "        fig.update_yaxes(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor='black',\n",
    "            tickfont=dict(size=11),  # Readable tick font\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    # Update annotation style for subplot titles (larger font for readability)\n",
    "    fig.update_annotations(font_size=14, font_color=\"black\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_topic_texts(topic_model, texts, output_folder, group_name, min_texts_per_topic=2):\n",
    "    \"\"\"\n",
    "    Save the texts belonging to each topic to separate .txt files\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    topic_model : BERTopic\n",
    "        The trained BERTopic model\n",
    "    texts : list\n",
    "        List of original texts used for topic modeling\n",
    "    output_folder : str\n",
    "        Directory to save the topic text files\n",
    "    group_name : str\n",
    "        Name of the group being analyzed (for filename prefix)\n",
    "    min_texts_per_topic : int\n",
    "        Minimum number of texts required to create a file for a topic\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with topic_id as key and number of texts as value\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Get topic assignments for each document\n",
    "    if len(texts) != len(topic_model.topics_):\n",
    "        print(\"‚ö†Ô∏è  Warning: Text length doesn't match topic assignments length\")\n",
    "        print(f\"Texts: {len(texts)}, Topics: {len(topic_model.topics_)}\")\n",
    "        print(\"Using the minimum length to avoid errors\")\n",
    "        min_len = min(len(texts), len(topic_model.topics_))\n",
    "        texts = texts[:min_len]\n",
    "        topics = topic_model.topics_[:min_len]\n",
    "    else:\n",
    "        topics = topic_model.topics_\n",
    "    \n",
    "    # Get topic info for labels\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    \n",
    "    # Create subdirectory for topic texts\n",
    "    topic_texts_dir = os.path.join(output_folder, \"topic_texts\")\n",
    "    os.makedirs(topic_texts_dir, exist_ok=True)\n",
    "    \n",
    "    # Group texts by topic\n",
    "    topic_texts_dict = {}\n",
    "    for text, topic_id in zip(texts, topics):\n",
    "        if topic_id not in topic_texts_dict:\n",
    "            topic_texts_dict[topic_id] = []\n",
    "        topic_texts_dict[topic_id].append(text)\n",
    "    \n",
    "    # Save texts for each topic\n",
    "    topic_counts = {}\n",
    "    saved_topics = 0\n",
    "    skipped_topics = 0\n",
    "    \n",
    "    for topic_id, topic_texts in topic_texts_dict.items():\n",
    "        topic_counts[topic_id] = len(topic_texts)\n",
    "        \n",
    "        # Skip outlier topic (-1) and topics with too few texts\n",
    "        if topic_id == -1:\n",
    "            print(f\"üìù Skipping outlier topic {topic_id} with {len(topic_texts)} texts\")\n",
    "            skipped_topics += 1\n",
    "            continue\n",
    "            \n",
    "        if len(topic_texts) < min_texts_per_topic:\n",
    "            print(f\"üìù Skipping topic {topic_id} with only {len(topic_texts)} texts (minimum: {min_texts_per_topic})\")\n",
    "            skipped_topics += 1\n",
    "            continue\n",
    "        \n",
    "        # Get topic label from topic_info\n",
    "        topic_row = topic_info[topic_info['Topic'] == topic_id]\n",
    "        if not topic_row.empty:\n",
    "            if 'CustomName' in topic_row.columns and pd.notna(topic_row.iloc[0]['CustomName']):\n",
    "                topic_label = topic_row.iloc[0]['CustomName']\n",
    "            elif 'Name' in topic_row.columns and pd.notna(topic_row.iloc[0]['Name']):\n",
    "                topic_label = topic_row.iloc[0]['Name']\n",
    "            else:\n",
    "                topic_label = f\"Topic_{topic_id}\"\n",
    "        else:\n",
    "            topic_label = f\"Topic_{topic_id}\"\n",
    "        \n",
    "        # Clean topic label for filename\n",
    "        clean_label = \"\".join(c for c in topic_label if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "        clean_label = clean_label.replace(' ', '_').lower()\n",
    "        \n",
    "        # Create filename\n",
    "        filename = f\"{group_name}_topic_{topic_id}_{clean_label}.txt\"\n",
    "        filepath = os.path.join(topic_texts_dir, filename)\n",
    "        \n",
    "        # Write texts to file\n",
    "        try:\n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"Topic {topic_id}: {topic_label}\\n\")\n",
    "                f.write(f\"Number of texts: {len(topic_texts)}\\n\")\n",
    "                f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "                \n",
    "                for i, text in enumerate(topic_texts, 1):\n",
    "                    f.write(f\"Text {i}:\\n\")\n",
    "                    f.write(f\"{text}\\n\")\n",
    "                    f.write(\"-\" * 40 + \"\\n\\n\")\n",
    "            \n",
    "            print(f\"üíæ Saved {len(topic_texts)} texts for Topic {topic_id} ({topic_label}) to {filename}\")\n",
    "            saved_topics += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving Topic {topic_id}: {e}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary_file = os.path.join(topic_texts_dir, f\"{group_name}_topic_texts_summary.txt\")\n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Topic Texts Summary for {group_name}\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Total topics processed: {len(topic_texts_dict)}\\n\")\n",
    "        f.write(f\"Topics saved: {saved_topics}\\n\")\n",
    "        f.write(f\"Topics skipped: {skipped_topics}\\n\")\n",
    "        f.write(f\"Minimum texts per topic: {min_texts_per_topic}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Topic Distribution:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        for topic_id, count in sorted(topic_counts.items()):\n",
    "            if topic_id == -1:\n",
    "                f.write(f\"Topic {topic_id} (Outliers): {count} texts\\n\")\n",
    "            else:\n",
    "                topic_row = topic_info[topic_info['Topic'] == topic_id]\n",
    "                if not topic_row.empty:\n",
    "                    if 'CustomName' in topic_row.columns and pd.notna(topic_row.iloc[0]['CustomName']):\n",
    "                        label = topic_row.iloc[0]['CustomName']\n",
    "                    elif 'Name' in topic_row.columns and pd.notna(topic_row.iloc[0]['Name']):\n",
    "                        label = topic_row.iloc[0]['Name']\n",
    "                    else:\n",
    "                        label = f\"Topic_{topic_id}\"\n",
    "                else:\n",
    "                    label = f\"Topic_{topic_id}\"\n",
    "                \n",
    "                status = \"SAVED\" if count >= min_texts_per_topic else \"SKIPPED\"\n",
    "                f.write(f\"Topic {topic_id} ({label}): {count} texts [{status}]\\n\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Topic texts extraction completed!\")\n",
    "    print(f\"üìä Saved {saved_topics} topic files, skipped {skipped_topics} topics\")\n",
    "    print(f\"üìÅ Files saved to: {topic_texts_dir}\")\n",
    "    print(f\"üìÑ Summary saved to: {summary_file}\")\n",
    "    \n",
    "    return topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb723fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhouette_score(topic_model, embeddings, use_reduced_embeddings=False):\n",
    "    \"\"\"\n",
    "    Calculate silhouette score for topic clustering quality assessment - CORRECTED VERSION\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    topic_model : BERTopic\n",
    "        The trained BERTopic model\n",
    "    embeddings : np.array\n",
    "        Original document embeddings used for training\n",
    "    use_reduced_embeddings : bool\n",
    "        Whether to use dimensionality-reduced embeddings (default: False, uses original)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with silhouette scores and diagnostic info\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from sklearn.decomposition import PCA\n",
    "    import numpy as np\n",
    "    \n",
    "    # Get document-topic assignments\n",
    "    document_topics = topic_model.topics_\n",
    "    \n",
    "    # Validate inputs\n",
    "    if len(embeddings) != len(document_topics):\n",
    "        print(f\"Warning: Embedding length ({len(embeddings)}) != topic assignments length ({len(document_topics)})\")\n",
    "        min_len = min(len(embeddings), len(document_topics))\n",
    "        embeddings = embeddings[:min_len]\n",
    "        document_topics = document_topics[:min_len]\n",
    "    \n",
    "    # Filter out outlier/noise topics (-1)\n",
    "    valid_indices = [i for i, topic in enumerate(document_topics) if topic != -1]\n",
    "    \n",
    "    # Diagnostic information\n",
    "    total_docs = len(document_topics)\n",
    "    outlier_docs = sum(1 for t in document_topics if t == -1)\n",
    "    valid_docs = len(valid_indices)\n",
    "    unique_topics = list(set([topic for topic in document_topics if topic != -1]))\n",
    "    \n",
    "    print(f\"üìä SILHOUETTE SCORE DIAGNOSTICS:\")\n",
    "    print(f\"  Total documents: {total_docs}\")\n",
    "    print(f\"  Outlier documents (-1 topic): {outlier_docs} ({outlier_docs/total_docs*100:.1f}%)\")\n",
    "    print(f\"  Valid documents: {valid_docs} ({valid_docs/total_docs*100:.1f}%)\")\n",
    "    print(f\"  Number of unique topics: {len(unique_topics)}\")\n",
    "    \n",
    "    # Check if we have enough valid documents and topics\n",
    "    if valid_docs < 2:\n",
    "        print(\"‚ùå Error: Not enough valid documents (non-outlier) for silhouette score calculation\")\n",
    "        return {\"silhouette_score\": 0.0, \"error\": \"insufficient_valid_docs\"}\n",
    "    \n",
    "    if len(unique_topics) < 2:\n",
    "        print(\"‚ùå Error: Need at least 2 topics for silhouette score calculation\")\n",
    "        return {\"silhouette_score\": 0.0, \"error\": \"insufficient_topics\"}\n",
    "    \n",
    "    # Topic distribution analysis\n",
    "    from collections import Counter\n",
    "    topic_counts = Counter([document_topics[i] for i in valid_indices])\n",
    "    print(f\"  Topic distribution: {dict(topic_counts)}\")\n",
    "    \n",
    "    # Check for severely imbalanced topics\n",
    "    min_topic_size = min(topic_counts.values())\n",
    "    max_topic_size = max(topic_counts.values())\n",
    "    if min_topic_size == 1:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Some topics have only 1 document - this affects silhouette score quality\")\n",
    "    \n",
    "    # Prepare embeddings and labels\n",
    "    X_valid = embeddings[valid_indices]\n",
    "    labels_valid = [document_topics[i] for i in valid_indices]\n",
    "    \n",
    "    # Calculate silhouette score using ORIGINAL embeddings (not UMAP!)\n",
    "    try:\n",
    "        if use_reduced_embeddings and X_valid.shape[1] > 50:\n",
    "            # Optional: Use PCA for dimensionality reduction (much better than UMAP for distances)\n",
    "            print(f\"üîÑ Using PCA to reduce dimensions from {X_valid.shape[1]} to 50...\")\n",
    "            pca = PCA(n_components=50, random_state=42)\n",
    "            X_reduced = pca.fit_transform(X_valid)\n",
    "            explained_variance = pca.explained_variance_ratio_.sum()\n",
    "            print(f\"  PCA explained variance: {explained_variance:.3f}\")\n",
    "            score = silhouette_score(X_reduced, labels_valid)\n",
    "            method = f\"PCA-reduced (50D, {explained_variance:.3f} variance)\"\n",
    "        else:\n",
    "            # Use original high-dimensional embeddings (RECOMMENDED)\n",
    "            print(f\"üîÑ Using original embeddings ({X_valid.shape[1]}D)...\")\n",
    "            score = silhouette_score(X_valid, labels_valid)\n",
    "            method = f\"Original embeddings ({X_valid.shape[1]}D)\"\n",
    "        \n",
    "        print(f\"‚úÖ Silhouette score: {score:.4f} (method: {method})\")\n",
    "        \n",
    "        # Interpret the score\n",
    "        if score > 0.5:\n",
    "            interpretation = \"Excellent clustering\"\n",
    "        elif score > 0.3:\n",
    "            interpretation = \"Good clustering\"\n",
    "        elif score > 0.1:\n",
    "            interpretation = \"Weak but acceptable clustering\"\n",
    "        elif score > 0:\n",
    "            interpretation = \"Poor clustering (overlapping clusters)\"\n",
    "        else:\n",
    "            interpretation = \"Very poor clustering (worse than random)\"\n",
    "        \n",
    "        print(f\"üìà Interpretation: {interpretation}\")\n",
    "        \n",
    "        return {\n",
    "            \"silhouette_score\": float(score),\n",
    "            \"method\": method,\n",
    "            \"interpretation\": interpretation,\n",
    "            \"total_docs\": total_docs,\n",
    "            \"valid_docs\": valid_docs,\n",
    "            \"outlier_docs\": outlier_docs,\n",
    "            \"num_topics\": len(unique_topics),\n",
    "            \"topic_distribution\": dict(topic_counts),\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error calculating silhouette score: {e}\")\n",
    "        return {\"silhouette_score\": 0.0, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba86719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topic_coherence_umass(topic_model, texts, vectorizer_model=None, top_k_words=10):\n",
    "    \"\"\"\n",
    "    UMass topic coherence (Mimno et al.): average over ordered word pairs (j<i) of\n",
    "        log((D(w_i, w_j) + 1) / D(w_j)),\n",
    "    where D(.) counts documents containing the term(s). Scores are typically negative;\n",
    "    higher (closer to 0) is better.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy import sparse\n",
    "\n",
    "    # Prefer the model's vectorizer to keep vocab/preprocessing aligned\n",
    "    if vectorizer_model is None and hasattr(topic_model, \"vectorizer_model\") and topic_model.vectorizer_model is not None:\n",
    "        print(\"Vectorizer available!\")\n",
    "        vectorizer_model = topic_model.vectorizer_model\n",
    "\n",
    "    # Fallback if the model has none\n",
    "    if vectorizer_model is None:\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        vectorizer_model = CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            lowercase=True,\n",
    "            token_pattern=r\"(?u)\\b\\w\\w+\\b\"\n",
    "        )\n",
    "\n",
    "    # Use transform if already fitted to preserve vocab; else fit\n",
    "    if hasattr(vectorizer_model, \"vocabulary_\") and vectorizer_model.vocabulary_:\n",
    "        X = vectorizer_model.transform(texts)\n",
    "        feature_names = np.array(sorted(vectorizer_model.vocabulary_, key=vectorizer_model.vocabulary_.get))\n",
    "    else:\n",
    "        X = vectorizer_model.fit_transform(texts)\n",
    "        feature_names = vectorizer_model.get_feature_names_out()\n",
    "\n",
    "    # Boolean presence matrix (sparse)\n",
    "    X = X.astype(bool).astype(int)  # keeps it sparse CSR\n",
    "\n",
    "    # Fast doc freq helper on sparse columns\n",
    "    def df(col_idx):\n",
    "        return X[:, col_idx].sum()\n",
    "\n",
    "    # Word -> column index\n",
    "    word_to_idx = {w: i for i, w in enumerate(feature_names)}\n",
    "\n",
    "    topics = topic_model.get_topics()\n",
    "    topic_coherences = {}\n",
    "\n",
    "    for topic_id, word_scores in topics.items():\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "        words = [w for (w, _) in word_scores[:top_k_words]]\n",
    "\n",
    "        pair_scores = []\n",
    "        for i in range(1, len(words)):\n",
    "            wi = words[i]\n",
    "            if wi not in word_to_idx:\n",
    "                continue\n",
    "            i_idx = word_to_idx[wi]\n",
    "            for j in range(i):\n",
    "                wj = words[j]\n",
    "                if wj not in word_to_idx:\n",
    "                    continue\n",
    "                j_idx = word_to_idx[wj]\n",
    "\n",
    "                Dj = df(j_idx)\n",
    "                if Dj == 0:\n",
    "                    continue  # undefined conditioning; skip\n",
    "\n",
    "                # co-doc frequency via elementwise multiply (still sparse)\n",
    "                Dij = X[:, i_idx].multiply(X[:, j_idx]).sum()\n",
    "\n",
    "                # UMass with +1 smoothing on the numerator\n",
    "                pair_scores.append(np.log((Dij + 1.0) / Dj))\n",
    "\n",
    "        topic_coherences[topic_id] = float(np.mean(pair_scores)) if pair_scores else float(\"nan\")\n",
    "\n",
    "    # Average across non-NaN topics\n",
    "    valid = [v for v in topic_coherences.values() if np.isfinite(v)]\n",
    "    avg = float(np.mean(valid)) if valid else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"topic_coherences\": topic_coherences,\n",
    "        \"average_coherence\": avg,\n",
    "        \"method\": \"UMass\",\n",
    "        \"top_k_words\": top_k_words,\n",
    "        \"description\": \"UMass coherence using document co-occurrence with +1 smoothing; higher (less negative) is better.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e743c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert_model(path):\n",
    "    return BERTopic.load(path, embedding_model=SentenceTransformer(\"PORTULAN/serafim-900m-portuguese-pt-sentence-encoder\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corresponding_df(df, group_name):\n",
    "    if group_name == \"Female_ADHD\":\n",
    "        topic_df = df[df[\"group\"] == \"Female_ADHD\"]\n",
    "        print(\"Female_ADHD\")\n",
    "    elif group_name == \"Female_noADHD\":\n",
    "        topic_df = df[df[\"group\"] == \"Female_noADHD\"]\n",
    "        print(\"Female_noADHD\")\n",
    "    elif group_name == \"ADHD\":\n",
    "        topic_df = df[df[\"group\"].isin([\"Male_ADHD\", \"Female_ADHD\"])]\n",
    "        print(\"ADHD\")\n",
    "    elif group_name == \"noADHD\":\n",
    "        topic_df = df[df[\"group\"].isin([\"Male_noADHD\", \"Female_noADHD\"])]\n",
    "        print(\"noADHD\")\n",
    "    return topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58555959",
   "metadata": {},
   "source": [
    "# Preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20385159",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = pd.read_pickle(\"../../data/adhd-beliefs-pt/adhd-beliefs-pt-embeddings-serafim-bertopic.pkl\")\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preliminary_steps(group_name, folder):\n",
    "    print(f\"Running preliminary steps for group: {group_name}, folder: {folder}\")\n",
    "    df_group = get_corresponding_df(topic_df, group_name)\n",
    "    path = f\"../../data/adhd-beliefs-pt/bertopic_final/{group_name}/{folder}/\"\n",
    "    output_folder = f\"../../outputs/bertopic_final/{group_name}/{folder}/\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    topic_model = load_bert_model(path)\n",
    "    return df_group, topic_model, output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hierarchy(topic_model, df_group, output_folder, group_name):\n",
    "    texts = df_group[\"response\"].tolist()\n",
    "    \n",
    "    # Generate and save hierarchical topics (this usually works fine)\n",
    "    try:\n",
    "        print(\"üîÑ Generating hierarchical topics...\")\n",
    "        hierarchical_topics = topic_model.hierarchical_topics(texts)\n",
    "        print(\"‚úÖ Hierarchical topics generated successfully\")\n",
    "        \n",
    "        # Visualize hierarchy (this also usually works)\n",
    "        try:\n",
    "            print(\"üîÑ Creating hierarchy visualization...\")\n",
    "            fig_hierarchy = topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics, custom_labels=True)\n",
    "            save_bertopic_figure_enhanced(fig_hierarchy, 'hierarchy', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "            display(fig_hierarchy)\n",
    "            print(\"‚úÖ Hierarchy visualization saved\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Warning: Could not create hierarchy visualization: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Could not generate hierarchical topics: {e}\")\n",
    "    \n",
    "    # Get and save topic info (this always works)\n",
    "    try:\n",
    "        topic_info = topic_model.get_topic_info()\n",
    "        topic_info.to_csv(f\"{output_folder}/topic_info.csv\", index=False)\n",
    "        \n",
    "        num_unique_topics = topic_info['Topic'].nunique()\n",
    "        num_real_topics = len(topic_info[topic_info['Topic'] != -1])  # Exclude outlier topic\n",
    "        \n",
    "        print(f\"üìä Number of unique topics: {num_unique_topics}\")\n",
    "        print(f\"üìä Number of real topics (excluding outliers): {num_real_topics}\")\n",
    "        \n",
    "        # Save topic summary\n",
    "        with open(f\"{output_folder}/topic_summary.txt\", \"w\") as f:\n",
    "            f.write(f\"Total unique topics: {num_unique_topics}\\n\")\n",
    "            f.write(f\"Real topics (excluding outliers): {num_real_topics}\\n\")\n",
    "            f.write(f\"Total documents: {len(texts)}\\n\")\n",
    "            f.write(f\"Documents per topic (avg): {len(texts) / max(num_real_topics, 1):.2f}\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting topic info: {e}\")\n",
    "        return topic_model\n",
    "    \n",
    "    # Try to create topic visualization with enhanced error handling\n",
    "    if num_real_topics <= 3:\n",
    "        print(\"‚ö†Ô∏è  Cannot create topic visualization: Need at least 3 real topics\")\n",
    "        print(\"üí° This model has too few distinct topics for meaningful visualization\")\n",
    "        \n",
    "        # Save a note about why visualization was skipped\n",
    "        with open(f\"{output_folder}/visualization_notes.txt\", \"w\") as f:\n",
    "            f.write(f\"Topic visualization skipped: Only {num_real_topics} real topics found\\n\")\n",
    "            f.write(\"Minimum 2 topics required for UMAP dimensionality reduction\\n\")\n",
    "            \n",
    "    elif num_real_topics <= 4:\n",
    "        print(\"‚ö†Ô∏è  Very few topics detected. Attempting visualization with fallback options...\")\n",
    "        \n",
    "        # Try with different UMAP parameters for small datasets\n",
    "        try:\n",
    "            print(\"üîÑ Attempting topic visualization with adjusted parameters...\")\n",
    "            \n",
    "            # Create a custom UMAP with parameters suitable for small datasets\n",
    "            from umap import UMAP\n",
    "            \n",
    "            # Override the model's UMAP temporarily with safer parameters\n",
    "            original_umap = topic_model.umap_model\n",
    "            \n",
    "            # Use parameters that work better with few topics\n",
    "            safe_umap = UMAP(\n",
    "                n_neighbors=min(2, num_real_topics),  # Very small n_neighbors\n",
    "                n_components=2,\n",
    "                metric=\"cosine\",\n",
    "                random_state=42,\n",
    "                min_dist=0.1,\n",
    "                spread=1.0\n",
    "            )\n",
    "            \n",
    "            topic_model.umap_model = safe_umap\n",
    "            \n",
    "            # Try the visualization\n",
    "            fig_topics = topic_model.visualize_topics(custom_labels=True)\n",
    "            save_bertopic_figure_enhanced(fig_topics, 'topics', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "            display(fig_topics)\n",
    "            print(\"‚úÖ Topic visualization created with adjusted parameters\")\n",
    "            \n",
    "            # Restore original UMAP\n",
    "            topic_model.umap_model = original_umap\n",
    "            \n",
    "        except (TypeError, ValueError) as e:\n",
    "            if \"k >= N\" in str(e) or \"zero-size array\" in str(e):\n",
    "                print(\"‚ö†Ô∏è  UMAP spectral initialization failed due to insufficient data\")\n",
    "                print(\"üí° This is expected with very few topics - the model is still valid\")\n",
    "                \n",
    "                # Save detailed error info\n",
    "                with open(f\"{output_folder}/visualization_error.txt\", \"w\") as f:\n",
    "                    f.write(f\"Visualization failed due to insufficient topic diversity\\n\")\n",
    "                    f.write(f\"Error: {str(e)}\\n\")\n",
    "                    f.write(f\"Real topics: {num_real_topics}\\n\")\n",
    "                    f.write(f\"This is a known limitation when fewer than 5-6 topics exist\\n\")\n",
    "                    \n",
    "            else:\n",
    "                print(f\"‚ùå Unexpected error in topic visualization: {e}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Other error in topic visualization: {e}\")\n",
    "            \n",
    "    else:\n",
    "        # Normal case: enough topics for standard visualization\n",
    "        try:\n",
    "            print(\"üîÑ Creating standard topic visualization...\")\n",
    "            fig_topics = topic_model.visualize_topics(custom_labels=True)\n",
    "            save_bertopic_figure_enhanced(fig_topics, 'topics', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "            display(fig_topics)\n",
    "            print(\"‚úÖ Topic visualization created successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in standard topic visualization: {e}\")\n",
    "    \n",
    "    return topic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bertopic_evals(topic_model, df_group, output_folder):\n",
    "    embeddings = np.vstack(df_group[\"response_embedding\"])\n",
    "    texts = df_group[\"response\"].tolist()\n",
    "    \n",
    "    # SILHOUETTE SCORE\n",
    "    silhouette_results = get_silhouette_score(topic_model, embeddings, use_reduced_embeddings=False)\n",
    "    silhouette_score_value = silhouette_results.get('silhouette_score', 0.0)\n",
    "    print(f\"Silhouette Score: {silhouette_score_value:.4f}\")\n",
    "    \n",
    "    with open(f\"{output_folder}/silhouette_detailed.json\", \"w\") as f:\n",
    "        if isinstance(silhouette_results, dict):\n",
    "            json.dump(silhouette_results, f, indent=2)\n",
    "        else:\n",
    "            json.dump({\"silhouette_score\": float(silhouette_results), \"note\": \"unexpected_return_type\"}, f, indent=2)\n",
    "    \n",
    "    with open(f\"{output_folder}/silhouette_score.txt\", \"w\") as f:\n",
    "        f.write(f\"Silhouette Score: {silhouette_score_value:.4f}\\n\")\n",
    "        if isinstance(silhouette_results, dict):\n",
    "            f.write(f\"Method: {silhouette_results.get('method', 'Unknown')}\\n\")\n",
    "            f.write(f\"Interpretation: {silhouette_results.get('interpretation', 'Unknown')}\\n\")\n",
    "            f.write(f\"Valid documents: {silhouette_results.get('valid_docs', 0)}/{silhouette_results.get('total_docs', 0)}\\n\")\n",
    "            f.write(f\"Number of topics: {silhouette_results.get('num_topics', 0)}\\n\")\n",
    "            if silhouette_results.get('error'):\n",
    "                f.write(f\"Error: {silhouette_results.get('error')}\\n\")\n",
    "    \n",
    "    # COHERENCE SCORE - Updated to use UMass\n",
    "    print(\"Calculating topic coherence using UMass metric...\")\n",
    "    coherence_results = calculate_topic_coherence_umass(topic_model, texts, top_k_words=10)\n",
    "    avg_coherence = coherence_results['average_coherence']\n",
    "    topic_coherences = coherence_results['topic_coherences']\n",
    "    \n",
    "    print(f\"Average Topic Coherence (UMass): {avg_coherence:.4f}\")\n",
    "    print(\"Individual Topic Coherences:\")\n",
    "    for topic_id, coherence in topic_coherences.items():\n",
    "        print(f\"  Topic {topic_id}: {coherence:.4f}\")\n",
    "    \n",
    "    # Save coherence results\n",
    "    with open(f\"{output_folder}/coherence_score.txt\", \"w\") as f:\n",
    "        f.write(f\"Average Coherence (UMass): {avg_coherence}\\n\")\n",
    "        f.write(\"Individual Topic Coherences:\\n\")\n",
    "        for topic_id, coherence in topic_coherences.items():\n",
    "            f.write(f\"Topic {topic_id}: {coherence}\\n\")\n",
    "    \n",
    "    # Save detailed coherence results as JSON for further analysis\n",
    "    with open(f\"{output_folder}/coherence_detailed.json\", \"w\") as f:\n",
    "        json.dump(coherence_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Coherence results saved to {output_folder}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bertopic_viz(topic_model, df_group, output_folder, group_name):\n",
    "    texts = df_group[\"response\"].tolist()\n",
    "    print(f\"Number of texts: {len(texts)}\")\n",
    "    print(f\"Number of topics: {len(topic_model.topics_)}\")\n",
    "    \n",
    "    # Check topic distribution before attempting datamap\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    real_topics = topic_info[topic_info['Topic'] != -1]\n",
    "    print(f\"Number of real topics (excluding outliers): {len(real_topics)}\")\n",
    "    \n",
    "    if len(texts) != len(topic_model.topics_):\n",
    "        print(\"Length mismatch detected. The model topics were from different training data.\")\n",
    "        print(\"Using topic info instead of document info.\")\n",
    "        display(topic_model.get_topic_info())\n",
    "    else:\n",
    "        document_info = topic_model.get_document_info(texts)\n",
    "        document_info.to_csv(f\"{output_folder}/document_info.csv\", index=False)\n",
    "        display(document_info)\n",
    "    print(\"=\" * 60)\n",
    "        \n",
    "    fig_heatmap = topic_model.visualize_heatmap(custom_labels=True)\n",
    "    save_bertopic_figure_enhanced(fig_heatmap, 'heatmap', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "    display(fig_heatmap)\n",
    "    \n",
    "    classes = df_group[\"question\"].tolist()\n",
    "    classes = ['Free Writing' if x == 'empty_sheet' \n",
    "               else 'Special Interest' if x == 'special_interest'\n",
    "               else 'Diary Entry' if x == 'diary_entry'\n",
    "               else 'Self-Defining Memory' if x == 'selfdefining_memory'\n",
    "               else x for x in classes]\n",
    "    topics_per_class = topic_model.topics_per_class(texts, classes=classes)\n",
    "    fig_topics_per_class = topic_model.visualize_topics_per_class(topics_per_class, custom_labels=True, top_n_topics=30)\n",
    "    \n",
    "    fig_topics_per_class = customize_topics_per_class_figure(\n",
    "        fig_topics_per_class, \n",
    "        custom_title=\"Distribution of Topic Documents per Open-Ended Questions\"\n",
    "    )\n",
    "    \n",
    "    save_bertopic_figure_enhanced(fig_topics_per_class, 'topics_per_class', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "    display(fig_topics_per_class)\n",
    "\n",
    "    # Check if we have enough valid topics for datamap visualization\n",
    "    if len(real_topics) < 2:\n",
    "        print(f\"‚ö†Ô∏è  Skipping document datamap: Only {len(real_topics)} real topics found (minimum 2 required)\")\n",
    "        with open(f\"{output_folder}/datamap_skipped.txt\", \"w\") as f:\n",
    "            f.write(f\"Document datamap skipped: Only {len(real_topics)} real topics found\\n\")\n",
    "            f.write(\"Minimum 2 real topics required for meaningful datamap visualization\\n\")\n",
    "    else:\n",
    "        try:\n",
    "            print(\"üîÑ Creating document datamap...\")\n",
    "            embeddings = np.vstack(df_group[\"response_embedding\"])\n",
    "            fig_document_datamap = topic_model.visualize_document_datamap(texts, embeddings=embeddings, custom_labels=True)\n",
    "            save_bertopic_figure_enhanced(fig_document_datamap, 'document_datamap', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "            display(fig_document_datamap)\n",
    "            print(\"‚úÖ Document datamap created successfully\")\n",
    "        except ValueError as e:\n",
    "            if \"array of sample points is empty\" in str(e):\n",
    "                print(\"‚ö†Ô∏è  Skipping document datamap: Insufficient valid data points for visualization\")\n",
    "                print(\"üí° This typically happens when most documents are classified as outliers\")\n",
    "                with open(f\"{output_folder}/datamap_error.txt\", \"w\") as f:\n",
    "                    f.write(f\"Document datamap failed: {str(e)}\\n\")\n",
    "                    f.write(\"This typically indicates insufficient topic diversity or too many outliers\\n\")\n",
    "            else:\n",
    "                print(f\"‚ùå Unexpected error in document datamap: {e}\")\n",
    "                raise e\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating document datamap: {e}\")\n",
    "\n",
    "    # Get translated topics\n",
    "    print(\"Translating topic words to English...\")\n",
    "    translated_topics = translate_topic_words(topic_model)\n",
    "\n",
    "    # Save translated topics\n",
    "    print(\"\\nTranslated Topics (Portuguese ‚Üí English):\")\n",
    "    print(\"=\"*60)\n",
    "    for topic_id, words_scores in translated_topics.items():\n",
    "        words = [word for word, score in words_scores[:5]]  # Top 5 words\n",
    "        print(f\"Topic {topic_id}: {', '.join(words)}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    fig_bertopic_style_fixed = visualize_barchart_translated_fixed(\n",
    "        topic_model, \n",
    "        translated_topics, \n",
    "        top_k_topics=10,  # Changed to 10 topics (5 per column)\n",
    "        n_words=5,\n",
    "        custom_labels=True,\n",
    "        width=1600,       # Larger width for 2-column layout\n",
    "        height=1200       # Larger height for better readability\n",
    "    )\n",
    "        \n",
    "    if fig_bertopic_style_fixed:\n",
    "        save_bertopic_figure_enhanced(fig_bertopic_style_fixed, 'translated_barchart', group_name=group_name, apply_enhancements=True, output_dir=output_folder)\n",
    "        display(fig_bertopic_style_fixed)\n",
    "    else:\n",
    "        print(\"No valid topics to display\")\n",
    "    \n",
    "    # Save topic texts to separate files\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üíæ Saving topic texts to individual files...\")\n",
    "    topic_counts = save_topic_texts(topic_model, texts, output_folder, group_name, min_texts_per_topic=2)\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_group(group_name, folder):\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Found folder: {folder}\")\n",
    "    print(\"=\" * 60)\n",
    "    df_group, topic_model, output_folder = preliminary_steps(group_name, folder)\n",
    "    if group_name == \"noADHD\":\n",
    "        chatgpt_topic_labels = {topic: \" | \".join(list(zip(*values))[0]) for topic, values in topic_model.topic_aspects_[\"OpenAI\"].items()}\n",
    "        chatgpt_topic_labels[13] = \"Immersive Fantasy and Anime Interests\"\n",
    "        topic_model.set_topic_labels(chatgpt_topic_labels)\n",
    "    check_hierarchy(topic_model, df_group, output_folder, group_name)\n",
    "    run_bertopic_evals(topic_model, df_group, output_folder)\n",
    "    run_bertopic_viz(topic_model, df_group, output_folder, group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90ad45",
   "metadata": {},
   "source": [
    "# Female ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4838b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"Female_ADHD\"\n",
    "folders = [name for name in os.listdir(f\"../../data/adhd-beliefs-pt/bertopic_final/{group_name}/\") if os.path.isdir(os.path.join(f\"../../data/adhd-beliefs-pt/bertopic_final/{group_name}/\", name))]\n",
    "folder = folders[0] if folders else None\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_group(group_name, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f95345",
   "metadata": {},
   "source": [
    "# Female no-ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28567e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"Female_noADHD\"\n",
    "folders = [name for name in os.listdir(f\"../../data/adhd-beliefs-pt/bertopic_final/{group_name}/\") if os.path.isdir(os.path.join(f\"../../data/adhd-beliefs-pt/bertopic_final/{group_name}/\", name))]\n",
    "folder = folders[0] if folders else None\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_group(group_name, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af34af3",
   "metadata": {},
   "source": [
    "# ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4432b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"ADHD\"\n",
    "folders = [name for name in os.listdir(f\"../../data/adhd-beliefs-pt/bertopic_final/{group_name}/\") if os.path.isdir(os.path.join(f\"../../data/adhd-beliefs-pt/bertopic_final/{group_name}/\", name))]\n",
    "folder = folders[0] if folders else None\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d4bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_group(group_name, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f37cdc9",
   "metadata": {},
   "source": [
    "# no-ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"noADHD\"\n",
    "folders = [name for name in os.listdir(f\"../../data/adhd-beliefs-pt/bertopic_final/{group_name}/\") if os.path.isdir(os.path.join(f\"../../data/adhd-beliefs-pt/bertopic_final/{group_name}/\", name))]\n",
    "folder = folders[0] if folders else None\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6917e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_group(group_name, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680267a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adhd-linguistic-patterns-beliefs-portuguese-women",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
