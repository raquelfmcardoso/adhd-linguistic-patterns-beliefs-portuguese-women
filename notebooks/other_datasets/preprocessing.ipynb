{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e12ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  This movie is not very good, but the soundtrac...   \n",
      "1  I don't think the acting was particularly impr...   \n",
      "2        The plot was simple, yet not boring at all.   \n",
      "\n",
      "                               cleaned_text  \n",
      "0         movie not good soundtrack not bad  \n",
      "1  not think acting particularly impressive  \n",
      "2                    plot simple not boring  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Example DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"This movie is not very good, but the soundtrack was not bad at all.\",\n",
    "        \"I don't think the acting was particularly impressive.\",\n",
    "        \"The plot was simple, yet not boring at all.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Important words to keep\n",
    "important_words = {\"not\", \"no\", \"nor\", \"never\", \"n't\"}\n",
    "adjusted_stop_words = {word for word in nlp.Defaults.stop_words if word not in important_words}\n",
    "\n",
    "# Define the smarter clean function\n",
    "def smart_clean(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in doc:\n",
    "        # Keep negations\n",
    "        if token.lower_ in important_words:\n",
    "            filtered_tokens.append(\"not\")  # Normalize n't -> not\n",
    "        elif not token.is_stop or token.lemma_.lower() not in adjusted_stop_words:\n",
    "            if token.is_alpha:  # Keep only words\n",
    "                filtered_tokens.append(token.lemma_.lower())\n",
    "\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Apply the function\n",
    "df['cleaned_text'] = df['text'].apply(smart_clean)\n",
    "\n",
    "print(df[['text', 'cleaned_text']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "036095ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I PRON True\n",
      "do do AUX True\n",
      "n't not PART True\n",
      "think think VERB False\n",
      "the the DET True\n",
      "acting acting NOUN False\n",
      "was be AUX True\n",
      "particularly particularly ADV False\n",
      "impressive impressive ADJ False\n",
      ". . PUNCT False\n"
     ]
    }
   ],
   "source": [
    "text = \"I don't think the acting was particularly impressive.\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfb623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
